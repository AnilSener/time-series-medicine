{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "#X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 750\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_4, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/750 Iteration: 5 Train loss: 1.780828 Train acc: 0.178333\n",
      "Epoch: 1/750 Iteration: 10 Train loss: 1.764765 Train acc: 0.218333\n",
      "Epoch: 1/750 Iteration: 10 Validation loss: 1.757154 Validation acc: 0.145000\n",
      "Epoch: 1/750 Iteration: 15 Train loss: 1.747301 Train acc: 0.231667\n",
      "Epoch: 2/750 Iteration: 20 Train loss: 1.725802 Train acc: 0.233333\n",
      "Epoch: 2/750 Iteration: 20 Validation loss: 1.721927 Validation acc: 0.238889\n",
      "Epoch: 2/750 Iteration: 25 Train loss: 1.705599 Train acc: 0.253333\n",
      "Epoch: 3/750 Iteration: 30 Train loss: 1.700111 Train acc: 0.243333\n",
      "Epoch: 3/750 Iteration: 30 Validation loss: 1.688670 Validation acc: 0.273889\n",
      "Epoch: 3/750 Iteration: 35 Train loss: 1.679952 Train acc: 0.233333\n",
      "Epoch: 4/750 Iteration: 40 Train loss: 1.672553 Train acc: 0.255000\n",
      "Epoch: 4/750 Iteration: 40 Validation loss: 1.656174 Validation acc: 0.312222\n",
      "Epoch: 4/750 Iteration: 45 Train loss: 1.648328 Train acc: 0.286667\n",
      "Epoch: 5/750 Iteration: 50 Train loss: 1.636304 Train acc: 0.311667\n",
      "Epoch: 5/750 Iteration: 50 Validation loss: 1.622955 Validation acc: 0.334444\n",
      "Epoch: 6/750 Iteration: 55 Train loss: 1.618098 Train acc: 0.345000\n",
      "Epoch: 6/750 Iteration: 60 Train loss: 1.605941 Train acc: 0.336667\n",
      "Epoch: 6/750 Iteration: 60 Validation loss: 1.586979 Validation acc: 0.351667\n",
      "Epoch: 7/750 Iteration: 65 Train loss: 1.566426 Train acc: 0.378333\n",
      "Epoch: 7/750 Iteration: 70 Train loss: 1.553511 Train acc: 0.371667\n",
      "Epoch: 7/750 Iteration: 70 Validation loss: 1.545293 Validation acc: 0.368889\n",
      "Epoch: 8/750 Iteration: 75 Train loss: 1.539994 Train acc: 0.378333\n",
      "Epoch: 8/750 Iteration: 80 Train loss: 1.509722 Train acc: 0.398333\n",
      "Epoch: 8/750 Iteration: 80 Validation loss: 1.496178 Validation acc: 0.487222\n",
      "Epoch: 9/750 Iteration: 85 Train loss: 1.492691 Train acc: 0.415000\n",
      "Epoch: 9/750 Iteration: 90 Train loss: 1.473304 Train acc: 0.426667\n",
      "Epoch: 9/750 Iteration: 90 Validation loss: 1.439229 Validation acc: 0.532778\n",
      "Epoch: 10/750 Iteration: 95 Train loss: 1.420004 Train acc: 0.510000\n",
      "Epoch: 11/750 Iteration: 100 Train loss: 1.405224 Train acc: 0.505000\n",
      "Epoch: 11/750 Iteration: 100 Validation loss: 1.373925 Validation acc: 0.552778\n",
      "Epoch: 11/750 Iteration: 105 Train loss: 1.361780 Train acc: 0.535000\n",
      "Epoch: 12/750 Iteration: 110 Train loss: 1.299816 Train acc: 0.546667\n",
      "Epoch: 12/750 Iteration: 110 Validation loss: 1.301382 Validation acc: 0.586667\n",
      "Epoch: 12/750 Iteration: 115 Train loss: 1.282574 Train acc: 0.535000\n",
      "Epoch: 13/750 Iteration: 120 Train loss: 1.261964 Train acc: 0.556667\n",
      "Epoch: 13/750 Iteration: 120 Validation loss: 1.225633 Validation acc: 0.612222\n",
      "Epoch: 13/750 Iteration: 125 Train loss: 1.210126 Train acc: 0.590000\n",
      "Epoch: 14/750 Iteration: 130 Train loss: 1.205148 Train acc: 0.558333\n",
      "Epoch: 14/750 Iteration: 130 Validation loss: 1.152549 Validation acc: 0.630000\n",
      "Epoch: 14/750 Iteration: 135 Train loss: 1.175528 Train acc: 0.605000\n",
      "Epoch: 15/750 Iteration: 140 Train loss: 1.065657 Train acc: 0.636667\n",
      "Epoch: 15/750 Iteration: 140 Validation loss: 1.085247 Validation acc: 0.642222\n",
      "Epoch: 16/750 Iteration: 145 Train loss: 1.073381 Train acc: 0.603333\n",
      "Epoch: 16/750 Iteration: 150 Train loss: 1.060186 Train acc: 0.605000\n",
      "Epoch: 16/750 Iteration: 150 Validation loss: 1.024412 Validation acc: 0.658333\n",
      "Epoch: 17/750 Iteration: 155 Train loss: 0.993169 Train acc: 0.633333\n",
      "Epoch: 17/750 Iteration: 160 Train loss: 1.014908 Train acc: 0.591667\n",
      "Epoch: 17/750 Iteration: 160 Validation loss: 0.968379 Validation acc: 0.695000\n",
      "Epoch: 18/750 Iteration: 165 Train loss: 1.008304 Train acc: 0.623333\n",
      "Epoch: 18/750 Iteration: 170 Train loss: 0.955660 Train acc: 0.621667\n",
      "Epoch: 18/750 Iteration: 170 Validation loss: 0.917201 Validation acc: 0.702778\n",
      "Epoch: 19/750 Iteration: 175 Train loss: 0.960123 Train acc: 0.588333\n",
      "Epoch: 19/750 Iteration: 180 Train loss: 0.927706 Train acc: 0.655000\n",
      "Epoch: 19/750 Iteration: 180 Validation loss: 0.870399 Validation acc: 0.725000\n",
      "Epoch: 20/750 Iteration: 185 Train loss: 0.859164 Train acc: 0.663333\n",
      "Epoch: 21/750 Iteration: 190 Train loss: 0.854672 Train acc: 0.663333\n",
      "Epoch: 21/750 Iteration: 190 Validation loss: 0.827876 Validation acc: 0.735556\n",
      "Epoch: 21/750 Iteration: 195 Train loss: 0.860975 Train acc: 0.641667\n",
      "Epoch: 22/750 Iteration: 200 Train loss: 0.814404 Train acc: 0.666667\n",
      "Epoch: 22/750 Iteration: 200 Validation loss: 0.789551 Validation acc: 0.747222\n",
      "Epoch: 22/750 Iteration: 205 Train loss: 0.812791 Train acc: 0.673333\n",
      "Epoch: 23/750 Iteration: 210 Train loss: 0.819700 Train acc: 0.661667\n",
      "Epoch: 23/750 Iteration: 210 Validation loss: 0.754204 Validation acc: 0.772778\n",
      "Epoch: 23/750 Iteration: 215 Train loss: 0.771263 Train acc: 0.700000\n",
      "Epoch: 24/750 Iteration: 220 Train loss: 0.797422 Train acc: 0.648333\n",
      "Epoch: 24/750 Iteration: 220 Validation loss: 0.721548 Validation acc: 0.787222\n",
      "Epoch: 24/750 Iteration: 225 Train loss: 0.761482 Train acc: 0.713333\n",
      "Epoch: 25/750 Iteration: 230 Train loss: 0.730715 Train acc: 0.706667\n",
      "Epoch: 25/750 Iteration: 230 Validation loss: 0.690980 Validation acc: 0.797778\n",
      "Epoch: 26/750 Iteration: 235 Train loss: 0.724280 Train acc: 0.688333\n",
      "Epoch: 26/750 Iteration: 240 Train loss: 0.711730 Train acc: 0.728333\n",
      "Epoch: 26/750 Iteration: 240 Validation loss: 0.661598 Validation acc: 0.821667\n",
      "Epoch: 27/750 Iteration: 245 Train loss: 0.698671 Train acc: 0.706667\n",
      "Epoch: 27/750 Iteration: 250 Train loss: 0.688105 Train acc: 0.716667\n",
      "Epoch: 27/750 Iteration: 250 Validation loss: 0.632676 Validation acc: 0.829444\n",
      "Epoch: 28/750 Iteration: 255 Train loss: 0.688634 Train acc: 0.728333\n",
      "Epoch: 28/750 Iteration: 260 Train loss: 0.660418 Train acc: 0.758333\n",
      "Epoch: 28/750 Iteration: 260 Validation loss: 0.603507 Validation acc: 0.843333\n",
      "Epoch: 29/750 Iteration: 265 Train loss: 0.678295 Train acc: 0.700000\n",
      "Epoch: 29/750 Iteration: 270 Train loss: 0.656939 Train acc: 0.756667\n",
      "Epoch: 29/750 Iteration: 270 Validation loss: 0.574724 Validation acc: 0.843889\n",
      "Epoch: 30/750 Iteration: 275 Train loss: 0.593253 Train acc: 0.770000\n",
      "Epoch: 31/750 Iteration: 280 Train loss: 0.596116 Train acc: 0.766667\n",
      "Epoch: 31/750 Iteration: 280 Validation loss: 0.546947 Validation acc: 0.859444\n",
      "Epoch: 31/750 Iteration: 285 Train loss: 0.566544 Train acc: 0.793333\n",
      "Epoch: 32/750 Iteration: 290 Train loss: 0.568178 Train acc: 0.785000\n",
      "Epoch: 32/750 Iteration: 290 Validation loss: 0.521343 Validation acc: 0.859444\n",
      "Epoch: 32/750 Iteration: 295 Train loss: 0.553138 Train acc: 0.801667\n",
      "Epoch: 33/750 Iteration: 300 Train loss: 0.565797 Train acc: 0.761667\n",
      "Epoch: 33/750 Iteration: 300 Validation loss: 0.497329 Validation acc: 0.865000\n",
      "Epoch: 33/750 Iteration: 305 Train loss: 0.508739 Train acc: 0.816667\n",
      "Epoch: 34/750 Iteration: 310 Train loss: 0.537053 Train acc: 0.798333\n",
      "Epoch: 34/750 Iteration: 310 Validation loss: 0.475678 Validation acc: 0.872222\n",
      "Epoch: 34/750 Iteration: 315 Train loss: 0.537979 Train acc: 0.796667\n",
      "Epoch: 35/750 Iteration: 320 Train loss: 0.503733 Train acc: 0.800000\n",
      "Epoch: 35/750 Iteration: 320 Validation loss: 0.456219 Validation acc: 0.873889\n",
      "Epoch: 36/750 Iteration: 325 Train loss: 0.495024 Train acc: 0.828333\n",
      "Epoch: 36/750 Iteration: 330 Train loss: 0.481241 Train acc: 0.818333\n",
      "Epoch: 36/750 Iteration: 330 Validation loss: 0.438440 Validation acc: 0.880000\n",
      "Epoch: 37/750 Iteration: 335 Train loss: 0.474385 Train acc: 0.833333\n",
      "Epoch: 37/750 Iteration: 340 Train loss: 0.492347 Train acc: 0.803333\n",
      "Epoch: 37/750 Iteration: 340 Validation loss: 0.422213 Validation acc: 0.877778\n",
      "Epoch: 38/750 Iteration: 345 Train loss: 0.487323 Train acc: 0.810000\n",
      "Epoch: 38/750 Iteration: 350 Train loss: 0.443097 Train acc: 0.848333\n",
      "Epoch: 38/750 Iteration: 350 Validation loss: 0.407279 Validation acc: 0.883333\n",
      "Epoch: 39/750 Iteration: 355 Train loss: 0.490282 Train acc: 0.788333\n",
      "Epoch: 39/750 Iteration: 360 Train loss: 0.445380 Train acc: 0.860000\n",
      "Epoch: 39/750 Iteration: 360 Validation loss: 0.394021 Validation acc: 0.881111\n",
      "Epoch: 40/750 Iteration: 365 Train loss: 0.437519 Train acc: 0.831667\n",
      "Epoch: 41/750 Iteration: 370 Train loss: 0.444678 Train acc: 0.845000\n",
      "Epoch: 41/750 Iteration: 370 Validation loss: 0.381483 Validation acc: 0.881667\n",
      "Epoch: 41/750 Iteration: 375 Train loss: 0.419352 Train acc: 0.841667\n",
      "Epoch: 42/750 Iteration: 380 Train loss: 0.399709 Train acc: 0.870000\n",
      "Epoch: 42/750 Iteration: 380 Validation loss: 0.369896 Validation acc: 0.885556\n",
      "Epoch: 42/750 Iteration: 385 Train loss: 0.428544 Train acc: 0.831667\n",
      "Epoch: 43/750 Iteration: 390 Train loss: 0.409350 Train acc: 0.840000\n",
      "Epoch: 43/750 Iteration: 390 Validation loss: 0.359377 Validation acc: 0.888333\n",
      "Epoch: 43/750 Iteration: 395 Train loss: 0.395355 Train acc: 0.858333\n",
      "Epoch: 44/750 Iteration: 400 Train loss: 0.416242 Train acc: 0.845000\n",
      "Epoch: 44/750 Iteration: 400 Validation loss: 0.348793 Validation acc: 0.887778\n",
      "Epoch: 44/750 Iteration: 405 Train loss: 0.414257 Train acc: 0.848333\n",
      "Epoch: 45/750 Iteration: 410 Train loss: 0.386136 Train acc: 0.851667\n",
      "Epoch: 45/750 Iteration: 410 Validation loss: 0.339385 Validation acc: 0.889444\n",
      "Epoch: 46/750 Iteration: 415 Train loss: 0.365857 Train acc: 0.876667\n",
      "Epoch: 46/750 Iteration: 420 Train loss: 0.346553 Train acc: 0.891667\n",
      "Epoch: 46/750 Iteration: 420 Validation loss: 0.330712 Validation acc: 0.894444\n",
      "Epoch: 47/750 Iteration: 425 Train loss: 0.365240 Train acc: 0.865000\n",
      "Epoch: 47/750 Iteration: 430 Train loss: 0.368872 Train acc: 0.880000\n",
      "Epoch: 47/750 Iteration: 430 Validation loss: 0.322989 Validation acc: 0.896111\n",
      "Epoch: 48/750 Iteration: 435 Train loss: 0.385859 Train acc: 0.858333\n",
      "Epoch: 48/750 Iteration: 440 Train loss: 0.324559 Train acc: 0.898333\n",
      "Epoch: 48/750 Iteration: 440 Validation loss: 0.315068 Validation acc: 0.896667\n",
      "Epoch: 49/750 Iteration: 445 Train loss: 0.349616 Train acc: 0.866667\n",
      "Epoch: 49/750 Iteration: 450 Train loss: 0.354275 Train acc: 0.875000\n",
      "Epoch: 49/750 Iteration: 450 Validation loss: 0.307834 Validation acc: 0.897222\n",
      "Epoch: 50/750 Iteration: 455 Train loss: 0.333683 Train acc: 0.886667\n",
      "Epoch: 51/750 Iteration: 460 Train loss: 0.335493 Train acc: 0.875000\n",
      "Epoch: 51/750 Iteration: 460 Validation loss: 0.300776 Validation acc: 0.898889\n",
      "Epoch: 51/750 Iteration: 465 Train loss: 0.302775 Train acc: 0.890000\n",
      "Epoch: 52/750 Iteration: 470 Train loss: 0.315509 Train acc: 0.905000\n",
      "Epoch: 52/750 Iteration: 470 Validation loss: 0.294159 Validation acc: 0.901111\n",
      "Epoch: 52/750 Iteration: 475 Train loss: 0.348980 Train acc: 0.881667\n",
      "Epoch: 53/750 Iteration: 480 Train loss: 0.351581 Train acc: 0.855000\n",
      "Epoch: 53/750 Iteration: 480 Validation loss: 0.287800 Validation acc: 0.901667\n",
      "Epoch: 53/750 Iteration: 485 Train loss: 0.298717 Train acc: 0.890000\n",
      "Epoch: 54/750 Iteration: 490 Train loss: 0.321077 Train acc: 0.886667\n",
      "Epoch: 54/750 Iteration: 490 Validation loss: 0.281808 Validation acc: 0.903889\n",
      "Epoch: 54/750 Iteration: 495 Train loss: 0.335942 Train acc: 0.893333\n",
      "Epoch: 55/750 Iteration: 500 Train loss: 0.310640 Train acc: 0.886667\n",
      "Epoch: 55/750 Iteration: 500 Validation loss: 0.276407 Validation acc: 0.904444\n",
      "Epoch: 56/750 Iteration: 505 Train loss: 0.296421 Train acc: 0.886667\n",
      "Epoch: 56/750 Iteration: 510 Train loss: 0.269922 Train acc: 0.916667\n",
      "Epoch: 56/750 Iteration: 510 Validation loss: 0.271606 Validation acc: 0.908333\n",
      "Epoch: 57/750 Iteration: 515 Train loss: 0.297205 Train acc: 0.921667\n",
      "Epoch: 57/750 Iteration: 520 Train loss: 0.305651 Train acc: 0.905000\n",
      "Epoch: 57/750 Iteration: 520 Validation loss: 0.266084 Validation acc: 0.905000\n",
      "Epoch: 58/750 Iteration: 525 Train loss: 0.312195 Train acc: 0.881667\n",
      "Epoch: 58/750 Iteration: 530 Train loss: 0.267671 Train acc: 0.901667\n",
      "Epoch: 58/750 Iteration: 530 Validation loss: 0.261690 Validation acc: 0.908333\n",
      "Epoch: 59/750 Iteration: 535 Train loss: 0.307782 Train acc: 0.875000\n",
      "Epoch: 59/750 Iteration: 540 Train loss: 0.295153 Train acc: 0.913333\n",
      "Epoch: 59/750 Iteration: 540 Validation loss: 0.257146 Validation acc: 0.910556\n",
      "Epoch: 60/750 Iteration: 545 Train loss: 0.266665 Train acc: 0.910000\n",
      "Epoch: 61/750 Iteration: 550 Train loss: 0.292457 Train acc: 0.885000\n",
      "Epoch: 61/750 Iteration: 550 Validation loss: 0.252436 Validation acc: 0.907778\n",
      "Epoch: 61/750 Iteration: 555 Train loss: 0.237897 Train acc: 0.926667\n",
      "Epoch: 62/750 Iteration: 560 Train loss: 0.269916 Train acc: 0.923333\n",
      "Epoch: 62/750 Iteration: 560 Validation loss: 0.248267 Validation acc: 0.909444\n",
      "Epoch: 62/750 Iteration: 565 Train loss: 0.279348 Train acc: 0.908333\n",
      "Epoch: 63/750 Iteration: 570 Train loss: 0.277160 Train acc: 0.888333\n",
      "Epoch: 63/750 Iteration: 570 Validation loss: 0.244073 Validation acc: 0.911667\n",
      "Epoch: 63/750 Iteration: 575 Train loss: 0.258346 Train acc: 0.910000\n",
      "Epoch: 64/750 Iteration: 580 Train loss: 0.284535 Train acc: 0.901667\n",
      "Epoch: 64/750 Iteration: 580 Validation loss: 0.240015 Validation acc: 0.913333\n",
      "Epoch: 64/750 Iteration: 585 Train loss: 0.281197 Train acc: 0.915000\n",
      "Epoch: 65/750 Iteration: 590 Train loss: 0.246926 Train acc: 0.913333\n",
      "Epoch: 65/750 Iteration: 590 Validation loss: 0.236546 Validation acc: 0.913333\n",
      "Epoch: 66/750 Iteration: 595 Train loss: 0.255814 Train acc: 0.901667\n",
      "Epoch: 66/750 Iteration: 600 Train loss: 0.229794 Train acc: 0.920000\n",
      "Epoch: 66/750 Iteration: 600 Validation loss: 0.232512 Validation acc: 0.913889\n",
      "Epoch: 67/750 Iteration: 605 Train loss: 0.260488 Train acc: 0.925000\n",
      "Epoch: 67/750 Iteration: 610 Train loss: 0.254204 Train acc: 0.913333\n",
      "Epoch: 67/750 Iteration: 610 Validation loss: 0.229133 Validation acc: 0.913333\n",
      "Epoch: 68/750 Iteration: 615 Train loss: 0.268152 Train acc: 0.906667\n",
      "Epoch: 68/750 Iteration: 620 Train loss: 0.219331 Train acc: 0.928333\n",
      "Epoch: 68/750 Iteration: 620 Validation loss: 0.225342 Validation acc: 0.915555\n",
      "Epoch: 69/750 Iteration: 625 Train loss: 0.271200 Train acc: 0.891667\n",
      "Epoch: 69/750 Iteration: 630 Train loss: 0.251882 Train acc: 0.925000\n",
      "Epoch: 69/750 Iteration: 630 Validation loss: 0.222372 Validation acc: 0.917778\n",
      "Epoch: 70/750 Iteration: 635 Train loss: 0.232445 Train acc: 0.911667\n",
      "Epoch: 71/750 Iteration: 640 Train loss: 0.229764 Train acc: 0.916667\n",
      "Epoch: 71/750 Iteration: 640 Validation loss: 0.218943 Validation acc: 0.918333\n",
      "Epoch: 71/750 Iteration: 645 Train loss: 0.210194 Train acc: 0.928333\n",
      "Epoch: 72/750 Iteration: 650 Train loss: 0.225726 Train acc: 0.928333\n",
      "Epoch: 72/750 Iteration: 650 Validation loss: 0.215872 Validation acc: 0.920556\n",
      "Epoch: 72/750 Iteration: 655 Train loss: 0.230199 Train acc: 0.921667\n",
      "Epoch: 73/750 Iteration: 660 Train loss: 0.231404 Train acc: 0.910000\n",
      "Epoch: 73/750 Iteration: 660 Validation loss: 0.213038 Validation acc: 0.921111\n",
      "Epoch: 73/750 Iteration: 665 Train loss: 0.202169 Train acc: 0.923333\n",
      "Epoch: 74/750 Iteration: 670 Train loss: 0.241417 Train acc: 0.905000\n",
      "Epoch: 74/750 Iteration: 670 Validation loss: 0.209820 Validation acc: 0.923889\n",
      "Epoch: 74/750 Iteration: 675 Train loss: 0.229958 Train acc: 0.920000\n",
      "Epoch: 75/750 Iteration: 680 Train loss: 0.226465 Train acc: 0.923333\n",
      "Epoch: 75/750 Iteration: 680 Validation loss: 0.206876 Validation acc: 0.923333\n",
      "Epoch: 76/750 Iteration: 685 Train loss: 0.221490 Train acc: 0.918333\n",
      "Epoch: 76/750 Iteration: 690 Train loss: 0.195419 Train acc: 0.930000\n",
      "Epoch: 76/750 Iteration: 690 Validation loss: 0.204148 Validation acc: 0.923333\n",
      "Epoch: 77/750 Iteration: 695 Train loss: 0.214267 Train acc: 0.933333\n",
      "Epoch: 77/750 Iteration: 700 Train loss: 0.222987 Train acc: 0.925000\n",
      "Epoch: 77/750 Iteration: 700 Validation loss: 0.201304 Validation acc: 0.925000\n",
      "Epoch: 78/750 Iteration: 705 Train loss: 0.245431 Train acc: 0.901667\n",
      "Epoch: 78/750 Iteration: 710 Train loss: 0.185605 Train acc: 0.930000\n",
      "Epoch: 78/750 Iteration: 710 Validation loss: 0.198663 Validation acc: 0.926667\n",
      "Epoch: 79/750 Iteration: 715 Train loss: 0.233683 Train acc: 0.906667\n",
      "Epoch: 79/750 Iteration: 720 Train loss: 0.225025 Train acc: 0.930000\n",
      "Epoch: 79/750 Iteration: 720 Validation loss: 0.195985 Validation acc: 0.926111\n",
      "Epoch: 80/750 Iteration: 725 Train loss: 0.226837 Train acc: 0.920000\n",
      "Epoch: 81/750 Iteration: 730 Train loss: 0.196051 Train acc: 0.928333\n",
      "Epoch: 81/750 Iteration: 730 Validation loss: 0.193534 Validation acc: 0.927778\n",
      "Epoch: 81/750 Iteration: 735 Train loss: 0.187272 Train acc: 0.936667\n",
      "Epoch: 82/750 Iteration: 740 Train loss: 0.195719 Train acc: 0.941667\n",
      "Epoch: 82/750 Iteration: 740 Validation loss: 0.191063 Validation acc: 0.930000\n",
      "Epoch: 82/750 Iteration: 745 Train loss: 0.205458 Train acc: 0.925000\n",
      "Epoch: 83/750 Iteration: 750 Train loss: 0.223208 Train acc: 0.906667\n",
      "Epoch: 83/750 Iteration: 750 Validation loss: 0.188753 Validation acc: 0.927778\n",
      "Epoch: 83/750 Iteration: 755 Train loss: 0.180568 Train acc: 0.936667\n",
      "Epoch: 84/750 Iteration: 760 Train loss: 0.225942 Train acc: 0.906667\n",
      "Epoch: 84/750 Iteration: 760 Validation loss: 0.186515 Validation acc: 0.931111\n",
      "Epoch: 84/750 Iteration: 765 Train loss: 0.215531 Train acc: 0.933333\n",
      "Epoch: 85/750 Iteration: 770 Train loss: 0.197924 Train acc: 0.931667\n",
      "Epoch: 85/750 Iteration: 770 Validation loss: 0.183915 Validation acc: 0.932222\n",
      "Epoch: 86/750 Iteration: 775 Train loss: 0.178625 Train acc: 0.938333\n",
      "Epoch: 86/750 Iteration: 780 Train loss: 0.165377 Train acc: 0.931667\n",
      "Epoch: 86/750 Iteration: 780 Validation loss: 0.181570 Validation acc: 0.930556\n",
      "Epoch: 87/750 Iteration: 785 Train loss: 0.190532 Train acc: 0.941667\n",
      "Epoch: 87/750 Iteration: 790 Train loss: 0.197753 Train acc: 0.930000\n",
      "Epoch: 87/750 Iteration: 790 Validation loss: 0.179607 Validation acc: 0.934444\n",
      "Epoch: 88/750 Iteration: 795 Train loss: 0.212007 Train acc: 0.915000\n",
      "Epoch: 88/750 Iteration: 800 Train loss: 0.154125 Train acc: 0.948333\n",
      "Epoch: 88/750 Iteration: 800 Validation loss: 0.177273 Validation acc: 0.933889\n",
      "Epoch: 89/750 Iteration: 805 Train loss: 0.204476 Train acc: 0.913333\n",
      "Epoch: 89/750 Iteration: 810 Train loss: 0.209222 Train acc: 0.925000\n",
      "Epoch: 89/750 Iteration: 810 Validation loss: 0.175163 Validation acc: 0.933889\n",
      "Epoch: 90/750 Iteration: 815 Train loss: 0.182975 Train acc: 0.938333\n",
      "Epoch: 91/750 Iteration: 820 Train loss: 0.182365 Train acc: 0.935000\n",
      "Epoch: 91/750 Iteration: 820 Validation loss: 0.173125 Validation acc: 0.934444\n",
      "Epoch: 91/750 Iteration: 825 Train loss: 0.156064 Train acc: 0.941667\n",
      "Epoch: 92/750 Iteration: 830 Train loss: 0.178329 Train acc: 0.940000\n",
      "Epoch: 92/750 Iteration: 830 Validation loss: 0.171295 Validation acc: 0.935000\n",
      "Epoch: 92/750 Iteration: 835 Train loss: 0.189299 Train acc: 0.925000\n",
      "Epoch: 93/750 Iteration: 840 Train loss: 0.195209 Train acc: 0.921667\n",
      "Epoch: 93/750 Iteration: 840 Validation loss: 0.169241 Validation acc: 0.936111\n",
      "Epoch: 93/750 Iteration: 845 Train loss: 0.151493 Train acc: 0.941667\n",
      "Epoch: 94/750 Iteration: 850 Train loss: 0.200354 Train acc: 0.918333\n",
      "Epoch: 94/750 Iteration: 850 Validation loss: 0.167478 Validation acc: 0.938333\n",
      "Epoch: 94/750 Iteration: 855 Train loss: 0.186348 Train acc: 0.940000\n",
      "Epoch: 95/750 Iteration: 860 Train loss: 0.191071 Train acc: 0.930000\n",
      "Epoch: 95/750 Iteration: 860 Validation loss: 0.165487 Validation acc: 0.938889\n",
      "Epoch: 96/750 Iteration: 865 Train loss: 0.155284 Train acc: 0.945000\n",
      "Epoch: 96/750 Iteration: 870 Train loss: 0.157108 Train acc: 0.938333\n",
      "Epoch: 96/750 Iteration: 870 Validation loss: 0.163485 Validation acc: 0.940000\n",
      "Epoch: 97/750 Iteration: 875 Train loss: 0.165124 Train acc: 0.955000\n",
      "Epoch: 97/750 Iteration: 880 Train loss: 0.175178 Train acc: 0.936667\n",
      "Epoch: 97/750 Iteration: 880 Validation loss: 0.161709 Validation acc: 0.940000\n",
      "Epoch: 98/750 Iteration: 885 Train loss: 0.198189 Train acc: 0.911667\n",
      "Epoch: 98/750 Iteration: 890 Train loss: 0.149883 Train acc: 0.950000\n",
      "Epoch: 98/750 Iteration: 890 Validation loss: 0.160098 Validation acc: 0.938333\n",
      "Epoch: 99/750 Iteration: 895 Train loss: 0.191522 Train acc: 0.923333\n",
      "Epoch: 99/750 Iteration: 900 Train loss: 0.189702 Train acc: 0.931667\n",
      "Epoch: 99/750 Iteration: 900 Validation loss: 0.158488 Validation acc: 0.941667\n",
      "Epoch: 100/750 Iteration: 905 Train loss: 0.163197 Train acc: 0.948333\n",
      "Epoch: 101/750 Iteration: 910 Train loss: 0.155001 Train acc: 0.938333\n",
      "Epoch: 101/750 Iteration: 910 Validation loss: 0.156710 Validation acc: 0.939444\n",
      "Epoch: 101/750 Iteration: 915 Train loss: 0.155629 Train acc: 0.940000\n",
      "Epoch: 102/750 Iteration: 920 Train loss: 0.160607 Train acc: 0.946667\n",
      "Epoch: 102/750 Iteration: 920 Validation loss: 0.154967 Validation acc: 0.941111\n",
      "Epoch: 102/750 Iteration: 925 Train loss: 0.166585 Train acc: 0.943333\n",
      "Epoch: 103/750 Iteration: 930 Train loss: 0.192164 Train acc: 0.921667\n",
      "Epoch: 103/750 Iteration: 930 Validation loss: 0.153433 Validation acc: 0.943333\n",
      "Epoch: 103/750 Iteration: 935 Train loss: 0.129854 Train acc: 0.953333\n",
      "Epoch: 104/750 Iteration: 940 Train loss: 0.178263 Train acc: 0.928333\n",
      "Epoch: 104/750 Iteration: 940 Validation loss: 0.151847 Validation acc: 0.943333\n",
      "Epoch: 104/750 Iteration: 945 Train loss: 0.176267 Train acc: 0.945000\n",
      "Epoch: 105/750 Iteration: 950 Train loss: 0.155174 Train acc: 0.941667\n",
      "Epoch: 105/750 Iteration: 950 Validation loss: 0.150888 Validation acc: 0.942778\n",
      "Epoch: 106/750 Iteration: 955 Train loss: 0.155731 Train acc: 0.936667\n",
      "Epoch: 106/750 Iteration: 960 Train loss: 0.134878 Train acc: 0.950000\n",
      "Epoch: 106/750 Iteration: 960 Validation loss: 0.148977 Validation acc: 0.945556\n",
      "Epoch: 107/750 Iteration: 965 Train loss: 0.151896 Train acc: 0.955000\n",
      "Epoch: 107/750 Iteration: 970 Train loss: 0.161123 Train acc: 0.941667\n",
      "Epoch: 107/750 Iteration: 970 Validation loss: 0.147569 Validation acc: 0.943889\n",
      "Epoch: 108/750 Iteration: 975 Train loss: 0.173859 Train acc: 0.923333\n",
      "Epoch: 108/750 Iteration: 980 Train loss: 0.121967 Train acc: 0.965000\n",
      "Epoch: 108/750 Iteration: 980 Validation loss: 0.146126 Validation acc: 0.945000\n",
      "Epoch: 109/750 Iteration: 985 Train loss: 0.177743 Train acc: 0.926667\n",
      "Epoch: 109/750 Iteration: 990 Train loss: 0.167057 Train acc: 0.945000\n",
      "Epoch: 109/750 Iteration: 990 Validation loss: 0.144759 Validation acc: 0.944444\n",
      "Epoch: 110/750 Iteration: 995 Train loss: 0.153075 Train acc: 0.941667\n",
      "Epoch: 111/750 Iteration: 1000 Train loss: 0.153040 Train acc: 0.945000\n",
      "Epoch: 111/750 Iteration: 1000 Validation loss: 0.143457 Validation acc: 0.946667\n",
      "Epoch: 111/750 Iteration: 1005 Train loss: 0.141858 Train acc: 0.940000\n",
      "Epoch: 112/750 Iteration: 1010 Train loss: 0.156775 Train acc: 0.946667\n",
      "Epoch: 112/750 Iteration: 1010 Validation loss: 0.142525 Validation acc: 0.945556\n",
      "Epoch: 112/750 Iteration: 1015 Train loss: 0.148178 Train acc: 0.943333\n",
      "Epoch: 113/750 Iteration: 1020 Train loss: 0.169141 Train acc: 0.928333\n",
      "Epoch: 113/750 Iteration: 1020 Validation loss: 0.141556 Validation acc: 0.946667\n",
      "Epoch: 113/750 Iteration: 1025 Train loss: 0.129915 Train acc: 0.945000\n",
      "Epoch: 114/750 Iteration: 1030 Train loss: 0.179130 Train acc: 0.921667\n",
      "Epoch: 114/750 Iteration: 1030 Validation loss: 0.140016 Validation acc: 0.946111\n",
      "Epoch: 114/750 Iteration: 1035 Train loss: 0.150415 Train acc: 0.951667\n",
      "Epoch: 115/750 Iteration: 1040 Train loss: 0.157923 Train acc: 0.945000\n",
      "Epoch: 115/750 Iteration: 1040 Validation loss: 0.139354 Validation acc: 0.946667\n",
      "Epoch: 116/750 Iteration: 1045 Train loss: 0.139352 Train acc: 0.946667\n",
      "Epoch: 116/750 Iteration: 1050 Train loss: 0.130787 Train acc: 0.943333\n",
      "Epoch: 116/750 Iteration: 1050 Validation loss: 0.137621 Validation acc: 0.947778\n",
      "Epoch: 117/750 Iteration: 1055 Train loss: 0.150090 Train acc: 0.948333\n",
      "Epoch: 117/750 Iteration: 1060 Train loss: 0.145210 Train acc: 0.950000\n",
      "Epoch: 117/750 Iteration: 1060 Validation loss: 0.136676 Validation acc: 0.947778\n",
      "Epoch: 118/750 Iteration: 1065 Train loss: 0.163273 Train acc: 0.928333\n",
      "Epoch: 118/750 Iteration: 1070 Train loss: 0.121354 Train acc: 0.955000\n",
      "Epoch: 118/750 Iteration: 1070 Validation loss: 0.136112 Validation acc: 0.946667\n",
      "Epoch: 119/750 Iteration: 1075 Train loss: 0.166502 Train acc: 0.926667\n",
      "Epoch: 119/750 Iteration: 1080 Train loss: 0.146911 Train acc: 0.945000\n",
      "Epoch: 119/750 Iteration: 1080 Validation loss: 0.135137 Validation acc: 0.946111\n",
      "Epoch: 120/750 Iteration: 1085 Train loss: 0.139089 Train acc: 0.953333\n",
      "Epoch: 121/750 Iteration: 1090 Train loss: 0.124512 Train acc: 0.953333\n",
      "Epoch: 121/750 Iteration: 1090 Validation loss: 0.133887 Validation acc: 0.947778\n",
      "Epoch: 121/750 Iteration: 1095 Train loss: 0.121999 Train acc: 0.948333\n",
      "Epoch: 122/750 Iteration: 1100 Train loss: 0.150150 Train acc: 0.956667\n",
      "Epoch: 122/750 Iteration: 1100 Validation loss: 0.133039 Validation acc: 0.948333\n",
      "Epoch: 122/750 Iteration: 1105 Train loss: 0.143622 Train acc: 0.948333\n",
      "Epoch: 123/750 Iteration: 1110 Train loss: 0.164545 Train acc: 0.925000\n",
      "Epoch: 123/750 Iteration: 1110 Validation loss: 0.132243 Validation acc: 0.948889\n",
      "Epoch: 123/750 Iteration: 1115 Train loss: 0.117865 Train acc: 0.951667\n",
      "Epoch: 124/750 Iteration: 1120 Train loss: 0.150258 Train acc: 0.941667\n",
      "Epoch: 124/750 Iteration: 1120 Validation loss: 0.131529 Validation acc: 0.948333\n",
      "Epoch: 124/750 Iteration: 1125 Train loss: 0.141584 Train acc: 0.953333\n",
      "Epoch: 125/750 Iteration: 1130 Train loss: 0.138899 Train acc: 0.953333\n",
      "Epoch: 125/750 Iteration: 1130 Validation loss: 0.130814 Validation acc: 0.948889\n",
      "Epoch: 126/750 Iteration: 1135 Train loss: 0.127194 Train acc: 0.953333\n",
      "Epoch: 126/750 Iteration: 1140 Train loss: 0.125850 Train acc: 0.946667\n",
      "Epoch: 126/750 Iteration: 1140 Validation loss: 0.130478 Validation acc: 0.948889\n",
      "Epoch: 127/750 Iteration: 1145 Train loss: 0.134065 Train acc: 0.953333\n",
      "Epoch: 127/750 Iteration: 1150 Train loss: 0.137011 Train acc: 0.943333\n",
      "Epoch: 127/750 Iteration: 1150 Validation loss: 0.129902 Validation acc: 0.947222\n",
      "Epoch: 128/750 Iteration: 1155 Train loss: 0.162318 Train acc: 0.928333\n",
      "Epoch: 128/750 Iteration: 1160 Train loss: 0.103396 Train acc: 0.961667\n",
      "Epoch: 128/750 Iteration: 1160 Validation loss: 0.128742 Validation acc: 0.949444\n",
      "Epoch: 129/750 Iteration: 1165 Train loss: 0.161118 Train acc: 0.936667\n",
      "Epoch: 129/750 Iteration: 1170 Train loss: 0.146723 Train acc: 0.948333\n",
      "Epoch: 129/750 Iteration: 1170 Validation loss: 0.128489 Validation acc: 0.947222\n",
      "Epoch: 130/750 Iteration: 1175 Train loss: 0.132574 Train acc: 0.951667\n",
      "Epoch: 131/750 Iteration: 1180 Train loss: 0.109502 Train acc: 0.965000\n",
      "Epoch: 131/750 Iteration: 1180 Validation loss: 0.127617 Validation acc: 0.949444\n",
      "Epoch: 131/750 Iteration: 1185 Train loss: 0.121424 Train acc: 0.945000\n",
      "Epoch: 132/750 Iteration: 1190 Train loss: 0.125790 Train acc: 0.956667\n",
      "Epoch: 132/750 Iteration: 1190 Validation loss: 0.127041 Validation acc: 0.951667\n",
      "Epoch: 132/750 Iteration: 1195 Train loss: 0.132834 Train acc: 0.951667\n",
      "Epoch: 133/750 Iteration: 1200 Train loss: 0.151857 Train acc: 0.931667\n",
      "Epoch: 133/750 Iteration: 1200 Validation loss: 0.126267 Validation acc: 0.950000\n",
      "Epoch: 133/750 Iteration: 1205 Train loss: 0.112335 Train acc: 0.953333\n",
      "Epoch: 134/750 Iteration: 1210 Train loss: 0.154698 Train acc: 0.926667\n",
      "Epoch: 134/750 Iteration: 1210 Validation loss: 0.125885 Validation acc: 0.948333\n",
      "Epoch: 134/750 Iteration: 1215 Train loss: 0.134860 Train acc: 0.948333\n",
      "Epoch: 135/750 Iteration: 1220 Train loss: 0.129015 Train acc: 0.953333\n",
      "Epoch: 135/750 Iteration: 1220 Validation loss: 0.125267 Validation acc: 0.951111\n",
      "Epoch: 136/750 Iteration: 1225 Train loss: 0.114945 Train acc: 0.956667\n",
      "Epoch: 136/750 Iteration: 1230 Train loss: 0.119433 Train acc: 0.953333\n",
      "Epoch: 136/750 Iteration: 1230 Validation loss: 0.124764 Validation acc: 0.948333\n",
      "Epoch: 137/750 Iteration: 1235 Train loss: 0.129547 Train acc: 0.956667\n",
      "Epoch: 137/750 Iteration: 1240 Train loss: 0.131391 Train acc: 0.951667\n",
      "Epoch: 137/750 Iteration: 1240 Validation loss: 0.124033 Validation acc: 0.952222\n",
      "Epoch: 138/750 Iteration: 1245 Train loss: 0.156329 Train acc: 0.928333\n",
      "Epoch: 138/750 Iteration: 1250 Train loss: 0.104507 Train acc: 0.955000\n",
      "Epoch: 138/750 Iteration: 1250 Validation loss: 0.123787 Validation acc: 0.952222\n",
      "Epoch: 139/750 Iteration: 1255 Train loss: 0.158668 Train acc: 0.933333\n",
      "Epoch: 139/750 Iteration: 1260 Train loss: 0.141197 Train acc: 0.943333\n",
      "Epoch: 139/750 Iteration: 1260 Validation loss: 0.123432 Validation acc: 0.949444\n",
      "Epoch: 140/750 Iteration: 1265 Train loss: 0.130519 Train acc: 0.946667\n",
      "Epoch: 141/750 Iteration: 1270 Train loss: 0.118570 Train acc: 0.948333\n",
      "Epoch: 141/750 Iteration: 1270 Validation loss: 0.122795 Validation acc: 0.950556\n",
      "Epoch: 141/750 Iteration: 1275 Train loss: 0.111012 Train acc: 0.956667\n",
      "Epoch: 142/750 Iteration: 1280 Train loss: 0.120644 Train acc: 0.960000\n",
      "Epoch: 142/750 Iteration: 1280 Validation loss: 0.122426 Validation acc: 0.952778\n",
      "Epoch: 142/750 Iteration: 1285 Train loss: 0.134547 Train acc: 0.946667\n",
      "Epoch: 143/750 Iteration: 1290 Train loss: 0.146291 Train acc: 0.930000\n",
      "Epoch: 143/750 Iteration: 1290 Validation loss: 0.121752 Validation acc: 0.952778\n",
      "Epoch: 143/750 Iteration: 1295 Train loss: 0.099621 Train acc: 0.966667\n",
      "Epoch: 144/750 Iteration: 1300 Train loss: 0.144109 Train acc: 0.928333\n",
      "Epoch: 144/750 Iteration: 1300 Validation loss: 0.121386 Validation acc: 0.954444\n",
      "Epoch: 144/750 Iteration: 1305 Train loss: 0.135626 Train acc: 0.951667\n",
      "Epoch: 145/750 Iteration: 1310 Train loss: 0.122003 Train acc: 0.963333\n",
      "Epoch: 145/750 Iteration: 1310 Validation loss: 0.120917 Validation acc: 0.952222\n",
      "Epoch: 146/750 Iteration: 1315 Train loss: 0.116583 Train acc: 0.951667\n",
      "Epoch: 146/750 Iteration: 1320 Train loss: 0.107830 Train acc: 0.956667\n",
      "Epoch: 146/750 Iteration: 1320 Validation loss: 0.120536 Validation acc: 0.950556\n",
      "Epoch: 147/750 Iteration: 1325 Train loss: 0.124980 Train acc: 0.961667\n",
      "Epoch: 147/750 Iteration: 1330 Train loss: 0.129205 Train acc: 0.946667\n",
      "Epoch: 147/750 Iteration: 1330 Validation loss: 0.120286 Validation acc: 0.952778\n",
      "Epoch: 148/750 Iteration: 1335 Train loss: 0.143931 Train acc: 0.935000\n",
      "Epoch: 148/750 Iteration: 1340 Train loss: 0.096933 Train acc: 0.958333\n",
      "Epoch: 148/750 Iteration: 1340 Validation loss: 0.119702 Validation acc: 0.955000\n",
      "Epoch: 149/750 Iteration: 1345 Train loss: 0.145429 Train acc: 0.928333\n",
      "Epoch: 149/750 Iteration: 1350 Train loss: 0.132669 Train acc: 0.948333\n",
      "Epoch: 149/750 Iteration: 1350 Validation loss: 0.119377 Validation acc: 0.951667\n",
      "Epoch: 150/750 Iteration: 1355 Train loss: 0.125446 Train acc: 0.955000\n",
      "Epoch: 151/750 Iteration: 1360 Train loss: 0.110028 Train acc: 0.958333\n",
      "Epoch: 151/750 Iteration: 1360 Validation loss: 0.119119 Validation acc: 0.950556\n",
      "Epoch: 151/750 Iteration: 1365 Train loss: 0.106067 Train acc: 0.958333\n",
      "Epoch: 152/750 Iteration: 1370 Train loss: 0.121614 Train acc: 0.961667\n",
      "Epoch: 152/750 Iteration: 1370 Validation loss: 0.118524 Validation acc: 0.955000\n",
      "Epoch: 152/750 Iteration: 1375 Train loss: 0.123789 Train acc: 0.958333\n",
      "Epoch: 153/750 Iteration: 1380 Train loss: 0.142890 Train acc: 0.941667\n",
      "Epoch: 153/750 Iteration: 1380 Validation loss: 0.118331 Validation acc: 0.953333\n",
      "Epoch: 153/750 Iteration: 1385 Train loss: 0.094171 Train acc: 0.965000\n",
      "Epoch: 154/750 Iteration: 1390 Train loss: 0.148906 Train acc: 0.936667\n",
      "Epoch: 154/750 Iteration: 1390 Validation loss: 0.117991 Validation acc: 0.955000\n",
      "Epoch: 154/750 Iteration: 1395 Train loss: 0.120652 Train acc: 0.953333\n",
      "Epoch: 155/750 Iteration: 1400 Train loss: 0.116643 Train acc: 0.958333\n",
      "Epoch: 155/750 Iteration: 1400 Validation loss: 0.117811 Validation acc: 0.955000\n",
      "Epoch: 156/750 Iteration: 1405 Train loss: 0.107382 Train acc: 0.955000\n",
      "Epoch: 156/750 Iteration: 1410 Train loss: 0.114024 Train acc: 0.951667\n",
      "Epoch: 156/750 Iteration: 1410 Validation loss: 0.117385 Validation acc: 0.952778\n",
      "Epoch: 157/750 Iteration: 1415 Train loss: 0.113482 Train acc: 0.958333\n",
      "Epoch: 157/750 Iteration: 1420 Train loss: 0.116024 Train acc: 0.960000\n",
      "Epoch: 157/750 Iteration: 1420 Validation loss: 0.117081 Validation acc: 0.952222\n",
      "Epoch: 158/750 Iteration: 1425 Train loss: 0.140517 Train acc: 0.941667\n",
      "Epoch: 158/750 Iteration: 1430 Train loss: 0.099658 Train acc: 0.961667\n",
      "Epoch: 158/750 Iteration: 1430 Validation loss: 0.116806 Validation acc: 0.955000\n",
      "Epoch: 159/750 Iteration: 1435 Train loss: 0.148620 Train acc: 0.930000\n",
      "Epoch: 159/750 Iteration: 1440 Train loss: 0.128392 Train acc: 0.950000\n",
      "Epoch: 159/750 Iteration: 1440 Validation loss: 0.116717 Validation acc: 0.950556\n",
      "Epoch: 160/750 Iteration: 1445 Train loss: 0.121251 Train acc: 0.953333\n",
      "Epoch: 161/750 Iteration: 1450 Train loss: 0.102686 Train acc: 0.956667\n",
      "Epoch: 161/750 Iteration: 1450 Validation loss: 0.116551 Validation acc: 0.953889\n",
      "Epoch: 161/750 Iteration: 1455 Train loss: 0.108251 Train acc: 0.953333\n",
      "Epoch: 162/750 Iteration: 1460 Train loss: 0.118455 Train acc: 0.960000\n",
      "Epoch: 162/750 Iteration: 1460 Validation loss: 0.115859 Validation acc: 0.953889\n",
      "Epoch: 162/750 Iteration: 1465 Train loss: 0.123493 Train acc: 0.951667\n",
      "Epoch: 163/750 Iteration: 1470 Train loss: 0.135187 Train acc: 0.936667\n",
      "Epoch: 163/750 Iteration: 1470 Validation loss: 0.115616 Validation acc: 0.953889\n",
      "Epoch: 163/750 Iteration: 1475 Train loss: 0.090446 Train acc: 0.960000\n",
      "Epoch: 164/750 Iteration: 1480 Train loss: 0.143655 Train acc: 0.935000\n",
      "Epoch: 164/750 Iteration: 1480 Validation loss: 0.115425 Validation acc: 0.955000\n",
      "Epoch: 164/750 Iteration: 1485 Train loss: 0.133490 Train acc: 0.946667\n",
      "Epoch: 165/750 Iteration: 1490 Train loss: 0.113529 Train acc: 0.951667\n",
      "Epoch: 165/750 Iteration: 1490 Validation loss: 0.115071 Validation acc: 0.952222\n",
      "Epoch: 166/750 Iteration: 1495 Train loss: 0.107665 Train acc: 0.955000\n",
      "Epoch: 166/750 Iteration: 1500 Train loss: 0.102236 Train acc: 0.960000\n",
      "Epoch: 166/750 Iteration: 1500 Validation loss: 0.114929 Validation acc: 0.954444\n",
      "Epoch: 167/750 Iteration: 1505 Train loss: 0.121574 Train acc: 0.958333\n",
      "Epoch: 167/750 Iteration: 1510 Train loss: 0.119303 Train acc: 0.950000\n",
      "Epoch: 167/750 Iteration: 1510 Validation loss: 0.114760 Validation acc: 0.951111\n",
      "Epoch: 168/750 Iteration: 1515 Train loss: 0.139576 Train acc: 0.938333\n",
      "Epoch: 168/750 Iteration: 1520 Train loss: 0.088058 Train acc: 0.965000\n",
      "Epoch: 168/750 Iteration: 1520 Validation loss: 0.114627 Validation acc: 0.952222\n",
      "Epoch: 169/750 Iteration: 1525 Train loss: 0.140170 Train acc: 0.936667\n",
      "Epoch: 169/750 Iteration: 1530 Train loss: 0.132687 Train acc: 0.948333\n",
      "Epoch: 169/750 Iteration: 1530 Validation loss: 0.114183 Validation acc: 0.951111\n",
      "Epoch: 170/750 Iteration: 1535 Train loss: 0.118148 Train acc: 0.955000\n",
      "Epoch: 171/750 Iteration: 1540 Train loss: 0.105606 Train acc: 0.955000\n",
      "Epoch: 171/750 Iteration: 1540 Validation loss: 0.114069 Validation acc: 0.951667\n",
      "Epoch: 171/750 Iteration: 1545 Train loss: 0.102858 Train acc: 0.956667\n",
      "Epoch: 172/750 Iteration: 1550 Train loss: 0.113685 Train acc: 0.955000\n",
      "Epoch: 172/750 Iteration: 1550 Validation loss: 0.113776 Validation acc: 0.953333\n",
      "Epoch: 172/750 Iteration: 1555 Train loss: 0.113969 Train acc: 0.961667\n",
      "Epoch: 173/750 Iteration: 1560 Train loss: 0.154146 Train acc: 0.933333\n",
      "Epoch: 173/750 Iteration: 1560 Validation loss: 0.113610 Validation acc: 0.952222\n",
      "Epoch: 173/750 Iteration: 1565 Train loss: 0.089699 Train acc: 0.961667\n",
      "Epoch: 174/750 Iteration: 1570 Train loss: 0.132898 Train acc: 0.940000\n",
      "Epoch: 174/750 Iteration: 1570 Validation loss: 0.113150 Validation acc: 0.956111\n",
      "Epoch: 174/750 Iteration: 1575 Train loss: 0.120521 Train acc: 0.948333\n",
      "Epoch: 175/750 Iteration: 1580 Train loss: 0.111006 Train acc: 0.956667\n",
      "Epoch: 175/750 Iteration: 1580 Validation loss: 0.113081 Validation acc: 0.953333\n",
      "Epoch: 176/750 Iteration: 1585 Train loss: 0.103430 Train acc: 0.961667\n",
      "Epoch: 176/750 Iteration: 1590 Train loss: 0.100424 Train acc: 0.955000\n",
      "Epoch: 176/750 Iteration: 1590 Validation loss: 0.113001 Validation acc: 0.951667\n",
      "Epoch: 177/750 Iteration: 1595 Train loss: 0.122704 Train acc: 0.956667\n",
      "Epoch: 177/750 Iteration: 1600 Train loss: 0.119267 Train acc: 0.950000\n",
      "Epoch: 177/750 Iteration: 1600 Validation loss: 0.112665 Validation acc: 0.952778\n",
      "Epoch: 178/750 Iteration: 1605 Train loss: 0.137919 Train acc: 0.931667\n",
      "Epoch: 178/750 Iteration: 1610 Train loss: 0.088182 Train acc: 0.961667\n",
      "Epoch: 178/750 Iteration: 1610 Validation loss: 0.112386 Validation acc: 0.952222\n",
      "Epoch: 179/750 Iteration: 1615 Train loss: 0.132709 Train acc: 0.941667\n",
      "Epoch: 179/750 Iteration: 1620 Train loss: 0.115610 Train acc: 0.958333\n",
      "Epoch: 179/750 Iteration: 1620 Validation loss: 0.113062 Validation acc: 0.952778\n",
      "Epoch: 180/750 Iteration: 1625 Train loss: 0.113741 Train acc: 0.958333\n",
      "Epoch: 181/750 Iteration: 1630 Train loss: 0.105576 Train acc: 0.956667\n",
      "Epoch: 181/750 Iteration: 1630 Validation loss: 0.112124 Validation acc: 0.951667\n",
      "Epoch: 181/750 Iteration: 1635 Train loss: 0.096360 Train acc: 0.955000\n",
      "Epoch: 182/750 Iteration: 1640 Train loss: 0.115698 Train acc: 0.955000\n",
      "Epoch: 182/750 Iteration: 1640 Validation loss: 0.112067 Validation acc: 0.951667\n",
      "Epoch: 182/750 Iteration: 1645 Train loss: 0.117031 Train acc: 0.958333\n",
      "Epoch: 183/750 Iteration: 1650 Train loss: 0.141398 Train acc: 0.933333\n",
      "Epoch: 183/750 Iteration: 1650 Validation loss: 0.111654 Validation acc: 0.953333\n",
      "Epoch: 183/750 Iteration: 1655 Train loss: 0.090339 Train acc: 0.958333\n",
      "Epoch: 184/750 Iteration: 1660 Train loss: 0.145442 Train acc: 0.935000\n",
      "Epoch: 184/750 Iteration: 1660 Validation loss: 0.111514 Validation acc: 0.953889\n",
      "Epoch: 184/750 Iteration: 1665 Train loss: 0.127281 Train acc: 0.951667\n",
      "Epoch: 185/750 Iteration: 1670 Train loss: 0.114356 Train acc: 0.956667\n",
      "Epoch: 185/750 Iteration: 1670 Validation loss: 0.111118 Validation acc: 0.953889\n",
      "Epoch: 186/750 Iteration: 1675 Train loss: 0.099048 Train acc: 0.956667\n",
      "Epoch: 186/750 Iteration: 1680 Train loss: 0.095716 Train acc: 0.958333\n",
      "Epoch: 186/750 Iteration: 1680 Validation loss: 0.111195 Validation acc: 0.952778\n",
      "Epoch: 187/750 Iteration: 1685 Train loss: 0.113038 Train acc: 0.963333\n",
      "Epoch: 187/750 Iteration: 1690 Train loss: 0.114607 Train acc: 0.956667\n",
      "Epoch: 187/750 Iteration: 1690 Validation loss: 0.110885 Validation acc: 0.951667\n",
      "Epoch: 188/750 Iteration: 1695 Train loss: 0.135851 Train acc: 0.933333\n",
      "Epoch: 188/750 Iteration: 1700 Train loss: 0.086763 Train acc: 0.963333\n",
      "Epoch: 188/750 Iteration: 1700 Validation loss: 0.110637 Validation acc: 0.952222\n",
      "Epoch: 189/750 Iteration: 1705 Train loss: 0.136345 Train acc: 0.940000\n",
      "Epoch: 189/750 Iteration: 1710 Train loss: 0.118885 Train acc: 0.951667\n",
      "Epoch: 189/750 Iteration: 1710 Validation loss: 0.110417 Validation acc: 0.952778\n",
      "Epoch: 190/750 Iteration: 1715 Train loss: 0.109216 Train acc: 0.958333\n",
      "Epoch: 191/750 Iteration: 1720 Train loss: 0.101087 Train acc: 0.958333\n",
      "Epoch: 191/750 Iteration: 1720 Validation loss: 0.110011 Validation acc: 0.952778\n",
      "Epoch: 191/750 Iteration: 1725 Train loss: 0.101174 Train acc: 0.955000\n",
      "Epoch: 192/750 Iteration: 1730 Train loss: 0.109835 Train acc: 0.961667\n",
      "Epoch: 192/750 Iteration: 1730 Validation loss: 0.109842 Validation acc: 0.952778\n",
      "Epoch: 192/750 Iteration: 1735 Train loss: 0.109170 Train acc: 0.958333\n",
      "Epoch: 193/750 Iteration: 1740 Train loss: 0.126897 Train acc: 0.941667\n",
      "Epoch: 193/750 Iteration: 1740 Validation loss: 0.109482 Validation acc: 0.953889\n",
      "Epoch: 193/750 Iteration: 1745 Train loss: 0.083500 Train acc: 0.963333\n",
      "Epoch: 194/750 Iteration: 1750 Train loss: 0.131706 Train acc: 0.935000\n",
      "Epoch: 194/750 Iteration: 1750 Validation loss: 0.109655 Validation acc: 0.955000\n",
      "Epoch: 194/750 Iteration: 1755 Train loss: 0.117205 Train acc: 0.955000\n",
      "Epoch: 195/750 Iteration: 1760 Train loss: 0.109076 Train acc: 0.958333\n",
      "Epoch: 195/750 Iteration: 1760 Validation loss: 0.109412 Validation acc: 0.953333\n",
      "Epoch: 196/750 Iteration: 1765 Train loss: 0.096565 Train acc: 0.960000\n",
      "Epoch: 196/750 Iteration: 1770 Train loss: 0.095185 Train acc: 0.960000\n",
      "Epoch: 196/750 Iteration: 1770 Validation loss: 0.109176 Validation acc: 0.952222\n",
      "Epoch: 197/750 Iteration: 1775 Train loss: 0.108406 Train acc: 0.961667\n",
      "Epoch: 197/750 Iteration: 1780 Train loss: 0.114658 Train acc: 0.955000\n",
      "Epoch: 197/750 Iteration: 1780 Validation loss: 0.109262 Validation acc: 0.953333\n",
      "Epoch: 198/750 Iteration: 1785 Train loss: 0.131947 Train acc: 0.938333\n",
      "Epoch: 198/750 Iteration: 1790 Train loss: 0.083366 Train acc: 0.965000\n",
      "Epoch: 198/750 Iteration: 1790 Validation loss: 0.108991 Validation acc: 0.952778\n",
      "Epoch: 199/750 Iteration: 1795 Train loss: 0.128505 Train acc: 0.935000\n",
      "Epoch: 199/750 Iteration: 1800 Train loss: 0.117089 Train acc: 0.956667\n",
      "Epoch: 199/750 Iteration: 1800 Validation loss: 0.108766 Validation acc: 0.952778\n",
      "Epoch: 200/750 Iteration: 1805 Train loss: 0.108583 Train acc: 0.958333\n",
      "Epoch: 201/750 Iteration: 1810 Train loss: 0.101224 Train acc: 0.956667\n",
      "Epoch: 201/750 Iteration: 1810 Validation loss: 0.108435 Validation acc: 0.952778\n",
      "Epoch: 201/750 Iteration: 1815 Train loss: 0.096660 Train acc: 0.955000\n",
      "Epoch: 202/750 Iteration: 1820 Train loss: 0.107196 Train acc: 0.961667\n",
      "Epoch: 202/750 Iteration: 1820 Validation loss: 0.108330 Validation acc: 0.952778\n",
      "Epoch: 202/750 Iteration: 1825 Train loss: 0.114019 Train acc: 0.955000\n",
      "Epoch: 203/750 Iteration: 1830 Train loss: 0.132329 Train acc: 0.935000\n",
      "Epoch: 203/750 Iteration: 1830 Validation loss: 0.108165 Validation acc: 0.953889\n",
      "Epoch: 203/750 Iteration: 1835 Train loss: 0.083523 Train acc: 0.968333\n",
      "Epoch: 204/750 Iteration: 1840 Train loss: 0.138025 Train acc: 0.933333\n",
      "Epoch: 204/750 Iteration: 1840 Validation loss: 0.108084 Validation acc: 0.952778\n",
      "Epoch: 204/750 Iteration: 1845 Train loss: 0.114429 Train acc: 0.960000\n",
      "Epoch: 205/750 Iteration: 1850 Train loss: 0.110622 Train acc: 0.955000\n",
      "Epoch: 205/750 Iteration: 1850 Validation loss: 0.107911 Validation acc: 0.953889\n",
      "Epoch: 206/750 Iteration: 1855 Train loss: 0.095353 Train acc: 0.958333\n",
      "Epoch: 206/750 Iteration: 1860 Train loss: 0.100049 Train acc: 0.953333\n",
      "Epoch: 206/750 Iteration: 1860 Validation loss: 0.108001 Validation acc: 0.953333\n",
      "Epoch: 207/750 Iteration: 1865 Train loss: 0.108899 Train acc: 0.960000\n",
      "Epoch: 207/750 Iteration: 1870 Train loss: 0.111907 Train acc: 0.955000\n",
      "Epoch: 207/750 Iteration: 1870 Validation loss: 0.107826 Validation acc: 0.952778\n",
      "Epoch: 208/750 Iteration: 1875 Train loss: 0.129887 Train acc: 0.931667\n",
      "Epoch: 208/750 Iteration: 1880 Train loss: 0.081471 Train acc: 0.965000\n",
      "Epoch: 208/750 Iteration: 1880 Validation loss: 0.107454 Validation acc: 0.952778\n",
      "Epoch: 209/750 Iteration: 1885 Train loss: 0.132438 Train acc: 0.938333\n",
      "Epoch: 209/750 Iteration: 1890 Train loss: 0.111675 Train acc: 0.953333\n",
      "Epoch: 209/750 Iteration: 1890 Validation loss: 0.107459 Validation acc: 0.953333\n",
      "Epoch: 210/750 Iteration: 1895 Train loss: 0.111330 Train acc: 0.958333\n",
      "Epoch: 211/750 Iteration: 1900 Train loss: 0.092635 Train acc: 0.956667\n",
      "Epoch: 211/750 Iteration: 1900 Validation loss: 0.107193 Validation acc: 0.953889\n",
      "Epoch: 211/750 Iteration: 1905 Train loss: 0.099757 Train acc: 0.948333\n",
      "Epoch: 212/750 Iteration: 1910 Train loss: 0.113007 Train acc: 0.958333\n",
      "Epoch: 212/750 Iteration: 1910 Validation loss: 0.107002 Validation acc: 0.953889\n",
      "Epoch: 212/750 Iteration: 1915 Train loss: 0.112265 Train acc: 0.958333\n",
      "Epoch: 213/750 Iteration: 1920 Train loss: 0.129766 Train acc: 0.938333\n",
      "Epoch: 213/750 Iteration: 1920 Validation loss: 0.107281 Validation acc: 0.953333\n",
      "Epoch: 213/750 Iteration: 1925 Train loss: 0.079439 Train acc: 0.966667\n",
      "Epoch: 214/750 Iteration: 1930 Train loss: 0.134378 Train acc: 0.935000\n",
      "Epoch: 214/750 Iteration: 1930 Validation loss: 0.107341 Validation acc: 0.953889\n",
      "Epoch: 214/750 Iteration: 1935 Train loss: 0.111970 Train acc: 0.961667\n",
      "Epoch: 215/750 Iteration: 1940 Train loss: 0.111798 Train acc: 0.955000\n",
      "Epoch: 215/750 Iteration: 1940 Validation loss: 0.106648 Validation acc: 0.952778\n",
      "Epoch: 216/750 Iteration: 1945 Train loss: 0.092408 Train acc: 0.955000\n",
      "Epoch: 216/750 Iteration: 1950 Train loss: 0.095468 Train acc: 0.960000\n",
      "Epoch: 216/750 Iteration: 1950 Validation loss: 0.106570 Validation acc: 0.953333\n",
      "Epoch: 217/750 Iteration: 1955 Train loss: 0.108173 Train acc: 0.961667\n",
      "Epoch: 217/750 Iteration: 1960 Train loss: 0.107788 Train acc: 0.955000\n",
      "Epoch: 217/750 Iteration: 1960 Validation loss: 0.106597 Validation acc: 0.953333\n",
      "Epoch: 218/750 Iteration: 1965 Train loss: 0.127214 Train acc: 0.933333\n",
      "Epoch: 218/750 Iteration: 1970 Train loss: 0.081330 Train acc: 0.968333\n",
      "Epoch: 218/750 Iteration: 1970 Validation loss: 0.106557 Validation acc: 0.953889\n",
      "Epoch: 219/750 Iteration: 1975 Train loss: 0.134129 Train acc: 0.935000\n",
      "Epoch: 219/750 Iteration: 1980 Train loss: 0.106160 Train acc: 0.958333\n",
      "Epoch: 219/750 Iteration: 1980 Validation loss: 0.106260 Validation acc: 0.953333\n",
      "Epoch: 220/750 Iteration: 1985 Train loss: 0.101105 Train acc: 0.963333\n",
      "Epoch: 221/750 Iteration: 1990 Train loss: 0.093817 Train acc: 0.956667\n",
      "Epoch: 221/750 Iteration: 1990 Validation loss: 0.106006 Validation acc: 0.952778\n",
      "Epoch: 221/750 Iteration: 1995 Train loss: 0.096976 Train acc: 0.960000\n",
      "Epoch: 222/750 Iteration: 2000 Train loss: 0.105150 Train acc: 0.961667\n",
      "Epoch: 222/750 Iteration: 2000 Validation loss: 0.105726 Validation acc: 0.953889\n",
      "Epoch: 222/750 Iteration: 2005 Train loss: 0.109075 Train acc: 0.955000\n",
      "Epoch: 223/750 Iteration: 2010 Train loss: 0.140162 Train acc: 0.935000\n",
      "Epoch: 223/750 Iteration: 2010 Validation loss: 0.105596 Validation acc: 0.953889\n",
      "Epoch: 223/750 Iteration: 2015 Train loss: 0.074856 Train acc: 0.968333\n",
      "Epoch: 224/750 Iteration: 2020 Train loss: 0.124128 Train acc: 0.941667\n",
      "Epoch: 224/750 Iteration: 2020 Validation loss: 0.105613 Validation acc: 0.954444\n",
      "Epoch: 224/750 Iteration: 2025 Train loss: 0.116925 Train acc: 0.953333\n",
      "Epoch: 225/750 Iteration: 2030 Train loss: 0.099684 Train acc: 0.963333\n",
      "Epoch: 225/750 Iteration: 2030 Validation loss: 0.105672 Validation acc: 0.954444\n",
      "Epoch: 226/750 Iteration: 2035 Train loss: 0.095049 Train acc: 0.956667\n",
      "Epoch: 226/750 Iteration: 2040 Train loss: 0.091363 Train acc: 0.958333\n",
      "Epoch: 226/750 Iteration: 2040 Validation loss: 0.105374 Validation acc: 0.953889\n",
      "Epoch: 227/750 Iteration: 2045 Train loss: 0.103590 Train acc: 0.961667\n",
      "Epoch: 227/750 Iteration: 2050 Train loss: 0.109975 Train acc: 0.955000\n",
      "Epoch: 227/750 Iteration: 2050 Validation loss: 0.105473 Validation acc: 0.953333\n",
      "Epoch: 228/750 Iteration: 2055 Train loss: 0.133716 Train acc: 0.933333\n",
      "Epoch: 228/750 Iteration: 2060 Train loss: 0.079052 Train acc: 0.973333\n",
      "Epoch: 228/750 Iteration: 2060 Validation loss: 0.105010 Validation acc: 0.953889\n",
      "Epoch: 229/750 Iteration: 2065 Train loss: 0.132311 Train acc: 0.940000\n",
      "Epoch: 229/750 Iteration: 2070 Train loss: 0.108604 Train acc: 0.958333\n",
      "Epoch: 229/750 Iteration: 2070 Validation loss: 0.105163 Validation acc: 0.953889\n",
      "Epoch: 230/750 Iteration: 2075 Train loss: 0.102959 Train acc: 0.958333\n",
      "Epoch: 231/750 Iteration: 2080 Train loss: 0.098314 Train acc: 0.956667\n",
      "Epoch: 231/750 Iteration: 2080 Validation loss: 0.104895 Validation acc: 0.954444\n",
      "Epoch: 231/750 Iteration: 2085 Train loss: 0.092148 Train acc: 0.956667\n",
      "Epoch: 232/750 Iteration: 2090 Train loss: 0.106829 Train acc: 0.961667\n",
      "Epoch: 232/750 Iteration: 2090 Validation loss: 0.104613 Validation acc: 0.954444\n",
      "Epoch: 232/750 Iteration: 2095 Train loss: 0.108352 Train acc: 0.953333\n",
      "Epoch: 233/750 Iteration: 2100 Train loss: 0.127169 Train acc: 0.938333\n",
      "Epoch: 233/750 Iteration: 2100 Validation loss: 0.104430 Validation acc: 0.954444\n",
      "Epoch: 233/750 Iteration: 2105 Train loss: 0.080968 Train acc: 0.971667\n",
      "Epoch: 234/750 Iteration: 2110 Train loss: 0.124543 Train acc: 0.943333\n",
      "Epoch: 234/750 Iteration: 2110 Validation loss: 0.104734 Validation acc: 0.955000\n",
      "Epoch: 234/750 Iteration: 2115 Train loss: 0.106822 Train acc: 0.956667\n",
      "Epoch: 235/750 Iteration: 2120 Train loss: 0.105108 Train acc: 0.956667\n",
      "Epoch: 235/750 Iteration: 2120 Validation loss: 0.104435 Validation acc: 0.955000\n",
      "Epoch: 236/750 Iteration: 2125 Train loss: 0.096330 Train acc: 0.958333\n",
      "Epoch: 236/750 Iteration: 2130 Train loss: 0.093621 Train acc: 0.958333\n",
      "Epoch: 236/750 Iteration: 2130 Validation loss: 0.104253 Validation acc: 0.954444\n",
      "Epoch: 237/750 Iteration: 2135 Train loss: 0.103320 Train acc: 0.961667\n",
      "Epoch: 237/750 Iteration: 2140 Train loss: 0.105325 Train acc: 0.958333\n",
      "Epoch: 237/750 Iteration: 2140 Validation loss: 0.104001 Validation acc: 0.954444\n",
      "Epoch: 238/750 Iteration: 2145 Train loss: 0.128616 Train acc: 0.936667\n",
      "Epoch: 238/750 Iteration: 2150 Train loss: 0.075977 Train acc: 0.965000\n",
      "Epoch: 238/750 Iteration: 2150 Validation loss: 0.104113 Validation acc: 0.955000\n",
      "Epoch: 239/750 Iteration: 2155 Train loss: 0.132920 Train acc: 0.933333\n",
      "Epoch: 239/750 Iteration: 2160 Train loss: 0.107926 Train acc: 0.953333\n",
      "Epoch: 239/750 Iteration: 2160 Validation loss: 0.104105 Validation acc: 0.955555\n",
      "Epoch: 240/750 Iteration: 2165 Train loss: 0.105091 Train acc: 0.961667\n",
      "Epoch: 241/750 Iteration: 2170 Train loss: 0.092177 Train acc: 0.958333\n",
      "Epoch: 241/750 Iteration: 2170 Validation loss: 0.103752 Validation acc: 0.954444\n",
      "Epoch: 241/750 Iteration: 2175 Train loss: 0.093269 Train acc: 0.956667\n",
      "Epoch: 242/750 Iteration: 2180 Train loss: 0.104684 Train acc: 0.961667\n",
      "Epoch: 242/750 Iteration: 2180 Validation loss: 0.103677 Validation acc: 0.955555\n",
      "Epoch: 242/750 Iteration: 2185 Train loss: 0.102492 Train acc: 0.958333\n",
      "Epoch: 243/750 Iteration: 2190 Train loss: 0.125388 Train acc: 0.940000\n",
      "Epoch: 243/750 Iteration: 2190 Validation loss: 0.103454 Validation acc: 0.955000\n",
      "Epoch: 243/750 Iteration: 2195 Train loss: 0.073259 Train acc: 0.973333\n",
      "Epoch: 244/750 Iteration: 2200 Train loss: 0.130244 Train acc: 0.936667\n",
      "Epoch: 244/750 Iteration: 2200 Validation loss: 0.103272 Validation acc: 0.955000\n",
      "Epoch: 244/750 Iteration: 2205 Train loss: 0.105162 Train acc: 0.961667\n",
      "Epoch: 245/750 Iteration: 2210 Train loss: 0.106122 Train acc: 0.956667\n",
      "Epoch: 245/750 Iteration: 2210 Validation loss: 0.103091 Validation acc: 0.955000\n",
      "Epoch: 246/750 Iteration: 2215 Train loss: 0.094528 Train acc: 0.960000\n",
      "Epoch: 246/750 Iteration: 2220 Train loss: 0.093689 Train acc: 0.956667\n",
      "Epoch: 246/750 Iteration: 2220 Validation loss: 0.103100 Validation acc: 0.955555\n",
      "Epoch: 247/750 Iteration: 2225 Train loss: 0.100593 Train acc: 0.961667\n",
      "Epoch: 247/750 Iteration: 2230 Train loss: 0.108274 Train acc: 0.951667\n",
      "Epoch: 247/750 Iteration: 2230 Validation loss: 0.103070 Validation acc: 0.956111\n",
      "Epoch: 248/750 Iteration: 2235 Train loss: 0.131249 Train acc: 0.931667\n",
      "Epoch: 248/750 Iteration: 2240 Train loss: 0.074478 Train acc: 0.968333\n",
      "Epoch: 248/750 Iteration: 2240 Validation loss: 0.102842 Validation acc: 0.955555\n",
      "Epoch: 249/750 Iteration: 2245 Train loss: 0.124765 Train acc: 0.938333\n",
      "Epoch: 249/750 Iteration: 2250 Train loss: 0.104545 Train acc: 0.956667\n",
      "Epoch: 249/750 Iteration: 2250 Validation loss: 0.103005 Validation acc: 0.956667\n",
      "Epoch: 250/750 Iteration: 2255 Train loss: 0.103818 Train acc: 0.951667\n",
      "Epoch: 251/750 Iteration: 2260 Train loss: 0.092715 Train acc: 0.961667\n",
      "Epoch: 251/750 Iteration: 2260 Validation loss: 0.102494 Validation acc: 0.955555\n",
      "Epoch: 251/750 Iteration: 2265 Train loss: 0.091721 Train acc: 0.958333\n",
      "Epoch: 252/750 Iteration: 2270 Train loss: 0.103311 Train acc: 0.963333\n",
      "Epoch: 252/750 Iteration: 2270 Validation loss: 0.102369 Validation acc: 0.956111\n",
      "Epoch: 252/750 Iteration: 2275 Train loss: 0.104328 Train acc: 0.958333\n",
      "Epoch: 253/750 Iteration: 2280 Train loss: 0.119225 Train acc: 0.940000\n",
      "Epoch: 253/750 Iteration: 2280 Validation loss: 0.102170 Validation acc: 0.956667\n",
      "Epoch: 253/750 Iteration: 2285 Train loss: 0.073968 Train acc: 0.971667\n",
      "Epoch: 254/750 Iteration: 2290 Train loss: 0.127763 Train acc: 0.935000\n",
      "Epoch: 254/750 Iteration: 2290 Validation loss: 0.102104 Validation acc: 0.956111\n",
      "Epoch: 254/750 Iteration: 2295 Train loss: 0.103255 Train acc: 0.961667\n",
      "Epoch: 255/750 Iteration: 2300 Train loss: 0.100789 Train acc: 0.961667\n",
      "Epoch: 255/750 Iteration: 2300 Validation loss: 0.102160 Validation acc: 0.955555\n",
      "Epoch: 256/750 Iteration: 2305 Train loss: 0.089563 Train acc: 0.960000\n",
      "Epoch: 256/750 Iteration: 2310 Train loss: 0.086490 Train acc: 0.955000\n",
      "Epoch: 256/750 Iteration: 2310 Validation loss: 0.102201 Validation acc: 0.955000\n",
      "Epoch: 257/750 Iteration: 2315 Train loss: 0.097128 Train acc: 0.963333\n",
      "Epoch: 257/750 Iteration: 2320 Train loss: 0.103902 Train acc: 0.961667\n",
      "Epoch: 257/750 Iteration: 2320 Validation loss: 0.101991 Validation acc: 0.955555\n",
      "Epoch: 258/750 Iteration: 2325 Train loss: 0.118910 Train acc: 0.943333\n",
      "Epoch: 258/750 Iteration: 2330 Train loss: 0.076589 Train acc: 0.975000\n",
      "Epoch: 258/750 Iteration: 2330 Validation loss: 0.101927 Validation acc: 0.955555\n",
      "Epoch: 259/750 Iteration: 2335 Train loss: 0.126241 Train acc: 0.943333\n",
      "Epoch: 259/750 Iteration: 2340 Train loss: 0.106967 Train acc: 0.953333\n",
      "Epoch: 259/750 Iteration: 2340 Validation loss: 0.101788 Validation acc: 0.955555\n",
      "Epoch: 260/750 Iteration: 2345 Train loss: 0.100667 Train acc: 0.963333\n",
      "Epoch: 261/750 Iteration: 2350 Train loss: 0.087157 Train acc: 0.961667\n",
      "Epoch: 261/750 Iteration: 2350 Validation loss: 0.101384 Validation acc: 0.955555\n",
      "Epoch: 261/750 Iteration: 2355 Train loss: 0.091026 Train acc: 0.958333\n",
      "Epoch: 262/750 Iteration: 2360 Train loss: 0.098248 Train acc: 0.960000\n",
      "Epoch: 262/750 Iteration: 2360 Validation loss: 0.101285 Validation acc: 0.956111\n",
      "Epoch: 262/750 Iteration: 2365 Train loss: 0.104444 Train acc: 0.965000\n",
      "Epoch: 263/750 Iteration: 2370 Train loss: 0.131065 Train acc: 0.938333\n",
      "Epoch: 263/750 Iteration: 2370 Validation loss: 0.101184 Validation acc: 0.956111\n",
      "Epoch: 263/750 Iteration: 2375 Train loss: 0.072669 Train acc: 0.973333\n",
      "Epoch: 264/750 Iteration: 2380 Train loss: 0.122828 Train acc: 0.940000\n",
      "Epoch: 264/750 Iteration: 2380 Validation loss: 0.101106 Validation acc: 0.956667\n",
      "Epoch: 264/750 Iteration: 2385 Train loss: 0.106134 Train acc: 0.956667\n",
      "Epoch: 265/750 Iteration: 2390 Train loss: 0.102704 Train acc: 0.955000\n",
      "Epoch: 265/750 Iteration: 2390 Validation loss: 0.101131 Validation acc: 0.956667\n",
      "Epoch: 266/750 Iteration: 2395 Train loss: 0.091244 Train acc: 0.960000\n",
      "Epoch: 266/750 Iteration: 2400 Train loss: 0.092733 Train acc: 0.956667\n",
      "Epoch: 266/750 Iteration: 2400 Validation loss: 0.101099 Validation acc: 0.955555\n",
      "Epoch: 267/750 Iteration: 2405 Train loss: 0.098223 Train acc: 0.960000\n",
      "Epoch: 267/750 Iteration: 2410 Train loss: 0.107392 Train acc: 0.961667\n",
      "Epoch: 267/750 Iteration: 2410 Validation loss: 0.101031 Validation acc: 0.956111\n",
      "Epoch: 268/750 Iteration: 2415 Train loss: 0.114090 Train acc: 0.946667\n",
      "Epoch: 268/750 Iteration: 2420 Train loss: 0.070623 Train acc: 0.970000\n",
      "Epoch: 268/750 Iteration: 2420 Validation loss: 0.100578 Validation acc: 0.956111\n",
      "Epoch: 269/750 Iteration: 2425 Train loss: 0.118812 Train acc: 0.940000\n",
      "Epoch: 269/750 Iteration: 2430 Train loss: 0.104919 Train acc: 0.956667\n",
      "Epoch: 269/750 Iteration: 2430 Validation loss: 0.100750 Validation acc: 0.956111\n",
      "Epoch: 270/750 Iteration: 2435 Train loss: 0.095835 Train acc: 0.961667\n",
      "Epoch: 271/750 Iteration: 2440 Train loss: 0.085984 Train acc: 0.960000\n",
      "Epoch: 271/750 Iteration: 2440 Validation loss: 0.100843 Validation acc: 0.956667\n",
      "Epoch: 271/750 Iteration: 2445 Train loss: 0.088073 Train acc: 0.958333\n",
      "Epoch: 272/750 Iteration: 2450 Train loss: 0.097374 Train acc: 0.965000\n",
      "Epoch: 272/750 Iteration: 2450 Validation loss: 0.100111 Validation acc: 0.956667\n",
      "Epoch: 272/750 Iteration: 2455 Train loss: 0.101323 Train acc: 0.956667\n",
      "Epoch: 273/750 Iteration: 2460 Train loss: 0.120555 Train acc: 0.938333\n",
      "Epoch: 273/750 Iteration: 2460 Validation loss: 0.099959 Validation acc: 0.957222\n",
      "Epoch: 273/750 Iteration: 2465 Train loss: 0.070313 Train acc: 0.968333\n",
      "Epoch: 274/750 Iteration: 2470 Train loss: 0.128968 Train acc: 0.941667\n",
      "Epoch: 274/750 Iteration: 2470 Validation loss: 0.100154 Validation acc: 0.956667\n",
      "Epoch: 274/750 Iteration: 2475 Train loss: 0.102047 Train acc: 0.960000\n",
      "Epoch: 275/750 Iteration: 2480 Train loss: 0.101650 Train acc: 0.960000\n",
      "Epoch: 275/750 Iteration: 2480 Validation loss: 0.100062 Validation acc: 0.956667\n",
      "Epoch: 276/750 Iteration: 2485 Train loss: 0.085747 Train acc: 0.961667\n",
      "Epoch: 276/750 Iteration: 2490 Train loss: 0.088739 Train acc: 0.961667\n",
      "Epoch: 276/750 Iteration: 2490 Validation loss: 0.099822 Validation acc: 0.956667\n",
      "Epoch: 277/750 Iteration: 2495 Train loss: 0.097702 Train acc: 0.963333\n",
      "Epoch: 277/750 Iteration: 2500 Train loss: 0.098958 Train acc: 0.955000\n",
      "Epoch: 277/750 Iteration: 2500 Validation loss: 0.099695 Validation acc: 0.955555\n",
      "Epoch: 278/750 Iteration: 2505 Train loss: 0.124999 Train acc: 0.936667\n",
      "Epoch: 278/750 Iteration: 2510 Train loss: 0.074755 Train acc: 0.968333\n",
      "Epoch: 278/750 Iteration: 2510 Validation loss: 0.099775 Validation acc: 0.956667\n",
      "Epoch: 279/750 Iteration: 2515 Train loss: 0.120943 Train acc: 0.941667\n",
      "Epoch: 279/750 Iteration: 2520 Train loss: 0.102673 Train acc: 0.960000\n",
      "Epoch: 279/750 Iteration: 2520 Validation loss: 0.099574 Validation acc: 0.956667\n",
      "Epoch: 280/750 Iteration: 2525 Train loss: 0.100388 Train acc: 0.955000\n",
      "Epoch: 281/750 Iteration: 2530 Train loss: 0.083282 Train acc: 0.963333\n",
      "Epoch: 281/750 Iteration: 2530 Validation loss: 0.099361 Validation acc: 0.957222\n",
      "Epoch: 281/750 Iteration: 2535 Train loss: 0.087484 Train acc: 0.961667\n",
      "Epoch: 282/750 Iteration: 2540 Train loss: 0.097678 Train acc: 0.961667\n",
      "Epoch: 282/750 Iteration: 2540 Validation loss: 0.099366 Validation acc: 0.956667\n",
      "Epoch: 282/750 Iteration: 2545 Train loss: 0.098632 Train acc: 0.956667\n",
      "Epoch: 283/750 Iteration: 2550 Train loss: 0.119375 Train acc: 0.941667\n",
      "Epoch: 283/750 Iteration: 2550 Validation loss: 0.099468 Validation acc: 0.956667\n",
      "Epoch: 283/750 Iteration: 2555 Train loss: 0.074066 Train acc: 0.971667\n",
      "Epoch: 284/750 Iteration: 2560 Train loss: 0.122888 Train acc: 0.940000\n",
      "Epoch: 284/750 Iteration: 2560 Validation loss: 0.099006 Validation acc: 0.957222\n",
      "Epoch: 284/750 Iteration: 2565 Train loss: 0.101922 Train acc: 0.968333\n",
      "Epoch: 285/750 Iteration: 2570 Train loss: 0.095514 Train acc: 0.960000\n",
      "Epoch: 285/750 Iteration: 2570 Validation loss: 0.098742 Validation acc: 0.957778\n",
      "Epoch: 286/750 Iteration: 2575 Train loss: 0.087618 Train acc: 0.961667\n",
      "Epoch: 286/750 Iteration: 2580 Train loss: 0.084727 Train acc: 0.961667\n",
      "Epoch: 286/750 Iteration: 2580 Validation loss: 0.099150 Validation acc: 0.957222\n",
      "Epoch: 287/750 Iteration: 2585 Train loss: 0.096924 Train acc: 0.966667\n",
      "Epoch: 287/750 Iteration: 2590 Train loss: 0.091839 Train acc: 0.965000\n",
      "Epoch: 287/750 Iteration: 2590 Validation loss: 0.098620 Validation acc: 0.957222\n",
      "Epoch: 288/750 Iteration: 2595 Train loss: 0.126622 Train acc: 0.933333\n",
      "Epoch: 288/750 Iteration: 2600 Train loss: 0.073986 Train acc: 0.966667\n",
      "Epoch: 288/750 Iteration: 2600 Validation loss: 0.098914 Validation acc: 0.957222\n",
      "Epoch: 289/750 Iteration: 2605 Train loss: 0.122734 Train acc: 0.941667\n",
      "Epoch: 289/750 Iteration: 2610 Train loss: 0.101881 Train acc: 0.965000\n",
      "Epoch: 289/750 Iteration: 2610 Validation loss: 0.098535 Validation acc: 0.956667\n",
      "Epoch: 290/750 Iteration: 2615 Train loss: 0.095594 Train acc: 0.960000\n",
      "Epoch: 291/750 Iteration: 2620 Train loss: 0.084455 Train acc: 0.966667\n",
      "Epoch: 291/750 Iteration: 2620 Validation loss: 0.098787 Validation acc: 0.957222\n",
      "Epoch: 291/750 Iteration: 2625 Train loss: 0.085883 Train acc: 0.963333\n",
      "Epoch: 292/750 Iteration: 2630 Train loss: 0.092308 Train acc: 0.965000\n",
      "Epoch: 292/750 Iteration: 2630 Validation loss: 0.098273 Validation acc: 0.957222\n",
      "Epoch: 292/750 Iteration: 2635 Train loss: 0.096165 Train acc: 0.963333\n",
      "Epoch: 293/750 Iteration: 2640 Train loss: 0.114102 Train acc: 0.943333\n",
      "Epoch: 293/750 Iteration: 2640 Validation loss: 0.097788 Validation acc: 0.957778\n",
      "Epoch: 293/750 Iteration: 2645 Train loss: 0.070545 Train acc: 0.968333\n",
      "Epoch: 294/750 Iteration: 2650 Train loss: 0.119082 Train acc: 0.943333\n",
      "Epoch: 294/750 Iteration: 2650 Validation loss: 0.097698 Validation acc: 0.957778\n",
      "Epoch: 294/750 Iteration: 2655 Train loss: 0.102144 Train acc: 0.963333\n",
      "Epoch: 295/750 Iteration: 2660 Train loss: 0.092117 Train acc: 0.965000\n",
      "Epoch: 295/750 Iteration: 2660 Validation loss: 0.097823 Validation acc: 0.956667\n",
      "Epoch: 296/750 Iteration: 2665 Train loss: 0.087890 Train acc: 0.960000\n",
      "Epoch: 296/750 Iteration: 2670 Train loss: 0.089485 Train acc: 0.955000\n",
      "Epoch: 296/750 Iteration: 2670 Validation loss: 0.097961 Validation acc: 0.957778\n",
      "Epoch: 297/750 Iteration: 2675 Train loss: 0.095568 Train acc: 0.963333\n",
      "Epoch: 297/750 Iteration: 2680 Train loss: 0.100013 Train acc: 0.958333\n",
      "Epoch: 297/750 Iteration: 2680 Validation loss: 0.097666 Validation acc: 0.957222\n",
      "Epoch: 298/750 Iteration: 2685 Train loss: 0.120222 Train acc: 0.938333\n",
      "Epoch: 298/750 Iteration: 2690 Train loss: 0.074247 Train acc: 0.965000\n",
      "Epoch: 298/750 Iteration: 2690 Validation loss: 0.097616 Validation acc: 0.957222\n",
      "Epoch: 299/750 Iteration: 2695 Train loss: 0.115483 Train acc: 0.938333\n",
      "Epoch: 299/750 Iteration: 2700 Train loss: 0.099897 Train acc: 0.961667\n",
      "Epoch: 299/750 Iteration: 2700 Validation loss: 0.097665 Validation acc: 0.956667\n",
      "Epoch: 300/750 Iteration: 2705 Train loss: 0.099634 Train acc: 0.955000\n",
      "Epoch: 301/750 Iteration: 2710 Train loss: 0.088349 Train acc: 0.960000\n",
      "Epoch: 301/750 Iteration: 2710 Validation loss: 0.097294 Validation acc: 0.958333\n",
      "Epoch: 301/750 Iteration: 2715 Train loss: 0.084709 Train acc: 0.958333\n",
      "Epoch: 302/750 Iteration: 2720 Train loss: 0.089419 Train acc: 0.965000\n",
      "Epoch: 302/750 Iteration: 2720 Validation loss: 0.097110 Validation acc: 0.957778\n",
      "Epoch: 302/750 Iteration: 2725 Train loss: 0.097186 Train acc: 0.956667\n",
      "Epoch: 303/750 Iteration: 2730 Train loss: 0.113698 Train acc: 0.938333\n",
      "Epoch: 303/750 Iteration: 2730 Validation loss: 0.096852 Validation acc: 0.958333\n",
      "Epoch: 303/750 Iteration: 2735 Train loss: 0.075065 Train acc: 0.968333\n",
      "Epoch: 304/750 Iteration: 2740 Train loss: 0.122723 Train acc: 0.941667\n",
      "Epoch: 304/750 Iteration: 2740 Validation loss: 0.096984 Validation acc: 0.957778\n",
      "Epoch: 304/750 Iteration: 2745 Train loss: 0.093425 Train acc: 0.961667\n",
      "Epoch: 305/750 Iteration: 2750 Train loss: 0.095728 Train acc: 0.961667\n",
      "Epoch: 305/750 Iteration: 2750 Validation loss: 0.096978 Validation acc: 0.957778\n",
      "Epoch: 306/750 Iteration: 2755 Train loss: 0.086730 Train acc: 0.965000\n",
      "Epoch: 306/750 Iteration: 2760 Train loss: 0.083893 Train acc: 0.961667\n",
      "Epoch: 306/750 Iteration: 2760 Validation loss: 0.096596 Validation acc: 0.958889\n",
      "Epoch: 307/750 Iteration: 2765 Train loss: 0.094520 Train acc: 0.966667\n",
      "Epoch: 307/750 Iteration: 2770 Train loss: 0.095642 Train acc: 0.960000\n",
      "Epoch: 307/750 Iteration: 2770 Validation loss: 0.096735 Validation acc: 0.957778\n",
      "Epoch: 308/750 Iteration: 2775 Train loss: 0.118324 Train acc: 0.946667\n",
      "Epoch: 308/750 Iteration: 2780 Train loss: 0.069583 Train acc: 0.970000\n",
      "Epoch: 308/750 Iteration: 2780 Validation loss: 0.096324 Validation acc: 0.958333\n",
      "Epoch: 309/750 Iteration: 2785 Train loss: 0.118952 Train acc: 0.945000\n",
      "Epoch: 309/750 Iteration: 2790 Train loss: 0.096692 Train acc: 0.956667\n",
      "Epoch: 309/750 Iteration: 2790 Validation loss: 0.096433 Validation acc: 0.957222\n",
      "Epoch: 310/750 Iteration: 2795 Train loss: 0.099882 Train acc: 0.961667\n",
      "Epoch: 311/750 Iteration: 2800 Train loss: 0.087349 Train acc: 0.965000\n",
      "Epoch: 311/750 Iteration: 2800 Validation loss: 0.096365 Validation acc: 0.958333\n",
      "Epoch: 311/750 Iteration: 2805 Train loss: 0.087091 Train acc: 0.960000\n",
      "Epoch: 312/750 Iteration: 2810 Train loss: 0.091900 Train acc: 0.961667\n",
      "Epoch: 312/750 Iteration: 2810 Validation loss: 0.095807 Validation acc: 0.958333\n",
      "Epoch: 312/750 Iteration: 2815 Train loss: 0.095963 Train acc: 0.961667\n",
      "Epoch: 313/750 Iteration: 2820 Train loss: 0.124020 Train acc: 0.938333\n",
      "Epoch: 313/750 Iteration: 2820 Validation loss: 0.095735 Validation acc: 0.958333\n",
      "Epoch: 313/750 Iteration: 2825 Train loss: 0.068792 Train acc: 0.968333\n",
      "Epoch: 314/750 Iteration: 2830 Train loss: 0.113663 Train acc: 0.941667\n",
      "Epoch: 314/750 Iteration: 2830 Validation loss: 0.095871 Validation acc: 0.958889\n",
      "Epoch: 314/750 Iteration: 2835 Train loss: 0.097608 Train acc: 0.961667\n",
      "Epoch: 315/750 Iteration: 2840 Train loss: 0.092684 Train acc: 0.951667\n",
      "Epoch: 315/750 Iteration: 2840 Validation loss: 0.095714 Validation acc: 0.958889\n",
      "Epoch: 316/750 Iteration: 2845 Train loss: 0.081563 Train acc: 0.965000\n",
      "Epoch: 316/750 Iteration: 2850 Train loss: 0.080541 Train acc: 0.961667\n",
      "Epoch: 316/750 Iteration: 2850 Validation loss: 0.095791 Validation acc: 0.957222\n",
      "Epoch: 317/750 Iteration: 2855 Train loss: 0.091216 Train acc: 0.963333\n",
      "Epoch: 317/750 Iteration: 2860 Train loss: 0.098009 Train acc: 0.961667\n",
      "Epoch: 317/750 Iteration: 2860 Validation loss: 0.095411 Validation acc: 0.958333\n",
      "Epoch: 318/750 Iteration: 2865 Train loss: 0.111931 Train acc: 0.946667\n",
      "Epoch: 318/750 Iteration: 2870 Train loss: 0.067435 Train acc: 0.973333\n",
      "Epoch: 318/750 Iteration: 2870 Validation loss: 0.095362 Validation acc: 0.957778\n",
      "Epoch: 319/750 Iteration: 2875 Train loss: 0.116507 Train acc: 0.943333\n",
      "Epoch: 319/750 Iteration: 2880 Train loss: 0.097463 Train acc: 0.961667\n",
      "Epoch: 319/750 Iteration: 2880 Validation loss: 0.095251 Validation acc: 0.960000\n",
      "Epoch: 320/750 Iteration: 2885 Train loss: 0.099329 Train acc: 0.958333\n",
      "Epoch: 321/750 Iteration: 2890 Train loss: 0.085858 Train acc: 0.963333\n",
      "Epoch: 321/750 Iteration: 2890 Validation loss: 0.095421 Validation acc: 0.958333\n",
      "Epoch: 321/750 Iteration: 2895 Train loss: 0.081416 Train acc: 0.958333\n",
      "Epoch: 322/750 Iteration: 2900 Train loss: 0.090586 Train acc: 0.963333\n",
      "Epoch: 322/750 Iteration: 2900 Validation loss: 0.095191 Validation acc: 0.957778\n",
      "Epoch: 322/750 Iteration: 2905 Train loss: 0.093222 Train acc: 0.965000\n",
      "Epoch: 323/750 Iteration: 2910 Train loss: 0.117780 Train acc: 0.946667\n",
      "Epoch: 323/750 Iteration: 2910 Validation loss: 0.095435 Validation acc: 0.957778\n",
      "Epoch: 323/750 Iteration: 2915 Train loss: 0.067763 Train acc: 0.973333\n",
      "Epoch: 324/750 Iteration: 2920 Train loss: 0.110039 Train acc: 0.948333\n",
      "Epoch: 324/750 Iteration: 2920 Validation loss: 0.094862 Validation acc: 0.958889\n",
      "Epoch: 324/750 Iteration: 2925 Train loss: 0.096239 Train acc: 0.960000\n",
      "Epoch: 325/750 Iteration: 2930 Train loss: 0.090641 Train acc: 0.960000\n",
      "Epoch: 325/750 Iteration: 2930 Validation loss: 0.094475 Validation acc: 0.958889\n",
      "Epoch: 326/750 Iteration: 2935 Train loss: 0.080471 Train acc: 0.965000\n",
      "Epoch: 326/750 Iteration: 2940 Train loss: 0.084328 Train acc: 0.956667\n",
      "Epoch: 326/750 Iteration: 2940 Validation loss: 0.094572 Validation acc: 0.958889\n",
      "Epoch: 327/750 Iteration: 2945 Train loss: 0.090983 Train acc: 0.965000\n",
      "Epoch: 327/750 Iteration: 2950 Train loss: 0.092035 Train acc: 0.963333\n",
      "Epoch: 327/750 Iteration: 2950 Validation loss: 0.094598 Validation acc: 0.958889\n",
      "Epoch: 328/750 Iteration: 2955 Train loss: 0.115314 Train acc: 0.946667\n",
      "Epoch: 328/750 Iteration: 2960 Train loss: 0.065012 Train acc: 0.970000\n",
      "Epoch: 328/750 Iteration: 2960 Validation loss: 0.094608 Validation acc: 0.958333\n",
      "Epoch: 329/750 Iteration: 2965 Train loss: 0.119520 Train acc: 0.943333\n",
      "Epoch: 329/750 Iteration: 2970 Train loss: 0.098788 Train acc: 0.966667\n",
      "Epoch: 329/750 Iteration: 2970 Validation loss: 0.094115 Validation acc: 0.959444\n",
      "Epoch: 330/750 Iteration: 2975 Train loss: 0.092747 Train acc: 0.963333\n",
      "Epoch: 331/750 Iteration: 2980 Train loss: 0.082768 Train acc: 0.966667\n",
      "Epoch: 331/750 Iteration: 2980 Validation loss: 0.093900 Validation acc: 0.959444\n",
      "Epoch: 331/750 Iteration: 2985 Train loss: 0.084702 Train acc: 0.956667\n",
      "Epoch: 332/750 Iteration: 2990 Train loss: 0.088235 Train acc: 0.965000\n",
      "Epoch: 332/750 Iteration: 2990 Validation loss: 0.093968 Validation acc: 0.957778\n",
      "Epoch: 332/750 Iteration: 2995 Train loss: 0.093700 Train acc: 0.970000\n",
      "Epoch: 333/750 Iteration: 3000 Train loss: 0.113568 Train acc: 0.940000\n",
      "Epoch: 333/750 Iteration: 3000 Validation loss: 0.093950 Validation acc: 0.959444\n",
      "Epoch: 333/750 Iteration: 3005 Train loss: 0.065933 Train acc: 0.973333\n",
      "Epoch: 334/750 Iteration: 3010 Train loss: 0.114946 Train acc: 0.941667\n",
      "Epoch: 334/750 Iteration: 3010 Validation loss: 0.093785 Validation acc: 0.958333\n",
      "Epoch: 334/750 Iteration: 3015 Train loss: 0.088376 Train acc: 0.968333\n",
      "Epoch: 335/750 Iteration: 3020 Train loss: 0.092858 Train acc: 0.965000\n",
      "Epoch: 335/750 Iteration: 3020 Validation loss: 0.093588 Validation acc: 0.958889\n",
      "Epoch: 336/750 Iteration: 3025 Train loss: 0.084419 Train acc: 0.970000\n",
      "Epoch: 336/750 Iteration: 3030 Train loss: 0.080604 Train acc: 0.963333\n",
      "Epoch: 336/750 Iteration: 3030 Validation loss: 0.093359 Validation acc: 0.957778\n",
      "Epoch: 337/750 Iteration: 3035 Train loss: 0.089665 Train acc: 0.963333\n",
      "Epoch: 337/750 Iteration: 3040 Train loss: 0.095059 Train acc: 0.958333\n",
      "Epoch: 337/750 Iteration: 3040 Validation loss: 0.093958 Validation acc: 0.957222\n",
      "Epoch: 338/750 Iteration: 3045 Train loss: 0.109231 Train acc: 0.941667\n",
      "Epoch: 338/750 Iteration: 3050 Train loss: 0.065749 Train acc: 0.970000\n",
      "Epoch: 338/750 Iteration: 3050 Validation loss: 0.093496 Validation acc: 0.959444\n",
      "Epoch: 339/750 Iteration: 3055 Train loss: 0.115741 Train acc: 0.946667\n",
      "Epoch: 339/750 Iteration: 3060 Train loss: 0.092135 Train acc: 0.961667\n",
      "Epoch: 339/750 Iteration: 3060 Validation loss: 0.092991 Validation acc: 0.959444\n",
      "Epoch: 340/750 Iteration: 3065 Train loss: 0.095725 Train acc: 0.958333\n",
      "Epoch: 341/750 Iteration: 3070 Train loss: 0.084226 Train acc: 0.968333\n",
      "Epoch: 341/750 Iteration: 3070 Validation loss: 0.093126 Validation acc: 0.958333\n",
      "Epoch: 341/750 Iteration: 3075 Train loss: 0.081862 Train acc: 0.960000\n",
      "Epoch: 342/750 Iteration: 3080 Train loss: 0.089708 Train acc: 0.965000\n",
      "Epoch: 342/750 Iteration: 3080 Validation loss: 0.092980 Validation acc: 0.959444\n",
      "Epoch: 342/750 Iteration: 3085 Train loss: 0.095459 Train acc: 0.963333\n",
      "Epoch: 343/750 Iteration: 3090 Train loss: 0.106374 Train acc: 0.950000\n",
      "Epoch: 343/750 Iteration: 3090 Validation loss: 0.092828 Validation acc: 0.958889\n",
      "Epoch: 343/750 Iteration: 3095 Train loss: 0.068148 Train acc: 0.973333\n",
      "Epoch: 344/750 Iteration: 3100 Train loss: 0.110897 Train acc: 0.945000\n",
      "Epoch: 344/750 Iteration: 3100 Validation loss: 0.092436 Validation acc: 0.958889\n",
      "Epoch: 344/750 Iteration: 3105 Train loss: 0.093362 Train acc: 0.963333\n",
      "Epoch: 345/750 Iteration: 3110 Train loss: 0.094150 Train acc: 0.960000\n",
      "Epoch: 345/750 Iteration: 3110 Validation loss: 0.092444 Validation acc: 0.960000\n",
      "Epoch: 346/750 Iteration: 3115 Train loss: 0.086132 Train acc: 0.963333\n",
      "Epoch: 346/750 Iteration: 3120 Train loss: 0.082446 Train acc: 0.958333\n",
      "Epoch: 346/750 Iteration: 3120 Validation loss: 0.092545 Validation acc: 0.958333\n",
      "Epoch: 347/750 Iteration: 3125 Train loss: 0.087207 Train acc: 0.968333\n",
      "Epoch: 347/750 Iteration: 3130 Train loss: 0.088468 Train acc: 0.966667\n",
      "Epoch: 347/750 Iteration: 3130 Validation loss: 0.092161 Validation acc: 0.959444\n",
      "Epoch: 348/750 Iteration: 3135 Train loss: 0.112557 Train acc: 0.941667\n",
      "Epoch: 348/750 Iteration: 3140 Train loss: 0.067014 Train acc: 0.973333\n",
      "Epoch: 348/750 Iteration: 3140 Validation loss: 0.092563 Validation acc: 0.959444\n",
      "Epoch: 349/750 Iteration: 3145 Train loss: 0.109243 Train acc: 0.945000\n",
      "Epoch: 349/750 Iteration: 3150 Train loss: 0.094216 Train acc: 0.966667\n",
      "Epoch: 349/750 Iteration: 3150 Validation loss: 0.092264 Validation acc: 0.958333\n",
      "Epoch: 350/750 Iteration: 3155 Train loss: 0.093557 Train acc: 0.963333\n",
      "Epoch: 351/750 Iteration: 3160 Train loss: 0.083253 Train acc: 0.963333\n",
      "Epoch: 351/750 Iteration: 3160 Validation loss: 0.091808 Validation acc: 0.958889\n",
      "Epoch: 351/750 Iteration: 3165 Train loss: 0.077811 Train acc: 0.961667\n",
      "Epoch: 352/750 Iteration: 3170 Train loss: 0.087872 Train acc: 0.963333\n",
      "Epoch: 352/750 Iteration: 3170 Validation loss: 0.091700 Validation acc: 0.959444\n",
      "Epoch: 352/750 Iteration: 3175 Train loss: 0.091102 Train acc: 0.968333\n",
      "Epoch: 353/750 Iteration: 3180 Train loss: 0.111726 Train acc: 0.946667\n",
      "Epoch: 353/750 Iteration: 3180 Validation loss: 0.091710 Validation acc: 0.959444\n",
      "Epoch: 353/750 Iteration: 3185 Train loss: 0.064508 Train acc: 0.975000\n",
      "Epoch: 354/750 Iteration: 3190 Train loss: 0.112580 Train acc: 0.945000\n",
      "Epoch: 354/750 Iteration: 3190 Validation loss: 0.091639 Validation acc: 0.958889\n",
      "Epoch: 354/750 Iteration: 3195 Train loss: 0.086867 Train acc: 0.970000\n",
      "Epoch: 355/750 Iteration: 3200 Train loss: 0.094709 Train acc: 0.960000\n",
      "Epoch: 355/750 Iteration: 3200 Validation loss: 0.091238 Validation acc: 0.960000\n",
      "Epoch: 356/750 Iteration: 3205 Train loss: 0.078333 Train acc: 0.965000\n",
      "Epoch: 356/750 Iteration: 3210 Train loss: 0.078355 Train acc: 0.963333\n",
      "Epoch: 356/750 Iteration: 3210 Validation loss: 0.091298 Validation acc: 0.960000\n",
      "Epoch: 357/750 Iteration: 3215 Train loss: 0.086671 Train acc: 0.965000\n",
      "Epoch: 357/750 Iteration: 3220 Train loss: 0.089018 Train acc: 0.963333\n",
      "Epoch: 357/750 Iteration: 3220 Validation loss: 0.091373 Validation acc: 0.958889\n",
      "Epoch: 358/750 Iteration: 3225 Train loss: 0.106443 Train acc: 0.940000\n",
      "Epoch: 358/750 Iteration: 3230 Train loss: 0.068951 Train acc: 0.973333\n",
      "Epoch: 358/750 Iteration: 3230 Validation loss: 0.091197 Validation acc: 0.958333\n",
      "Epoch: 359/750 Iteration: 3235 Train loss: 0.110827 Train acc: 0.941667\n",
      "Epoch: 359/750 Iteration: 3240 Train loss: 0.091236 Train acc: 0.966667\n",
      "Epoch: 359/750 Iteration: 3240 Validation loss: 0.090943 Validation acc: 0.958889\n",
      "Epoch: 360/750 Iteration: 3245 Train loss: 0.091658 Train acc: 0.958333\n",
      "Epoch: 361/750 Iteration: 3250 Train loss: 0.081406 Train acc: 0.960000\n",
      "Epoch: 361/750 Iteration: 3250 Validation loss: 0.090917 Validation acc: 0.958889\n",
      "Epoch: 361/750 Iteration: 3255 Train loss: 0.079589 Train acc: 0.956667\n",
      "Epoch: 362/750 Iteration: 3260 Train loss: 0.082123 Train acc: 0.965000\n",
      "Epoch: 362/750 Iteration: 3260 Validation loss: 0.090532 Validation acc: 0.958889\n",
      "Epoch: 362/750 Iteration: 3265 Train loss: 0.087332 Train acc: 0.966667\n",
      "Epoch: 363/750 Iteration: 3270 Train loss: 0.104126 Train acc: 0.945000\n",
      "Epoch: 363/750 Iteration: 3270 Validation loss: 0.090475 Validation acc: 0.960000\n",
      "Epoch: 363/750 Iteration: 3275 Train loss: 0.065805 Train acc: 0.975000\n",
      "Epoch: 364/750 Iteration: 3280 Train loss: 0.109457 Train acc: 0.940000\n",
      "Epoch: 364/750 Iteration: 3280 Validation loss: 0.090448 Validation acc: 0.960000\n",
      "Epoch: 364/750 Iteration: 3285 Train loss: 0.089391 Train acc: 0.965000\n",
      "Epoch: 365/750 Iteration: 3290 Train loss: 0.095911 Train acc: 0.958333\n",
      "Epoch: 365/750 Iteration: 3290 Validation loss: 0.090370 Validation acc: 0.960556\n",
      "Epoch: 366/750 Iteration: 3295 Train loss: 0.079901 Train acc: 0.965000\n",
      "Epoch: 366/750 Iteration: 3300 Train loss: 0.078188 Train acc: 0.965000\n",
      "Epoch: 366/750 Iteration: 3300 Validation loss: 0.090052 Validation acc: 0.960000\n",
      "Epoch: 367/750 Iteration: 3305 Train loss: 0.084665 Train acc: 0.966667\n",
      "Epoch: 367/750 Iteration: 3310 Train loss: 0.092112 Train acc: 0.963333\n",
      "Epoch: 367/750 Iteration: 3310 Validation loss: 0.090285 Validation acc: 0.958889\n",
      "Epoch: 368/750 Iteration: 3315 Train loss: 0.103730 Train acc: 0.950000\n",
      "Epoch: 368/750 Iteration: 3320 Train loss: 0.063279 Train acc: 0.976667\n",
      "Epoch: 368/750 Iteration: 3320 Validation loss: 0.089965 Validation acc: 0.958889\n",
      "Epoch: 369/750 Iteration: 3325 Train loss: 0.107557 Train acc: 0.948333\n",
      "Epoch: 369/750 Iteration: 3330 Train loss: 0.091810 Train acc: 0.963333\n",
      "Epoch: 369/750 Iteration: 3330 Validation loss: 0.089765 Validation acc: 0.958889\n",
      "Epoch: 370/750 Iteration: 3335 Train loss: 0.091689 Train acc: 0.965000\n",
      "Epoch: 371/750 Iteration: 3340 Train loss: 0.077602 Train acc: 0.966667\n",
      "Epoch: 371/750 Iteration: 3340 Validation loss: 0.089637 Validation acc: 0.959444\n",
      "Epoch: 371/750 Iteration: 3345 Train loss: 0.078043 Train acc: 0.966667\n",
      "Epoch: 372/750 Iteration: 3350 Train loss: 0.083463 Train acc: 0.966667\n",
      "Epoch: 372/750 Iteration: 3350 Validation loss: 0.089335 Validation acc: 0.960000\n",
      "Epoch: 372/750 Iteration: 3355 Train loss: 0.084210 Train acc: 0.963333\n",
      "Epoch: 373/750 Iteration: 3360 Train loss: 0.107410 Train acc: 0.945000\n",
      "Epoch: 373/750 Iteration: 3360 Validation loss: 0.089356 Validation acc: 0.961111\n",
      "Epoch: 373/750 Iteration: 3365 Train loss: 0.064421 Train acc: 0.971667\n",
      "Epoch: 374/750 Iteration: 3370 Train loss: 0.110070 Train acc: 0.946667\n",
      "Epoch: 374/750 Iteration: 3370 Validation loss: 0.089255 Validation acc: 0.960556\n",
      "Epoch: 374/750 Iteration: 3375 Train loss: 0.091084 Train acc: 0.968333\n",
      "Epoch: 375/750 Iteration: 3380 Train loss: 0.091040 Train acc: 0.961667\n",
      "Epoch: 375/750 Iteration: 3380 Validation loss: 0.089283 Validation acc: 0.959444\n",
      "Epoch: 376/750 Iteration: 3385 Train loss: 0.074181 Train acc: 0.966667\n",
      "Epoch: 376/750 Iteration: 3390 Train loss: 0.082154 Train acc: 0.960000\n",
      "Epoch: 376/750 Iteration: 3390 Validation loss: 0.088701 Validation acc: 0.961111\n",
      "Epoch: 377/750 Iteration: 3395 Train loss: 0.080410 Train acc: 0.965000\n",
      "Epoch: 377/750 Iteration: 3400 Train loss: 0.086491 Train acc: 0.966667\n",
      "Epoch: 377/750 Iteration: 3400 Validation loss: 0.088371 Validation acc: 0.961111\n",
      "Epoch: 378/750 Iteration: 3405 Train loss: 0.106793 Train acc: 0.946667\n",
      "Epoch: 378/750 Iteration: 3410 Train loss: 0.061333 Train acc: 0.973333\n",
      "Epoch: 378/750 Iteration: 3410 Validation loss: 0.088543 Validation acc: 0.961111\n",
      "Epoch: 379/750 Iteration: 3415 Train loss: 0.109064 Train acc: 0.946667\n",
      "Epoch: 379/750 Iteration: 3420 Train loss: 0.085647 Train acc: 0.968333\n",
      "Epoch: 379/750 Iteration: 3420 Validation loss: 0.088558 Validation acc: 0.958889\n",
      "Epoch: 380/750 Iteration: 3425 Train loss: 0.089463 Train acc: 0.960000\n",
      "Epoch: 381/750 Iteration: 3430 Train loss: 0.078469 Train acc: 0.966667\n",
      "Epoch: 381/750 Iteration: 3430 Validation loss: 0.089036 Validation acc: 0.958333\n",
      "Epoch: 381/750 Iteration: 3435 Train loss: 0.078991 Train acc: 0.961667\n",
      "Epoch: 382/750 Iteration: 3440 Train loss: 0.082193 Train acc: 0.966667\n",
      "Epoch: 382/750 Iteration: 3440 Validation loss: 0.088174 Validation acc: 0.960556\n",
      "Epoch: 382/750 Iteration: 3445 Train loss: 0.083944 Train acc: 0.966667\n",
      "Epoch: 383/750 Iteration: 3450 Train loss: 0.105447 Train acc: 0.945000\n",
      "Epoch: 383/750 Iteration: 3450 Validation loss: 0.087962 Validation acc: 0.960555\n",
      "Epoch: 383/750 Iteration: 3455 Train loss: 0.058799 Train acc: 0.975000\n",
      "Epoch: 384/750 Iteration: 3460 Train loss: 0.109749 Train acc: 0.946667\n",
      "Epoch: 384/750 Iteration: 3460 Validation loss: 0.087793 Validation acc: 0.960000\n",
      "Epoch: 384/750 Iteration: 3465 Train loss: 0.093250 Train acc: 0.960000\n",
      "Epoch: 385/750 Iteration: 3470 Train loss: 0.091517 Train acc: 0.963333\n",
      "Epoch: 385/750 Iteration: 3470 Validation loss: 0.087842 Validation acc: 0.960556\n",
      "Epoch: 386/750 Iteration: 3475 Train loss: 0.076140 Train acc: 0.968333\n",
      "Epoch: 386/750 Iteration: 3480 Train loss: 0.074388 Train acc: 0.968333\n",
      "Epoch: 386/750 Iteration: 3480 Validation loss: 0.087452 Validation acc: 0.961111\n",
      "Epoch: 387/750 Iteration: 3485 Train loss: 0.082113 Train acc: 0.965000\n",
      "Epoch: 387/750 Iteration: 3490 Train loss: 0.082712 Train acc: 0.966667\n",
      "Epoch: 387/750 Iteration: 3490 Validation loss: 0.087198 Validation acc: 0.960556\n",
      "Epoch: 388/750 Iteration: 3495 Train loss: 0.103278 Train acc: 0.945000\n",
      "Epoch: 388/750 Iteration: 3500 Train loss: 0.061729 Train acc: 0.975000\n",
      "Epoch: 388/750 Iteration: 3500 Validation loss: 0.087201 Validation acc: 0.961111\n",
      "Epoch: 389/750 Iteration: 3505 Train loss: 0.109490 Train acc: 0.941667\n",
      "Epoch: 389/750 Iteration: 3510 Train loss: 0.081349 Train acc: 0.966667\n",
      "Epoch: 389/750 Iteration: 3510 Validation loss: 0.087035 Validation acc: 0.960556\n",
      "Epoch: 390/750 Iteration: 3515 Train loss: 0.089471 Train acc: 0.963333\n",
      "Epoch: 391/750 Iteration: 3520 Train loss: 0.077325 Train acc: 0.970000\n",
      "Epoch: 391/750 Iteration: 3520 Validation loss: 0.087485 Validation acc: 0.959444\n",
      "Epoch: 391/750 Iteration: 3525 Train loss: 0.080431 Train acc: 0.961667\n",
      "Epoch: 392/750 Iteration: 3530 Train loss: 0.078592 Train acc: 0.970000\n",
      "Epoch: 392/750 Iteration: 3530 Validation loss: 0.086774 Validation acc: 0.961667\n",
      "Epoch: 392/750 Iteration: 3535 Train loss: 0.082135 Train acc: 0.970000\n",
      "Epoch: 393/750 Iteration: 3540 Train loss: 0.107389 Train acc: 0.945000\n",
      "Epoch: 393/750 Iteration: 3540 Validation loss: 0.087137 Validation acc: 0.961111\n",
      "Epoch: 393/750 Iteration: 3545 Train loss: 0.063355 Train acc: 0.976667\n",
      "Epoch: 394/750 Iteration: 3550 Train loss: 0.107461 Train acc: 0.941667\n",
      "Epoch: 394/750 Iteration: 3550 Validation loss: 0.086317 Validation acc: 0.962222\n",
      "Epoch: 394/750 Iteration: 3555 Train loss: 0.081155 Train acc: 0.970000\n",
      "Epoch: 395/750 Iteration: 3560 Train loss: 0.091277 Train acc: 0.961667\n",
      "Epoch: 395/750 Iteration: 3560 Validation loss: 0.086227 Validation acc: 0.962222\n",
      "Epoch: 396/750 Iteration: 3565 Train loss: 0.078992 Train acc: 0.968333\n",
      "Epoch: 396/750 Iteration: 3570 Train loss: 0.074108 Train acc: 0.961667\n",
      "Epoch: 396/750 Iteration: 3570 Validation loss: 0.086350 Validation acc: 0.961667\n",
      "Epoch: 397/750 Iteration: 3575 Train loss: 0.078332 Train acc: 0.966667\n",
      "Epoch: 397/750 Iteration: 3580 Train loss: 0.086377 Train acc: 0.966667\n",
      "Epoch: 397/750 Iteration: 3580 Validation loss: 0.086418 Validation acc: 0.961111\n",
      "Epoch: 398/750 Iteration: 3585 Train loss: 0.100939 Train acc: 0.951667\n",
      "Epoch: 398/750 Iteration: 3590 Train loss: 0.061974 Train acc: 0.973333\n",
      "Epoch: 398/750 Iteration: 3590 Validation loss: 0.086240 Validation acc: 0.960000\n",
      "Epoch: 399/750 Iteration: 3595 Train loss: 0.108680 Train acc: 0.946667\n",
      "Epoch: 399/750 Iteration: 3600 Train loss: 0.079734 Train acc: 0.966667\n",
      "Epoch: 399/750 Iteration: 3600 Validation loss: 0.086097 Validation acc: 0.961667\n",
      "Epoch: 400/750 Iteration: 3605 Train loss: 0.088891 Train acc: 0.965000\n",
      "Epoch: 401/750 Iteration: 3610 Train loss: 0.074434 Train acc: 0.966667\n",
      "Epoch: 401/750 Iteration: 3610 Validation loss: 0.085884 Validation acc: 0.962222\n",
      "Epoch: 401/750 Iteration: 3615 Train loss: 0.080112 Train acc: 0.965000\n",
      "Epoch: 402/750 Iteration: 3620 Train loss: 0.076124 Train acc: 0.966667\n",
      "Epoch: 402/750 Iteration: 3620 Validation loss: 0.085689 Validation acc: 0.962222\n",
      "Epoch: 402/750 Iteration: 3625 Train loss: 0.083366 Train acc: 0.970000\n",
      "Epoch: 403/750 Iteration: 3630 Train loss: 0.103925 Train acc: 0.941667\n",
      "Epoch: 403/750 Iteration: 3630 Validation loss: 0.085461 Validation acc: 0.962778\n",
      "Epoch: 403/750 Iteration: 3635 Train loss: 0.059006 Train acc: 0.973333\n",
      "Epoch: 404/750 Iteration: 3640 Train loss: 0.100763 Train acc: 0.946667\n",
      "Epoch: 404/750 Iteration: 3640 Validation loss: 0.085183 Validation acc: 0.962222\n",
      "Epoch: 404/750 Iteration: 3645 Train loss: 0.083838 Train acc: 0.966667\n",
      "Epoch: 405/750 Iteration: 3650 Train loss: 0.088727 Train acc: 0.963333\n",
      "Epoch: 405/750 Iteration: 3650 Validation loss: 0.084993 Validation acc: 0.962778\n",
      "Epoch: 406/750 Iteration: 3655 Train loss: 0.073712 Train acc: 0.970000\n",
      "Epoch: 406/750 Iteration: 3660 Train loss: 0.075664 Train acc: 0.966667\n",
      "Epoch: 406/750 Iteration: 3660 Validation loss: 0.085049 Validation acc: 0.961667\n",
      "Epoch: 407/750 Iteration: 3665 Train loss: 0.076352 Train acc: 0.968333\n",
      "Epoch: 407/750 Iteration: 3670 Train loss: 0.090384 Train acc: 0.965000\n",
      "Epoch: 407/750 Iteration: 3670 Validation loss: 0.085130 Validation acc: 0.962222\n",
      "Epoch: 408/750 Iteration: 3675 Train loss: 0.104664 Train acc: 0.948333\n",
      "Epoch: 408/750 Iteration: 3680 Train loss: 0.061054 Train acc: 0.975000\n",
      "Epoch: 408/750 Iteration: 3680 Validation loss: 0.084371 Validation acc: 0.962778\n",
      "Epoch: 409/750 Iteration: 3685 Train loss: 0.112088 Train acc: 0.938333\n",
      "Epoch: 409/750 Iteration: 3690 Train loss: 0.081625 Train acc: 0.965000\n",
      "Epoch: 409/750 Iteration: 3690 Validation loss: 0.084576 Validation acc: 0.962778\n",
      "Epoch: 410/750 Iteration: 3695 Train loss: 0.083850 Train acc: 0.965000\n",
      "Epoch: 411/750 Iteration: 3700 Train loss: 0.075655 Train acc: 0.966667\n",
      "Epoch: 411/750 Iteration: 3700 Validation loss: 0.084698 Validation acc: 0.961667\n",
      "Epoch: 411/750 Iteration: 3705 Train loss: 0.073231 Train acc: 0.966667\n",
      "Epoch: 412/750 Iteration: 3710 Train loss: 0.075900 Train acc: 0.968333\n",
      "Epoch: 412/750 Iteration: 3710 Validation loss: 0.084359 Validation acc: 0.961667\n",
      "Epoch: 412/750 Iteration: 3715 Train loss: 0.080259 Train acc: 0.966667\n",
      "Epoch: 413/750 Iteration: 3720 Train loss: 0.100902 Train acc: 0.948333\n",
      "Epoch: 413/750 Iteration: 3720 Validation loss: 0.084277 Validation acc: 0.962778\n",
      "Epoch: 413/750 Iteration: 3725 Train loss: 0.056956 Train acc: 0.976667\n",
      "Epoch: 414/750 Iteration: 3730 Train loss: 0.111040 Train acc: 0.943333\n",
      "Epoch: 414/750 Iteration: 3730 Validation loss: 0.083977 Validation acc: 0.962778\n",
      "Epoch: 414/750 Iteration: 3735 Train loss: 0.082476 Train acc: 0.968333\n",
      "Epoch: 415/750 Iteration: 3740 Train loss: 0.082779 Train acc: 0.970000\n",
      "Epoch: 415/750 Iteration: 3740 Validation loss: 0.083838 Validation acc: 0.962778\n",
      "Epoch: 416/750 Iteration: 3745 Train loss: 0.075877 Train acc: 0.968333\n",
      "Epoch: 416/750 Iteration: 3750 Train loss: 0.080121 Train acc: 0.960000\n",
      "Epoch: 416/750 Iteration: 3750 Validation loss: 0.083984 Validation acc: 0.962222\n",
      "Epoch: 417/750 Iteration: 3755 Train loss: 0.072234 Train acc: 0.968333\n",
      "Epoch: 417/750 Iteration: 3760 Train loss: 0.082378 Train acc: 0.970000\n",
      "Epoch: 417/750 Iteration: 3760 Validation loss: 0.084641 Validation acc: 0.961111\n",
      "Epoch: 418/750 Iteration: 3765 Train loss: 0.101858 Train acc: 0.943333\n",
      "Epoch: 418/750 Iteration: 3770 Train loss: 0.056546 Train acc: 0.975000\n",
      "Epoch: 418/750 Iteration: 3770 Validation loss: 0.083675 Validation acc: 0.961667\n",
      "Epoch: 419/750 Iteration: 3775 Train loss: 0.104571 Train acc: 0.945000\n",
      "Epoch: 419/750 Iteration: 3780 Train loss: 0.080667 Train acc: 0.966667\n",
      "Epoch: 419/750 Iteration: 3780 Validation loss: 0.083690 Validation acc: 0.962222\n",
      "Epoch: 420/750 Iteration: 3785 Train loss: 0.082669 Train acc: 0.963333\n",
      "Epoch: 421/750 Iteration: 3790 Train loss: 0.073987 Train acc: 0.965000\n",
      "Epoch: 421/750 Iteration: 3790 Validation loss: 0.084211 Validation acc: 0.961667\n",
      "Epoch: 421/750 Iteration: 3795 Train loss: 0.073117 Train acc: 0.966667\n",
      "Epoch: 422/750 Iteration: 3800 Train loss: 0.082601 Train acc: 0.965000\n",
      "Epoch: 422/750 Iteration: 3800 Validation loss: 0.082948 Validation acc: 0.963889\n",
      "Epoch: 422/750 Iteration: 3805 Train loss: 0.087964 Train acc: 0.965000\n",
      "Epoch: 423/750 Iteration: 3810 Train loss: 0.098952 Train acc: 0.943333\n",
      "Epoch: 423/750 Iteration: 3810 Validation loss: 0.082837 Validation acc: 0.963333\n",
      "Epoch: 423/750 Iteration: 3815 Train loss: 0.054648 Train acc: 0.980000\n",
      "Epoch: 424/750 Iteration: 3820 Train loss: 0.103322 Train acc: 0.950000\n",
      "Epoch: 424/750 Iteration: 3820 Validation loss: 0.082954 Validation acc: 0.963333\n",
      "Epoch: 424/750 Iteration: 3825 Train loss: 0.077554 Train acc: 0.973333\n",
      "Epoch: 425/750 Iteration: 3830 Train loss: 0.089328 Train acc: 0.961667\n",
      "Epoch: 425/750 Iteration: 3830 Validation loss: 0.082776 Validation acc: 0.962778\n",
      "Epoch: 426/750 Iteration: 3835 Train loss: 0.071905 Train acc: 0.976667\n",
      "Epoch: 426/750 Iteration: 3840 Train loss: 0.073714 Train acc: 0.965000\n",
      "Epoch: 426/750 Iteration: 3840 Validation loss: 0.082457 Validation acc: 0.962778\n",
      "Epoch: 427/750 Iteration: 3845 Train loss: 0.074973 Train acc: 0.968333\n",
      "Epoch: 427/750 Iteration: 3850 Train loss: 0.084142 Train acc: 0.966667\n",
      "Epoch: 427/750 Iteration: 3850 Validation loss: 0.082342 Validation acc: 0.962222\n",
      "Epoch: 428/750 Iteration: 3855 Train loss: 0.096286 Train acc: 0.948333\n",
      "Epoch: 428/750 Iteration: 3860 Train loss: 0.054370 Train acc: 0.980000\n",
      "Epoch: 428/750 Iteration: 3860 Validation loss: 0.081962 Validation acc: 0.963333\n",
      "Epoch: 429/750 Iteration: 3865 Train loss: 0.106867 Train acc: 0.946667\n",
      "Epoch: 429/750 Iteration: 3870 Train loss: 0.076101 Train acc: 0.970000\n",
      "Epoch: 429/750 Iteration: 3870 Validation loss: 0.082375 Validation acc: 0.963333\n",
      "Epoch: 430/750 Iteration: 3875 Train loss: 0.086688 Train acc: 0.966667\n",
      "Epoch: 431/750 Iteration: 3880 Train loss: 0.070236 Train acc: 0.971667\n",
      "Epoch: 431/750 Iteration: 3880 Validation loss: 0.082527 Validation acc: 0.962778\n",
      "Epoch: 431/750 Iteration: 3885 Train loss: 0.070112 Train acc: 0.963333\n",
      "Epoch: 432/750 Iteration: 3890 Train loss: 0.069401 Train acc: 0.971667\n",
      "Epoch: 432/750 Iteration: 3890 Validation loss: 0.082029 Validation acc: 0.962222\n",
      "Epoch: 432/750 Iteration: 3895 Train loss: 0.086390 Train acc: 0.968333\n",
      "Epoch: 433/750 Iteration: 3900 Train loss: 0.094196 Train acc: 0.948333\n",
      "Epoch: 433/750 Iteration: 3900 Validation loss: 0.081889 Validation acc: 0.962778\n",
      "Epoch: 433/750 Iteration: 3905 Train loss: 0.055593 Train acc: 0.980000\n",
      "Epoch: 434/750 Iteration: 3910 Train loss: 0.101074 Train acc: 0.941667\n",
      "Epoch: 434/750 Iteration: 3910 Validation loss: 0.081484 Validation acc: 0.963333\n",
      "Epoch: 434/750 Iteration: 3915 Train loss: 0.078185 Train acc: 0.971667\n",
      "Epoch: 435/750 Iteration: 3920 Train loss: 0.082163 Train acc: 0.965000\n",
      "Epoch: 435/750 Iteration: 3920 Validation loss: 0.081242 Validation acc: 0.963333\n",
      "Epoch: 436/750 Iteration: 3925 Train loss: 0.071122 Train acc: 0.968333\n",
      "Epoch: 436/750 Iteration: 3930 Train loss: 0.075437 Train acc: 0.966667\n",
      "Epoch: 436/750 Iteration: 3930 Validation loss: 0.081156 Validation acc: 0.962778\n",
      "Epoch: 437/750 Iteration: 3935 Train loss: 0.069968 Train acc: 0.970000\n",
      "Epoch: 437/750 Iteration: 3940 Train loss: 0.076027 Train acc: 0.973333\n",
      "Epoch: 437/750 Iteration: 3940 Validation loss: 0.081334 Validation acc: 0.962222\n",
      "Epoch: 438/750 Iteration: 3945 Train loss: 0.095691 Train acc: 0.945000\n",
      "Epoch: 438/750 Iteration: 3950 Train loss: 0.051835 Train acc: 0.978333\n",
      "Epoch: 438/750 Iteration: 3950 Validation loss: 0.081185 Validation acc: 0.963333\n",
      "Epoch: 439/750 Iteration: 3955 Train loss: 0.103731 Train acc: 0.943333\n",
      "Epoch: 439/750 Iteration: 3960 Train loss: 0.082046 Train acc: 0.970000\n",
      "Epoch: 439/750 Iteration: 3960 Validation loss: 0.080614 Validation acc: 0.963333\n",
      "Epoch: 440/750 Iteration: 3965 Train loss: 0.082859 Train acc: 0.960000\n",
      "Epoch: 441/750 Iteration: 3970 Train loss: 0.069971 Train acc: 0.971667\n",
      "Epoch: 441/750 Iteration: 3970 Validation loss: 0.080608 Validation acc: 0.962778\n",
      "Epoch: 441/750 Iteration: 3975 Train loss: 0.069677 Train acc: 0.963333\n",
      "Epoch: 442/750 Iteration: 3980 Train loss: 0.074200 Train acc: 0.970000\n",
      "Epoch: 442/750 Iteration: 3980 Validation loss: 0.080857 Validation acc: 0.963333\n",
      "Epoch: 442/750 Iteration: 3985 Train loss: 0.075861 Train acc: 0.970000\n",
      "Epoch: 443/750 Iteration: 3990 Train loss: 0.097608 Train acc: 0.943333\n",
      "Epoch: 443/750 Iteration: 3990 Validation loss: 0.080554 Validation acc: 0.963333\n",
      "Epoch: 443/750 Iteration: 3995 Train loss: 0.055251 Train acc: 0.976667\n",
      "Epoch: 444/750 Iteration: 4000 Train loss: 0.105515 Train acc: 0.950000\n",
      "Epoch: 444/750 Iteration: 4000 Validation loss: 0.080516 Validation acc: 0.963333\n",
      "Epoch: 444/750 Iteration: 4005 Train loss: 0.080197 Train acc: 0.966667\n",
      "Epoch: 445/750 Iteration: 4010 Train loss: 0.083013 Train acc: 0.970000\n",
      "Epoch: 445/750 Iteration: 4010 Validation loss: 0.080359 Validation acc: 0.963889\n",
      "Epoch: 446/750 Iteration: 4015 Train loss: 0.072960 Train acc: 0.970000\n",
      "Epoch: 446/750 Iteration: 4020 Train loss: 0.070064 Train acc: 0.970000\n",
      "Epoch: 446/750 Iteration: 4020 Validation loss: 0.080143 Validation acc: 0.963889\n",
      "Epoch: 447/750 Iteration: 4025 Train loss: 0.070974 Train acc: 0.966667\n",
      "Epoch: 447/750 Iteration: 4030 Train loss: 0.082079 Train acc: 0.966667\n",
      "Epoch: 447/750 Iteration: 4030 Validation loss: 0.080298 Validation acc: 0.963889\n",
      "Epoch: 448/750 Iteration: 4035 Train loss: 0.102416 Train acc: 0.943333\n",
      "Epoch: 448/750 Iteration: 4040 Train loss: 0.054758 Train acc: 0.975000\n",
      "Epoch: 448/750 Iteration: 4040 Validation loss: 0.080059 Validation acc: 0.963889\n",
      "Epoch: 449/750 Iteration: 4045 Train loss: 0.098841 Train acc: 0.950000\n",
      "Epoch: 449/750 Iteration: 4050 Train loss: 0.070480 Train acc: 0.976667\n",
      "Epoch: 449/750 Iteration: 4050 Validation loss: 0.079608 Validation acc: 0.962778\n",
      "Epoch: 450/750 Iteration: 4055 Train loss: 0.078542 Train acc: 0.966667\n",
      "Epoch: 451/750 Iteration: 4060 Train loss: 0.070294 Train acc: 0.970000\n",
      "Epoch: 451/750 Iteration: 4060 Validation loss: 0.079542 Validation acc: 0.963333\n",
      "Epoch: 451/750 Iteration: 4065 Train loss: 0.071292 Train acc: 0.968333\n",
      "Epoch: 452/750 Iteration: 4070 Train loss: 0.073417 Train acc: 0.970000\n",
      "Epoch: 452/750 Iteration: 4070 Validation loss: 0.079410 Validation acc: 0.963333\n",
      "Epoch: 452/750 Iteration: 4075 Train loss: 0.082296 Train acc: 0.968333\n",
      "Epoch: 453/750 Iteration: 4080 Train loss: 0.097557 Train acc: 0.950000\n",
      "Epoch: 453/750 Iteration: 4080 Validation loss: 0.079197 Validation acc: 0.963333\n",
      "Epoch: 453/750 Iteration: 4085 Train loss: 0.052406 Train acc: 0.980000\n",
      "Epoch: 454/750 Iteration: 4090 Train loss: 0.099498 Train acc: 0.946667\n",
      "Epoch: 454/750 Iteration: 4090 Validation loss: 0.079167 Validation acc: 0.963889\n",
      "Epoch: 454/750 Iteration: 4095 Train loss: 0.071920 Train acc: 0.973333\n",
      "Epoch: 455/750 Iteration: 4100 Train loss: 0.077394 Train acc: 0.968333\n",
      "Epoch: 455/750 Iteration: 4100 Validation loss: 0.078896 Validation acc: 0.963889\n",
      "Epoch: 456/750 Iteration: 4105 Train loss: 0.069524 Train acc: 0.968333\n",
      "Epoch: 456/750 Iteration: 4110 Train loss: 0.066213 Train acc: 0.966667\n",
      "Epoch: 456/750 Iteration: 4110 Validation loss: 0.078547 Validation acc: 0.963889\n",
      "Epoch: 457/750 Iteration: 4115 Train loss: 0.067221 Train acc: 0.971667\n",
      "Epoch: 457/750 Iteration: 4120 Train loss: 0.074494 Train acc: 0.968333\n",
      "Epoch: 457/750 Iteration: 4120 Validation loss: 0.078759 Validation acc: 0.963889\n",
      "Epoch: 458/750 Iteration: 4125 Train loss: 0.089577 Train acc: 0.953333\n",
      "Epoch: 458/750 Iteration: 4130 Train loss: 0.055354 Train acc: 0.976667\n",
      "Epoch: 458/750 Iteration: 4130 Validation loss: 0.078856 Validation acc: 0.963889\n",
      "Epoch: 459/750 Iteration: 4135 Train loss: 0.101644 Train acc: 0.941667\n",
      "Epoch: 459/750 Iteration: 4140 Train loss: 0.073074 Train acc: 0.971667\n",
      "Epoch: 459/750 Iteration: 4140 Validation loss: 0.078541 Validation acc: 0.963333\n",
      "Epoch: 460/750 Iteration: 4145 Train loss: 0.079843 Train acc: 0.968333\n",
      "Epoch: 461/750 Iteration: 4150 Train loss: 0.071404 Train acc: 0.970000\n",
      "Epoch: 461/750 Iteration: 4150 Validation loss: 0.078255 Validation acc: 0.963889\n",
      "Epoch: 461/750 Iteration: 4155 Train loss: 0.072163 Train acc: 0.968333\n",
      "Epoch: 462/750 Iteration: 4160 Train loss: 0.066449 Train acc: 0.970000\n",
      "Epoch: 462/750 Iteration: 4160 Validation loss: 0.078057 Validation acc: 0.963333\n",
      "Epoch: 462/750 Iteration: 4165 Train loss: 0.081603 Train acc: 0.966667\n",
      "Epoch: 463/750 Iteration: 4170 Train loss: 0.092348 Train acc: 0.951667\n",
      "Epoch: 463/750 Iteration: 4170 Validation loss: 0.078112 Validation acc: 0.963333\n",
      "Epoch: 463/750 Iteration: 4175 Train loss: 0.051379 Train acc: 0.981667\n",
      "Epoch: 464/750 Iteration: 4180 Train loss: 0.108748 Train acc: 0.945000\n",
      "Epoch: 464/750 Iteration: 4180 Validation loss: 0.077847 Validation acc: 0.963889\n",
      "Epoch: 464/750 Iteration: 4185 Train loss: 0.073331 Train acc: 0.970000\n",
      "Epoch: 465/750 Iteration: 4190 Train loss: 0.080226 Train acc: 0.966667\n",
      "Epoch: 465/750 Iteration: 4190 Validation loss: 0.077473 Validation acc: 0.963889\n",
      "Epoch: 466/750 Iteration: 4195 Train loss: 0.066964 Train acc: 0.975000\n",
      "Epoch: 466/750 Iteration: 4200 Train loss: 0.067980 Train acc: 0.965000\n",
      "Epoch: 466/750 Iteration: 4200 Validation loss: 0.077341 Validation acc: 0.963889\n",
      "Epoch: 467/750 Iteration: 4205 Train loss: 0.066570 Train acc: 0.971667\n",
      "Epoch: 467/750 Iteration: 4210 Train loss: 0.076946 Train acc: 0.968333\n",
      "Epoch: 467/750 Iteration: 4210 Validation loss: 0.077602 Validation acc: 0.964444\n",
      "Epoch: 468/750 Iteration: 4215 Train loss: 0.098842 Train acc: 0.953333\n",
      "Epoch: 468/750 Iteration: 4220 Train loss: 0.047654 Train acc: 0.985000\n",
      "Epoch: 468/750 Iteration: 4220 Validation loss: 0.077412 Validation acc: 0.964444\n",
      "Epoch: 469/750 Iteration: 4225 Train loss: 0.093653 Train acc: 0.948333\n",
      "Epoch: 469/750 Iteration: 4230 Train loss: 0.072391 Train acc: 0.968333\n",
      "Epoch: 469/750 Iteration: 4230 Validation loss: 0.077295 Validation acc: 0.964444\n",
      "Epoch: 470/750 Iteration: 4235 Train loss: 0.075282 Train acc: 0.966667\n",
      "Epoch: 471/750 Iteration: 4240 Train loss: 0.069874 Train acc: 0.968333\n",
      "Epoch: 471/750 Iteration: 4240 Validation loss: 0.077195 Validation acc: 0.964444\n",
      "Epoch: 471/750 Iteration: 4245 Train loss: 0.066409 Train acc: 0.968333\n",
      "Epoch: 472/750 Iteration: 4250 Train loss: 0.068281 Train acc: 0.970000\n",
      "Epoch: 472/750 Iteration: 4250 Validation loss: 0.076650 Validation acc: 0.963889\n",
      "Epoch: 472/750 Iteration: 4255 Train loss: 0.073815 Train acc: 0.971667\n",
      "Epoch: 473/750 Iteration: 4260 Train loss: 0.089458 Train acc: 0.951667\n",
      "Epoch: 473/750 Iteration: 4260 Validation loss: 0.076751 Validation acc: 0.963333\n",
      "Epoch: 473/750 Iteration: 4265 Train loss: 0.049878 Train acc: 0.983333\n",
      "Epoch: 474/750 Iteration: 4270 Train loss: 0.096590 Train acc: 0.946667\n",
      "Epoch: 474/750 Iteration: 4270 Validation loss: 0.076939 Validation acc: 0.963889\n",
      "Epoch: 474/750 Iteration: 4275 Train loss: 0.069031 Train acc: 0.973333\n",
      "Epoch: 475/750 Iteration: 4280 Train loss: 0.077536 Train acc: 0.965000\n",
      "Epoch: 475/750 Iteration: 4280 Validation loss: 0.076147 Validation acc: 0.963889\n",
      "Epoch: 476/750 Iteration: 4285 Train loss: 0.069485 Train acc: 0.970000\n",
      "Epoch: 476/750 Iteration: 4290 Train loss: 0.067864 Train acc: 0.965000\n",
      "Epoch: 476/750 Iteration: 4290 Validation loss: 0.076760 Validation acc: 0.965000\n",
      "Epoch: 477/750 Iteration: 4295 Train loss: 0.064309 Train acc: 0.971667\n",
      "Epoch: 477/750 Iteration: 4300 Train loss: 0.072193 Train acc: 0.971667\n",
      "Epoch: 477/750 Iteration: 4300 Validation loss: 0.076509 Validation acc: 0.963889\n",
      "Epoch: 478/750 Iteration: 4305 Train loss: 0.087284 Train acc: 0.956667\n",
      "Epoch: 478/750 Iteration: 4310 Train loss: 0.048636 Train acc: 0.983333\n",
      "Epoch: 478/750 Iteration: 4310 Validation loss: 0.075690 Validation acc: 0.963889\n",
      "Epoch: 479/750 Iteration: 4315 Train loss: 0.098066 Train acc: 0.945000\n",
      "Epoch: 479/750 Iteration: 4320 Train loss: 0.072491 Train acc: 0.968333\n",
      "Epoch: 479/750 Iteration: 4320 Validation loss: 0.075717 Validation acc: 0.965000\n",
      "Epoch: 480/750 Iteration: 4325 Train loss: 0.074668 Train acc: 0.971667\n",
      "Epoch: 481/750 Iteration: 4330 Train loss: 0.067191 Train acc: 0.971667\n",
      "Epoch: 481/750 Iteration: 4330 Validation loss: 0.075703 Validation acc: 0.964444\n",
      "Epoch: 481/750 Iteration: 4335 Train loss: 0.064991 Train acc: 0.966667\n",
      "Epoch: 482/750 Iteration: 4340 Train loss: 0.062251 Train acc: 0.971667\n",
      "Epoch: 482/750 Iteration: 4340 Validation loss: 0.075531 Validation acc: 0.965000\n",
      "Epoch: 482/750 Iteration: 4345 Train loss: 0.075650 Train acc: 0.971667\n",
      "Epoch: 483/750 Iteration: 4350 Train loss: 0.092445 Train acc: 0.950000\n",
      "Epoch: 483/750 Iteration: 4350 Validation loss: 0.075162 Validation acc: 0.964444\n",
      "Epoch: 483/750 Iteration: 4355 Train loss: 0.046332 Train acc: 0.983333\n",
      "Epoch: 484/750 Iteration: 4360 Train loss: 0.094085 Train acc: 0.951667\n",
      "Epoch: 484/750 Iteration: 4360 Validation loss: 0.075401 Validation acc: 0.964444\n",
      "Epoch: 484/750 Iteration: 4365 Train loss: 0.068319 Train acc: 0.973333\n",
      "Epoch: 485/750 Iteration: 4370 Train loss: 0.077511 Train acc: 0.970000\n",
      "Epoch: 485/750 Iteration: 4370 Validation loss: 0.074904 Validation acc: 0.963889\n",
      "Epoch: 486/750 Iteration: 4375 Train loss: 0.072081 Train acc: 0.970000\n",
      "Epoch: 486/750 Iteration: 4380 Train loss: 0.066633 Train acc: 0.965000\n",
      "Epoch: 486/750 Iteration: 4380 Validation loss: 0.074983 Validation acc: 0.963333\n",
      "Epoch: 487/750 Iteration: 4385 Train loss: 0.063408 Train acc: 0.971667\n",
      "Epoch: 487/750 Iteration: 4390 Train loss: 0.071216 Train acc: 0.968333\n",
      "Epoch: 487/750 Iteration: 4390 Validation loss: 0.074839 Validation acc: 0.965000\n",
      "Epoch: 488/750 Iteration: 4395 Train loss: 0.089551 Train acc: 0.956667\n",
      "Epoch: 488/750 Iteration: 4400 Train loss: 0.047888 Train acc: 0.985000\n",
      "Epoch: 488/750 Iteration: 4400 Validation loss: 0.075044 Validation acc: 0.965000\n",
      "Epoch: 489/750 Iteration: 4405 Train loss: 0.092071 Train acc: 0.955000\n",
      "Epoch: 489/750 Iteration: 4410 Train loss: 0.068725 Train acc: 0.971667\n",
      "Epoch: 489/750 Iteration: 4410 Validation loss: 0.074815 Validation acc: 0.965000\n",
      "Epoch: 490/750 Iteration: 4415 Train loss: 0.076009 Train acc: 0.963333\n",
      "Epoch: 491/750 Iteration: 4420 Train loss: 0.065002 Train acc: 0.970000\n",
      "Epoch: 491/750 Iteration: 4420 Validation loss: 0.074105 Validation acc: 0.965000\n",
      "Epoch: 491/750 Iteration: 4425 Train loss: 0.061610 Train acc: 0.971667\n",
      "Epoch: 492/750 Iteration: 4430 Train loss: 0.061193 Train acc: 0.975000\n",
      "Epoch: 492/750 Iteration: 4430 Validation loss: 0.073918 Validation acc: 0.965555\n",
      "Epoch: 492/750 Iteration: 4435 Train loss: 0.074412 Train acc: 0.975000\n",
      "Epoch: 493/750 Iteration: 4440 Train loss: 0.087417 Train acc: 0.958333\n",
      "Epoch: 493/750 Iteration: 4440 Validation loss: 0.074887 Validation acc: 0.963889\n",
      "Epoch: 493/750 Iteration: 4445 Train loss: 0.047222 Train acc: 0.986667\n",
      "Epoch: 494/750 Iteration: 4450 Train loss: 0.096153 Train acc: 0.943333\n",
      "Epoch: 494/750 Iteration: 4450 Validation loss: 0.074009 Validation acc: 0.963333\n",
      "Epoch: 494/750 Iteration: 4455 Train loss: 0.067391 Train acc: 0.973333\n",
      "Epoch: 495/750 Iteration: 4460 Train loss: 0.076937 Train acc: 0.968333\n",
      "Epoch: 495/750 Iteration: 4460 Validation loss: 0.073639 Validation acc: 0.963889\n",
      "Epoch: 496/750 Iteration: 4465 Train loss: 0.065546 Train acc: 0.970000\n",
      "Epoch: 496/750 Iteration: 4470 Train loss: 0.060048 Train acc: 0.978333\n",
      "Epoch: 496/750 Iteration: 4470 Validation loss: 0.073966 Validation acc: 0.965000\n",
      "Epoch: 497/750 Iteration: 4475 Train loss: 0.061002 Train acc: 0.973333\n",
      "Epoch: 497/750 Iteration: 4480 Train loss: 0.066177 Train acc: 0.975000\n",
      "Epoch: 497/750 Iteration: 4480 Validation loss: 0.073985 Validation acc: 0.965000\n",
      "Epoch: 498/750 Iteration: 4485 Train loss: 0.082828 Train acc: 0.961667\n",
      "Epoch: 498/750 Iteration: 4490 Train loss: 0.046350 Train acc: 0.980000\n",
      "Epoch: 498/750 Iteration: 4490 Validation loss: 0.073451 Validation acc: 0.965555\n",
      "Epoch: 499/750 Iteration: 4495 Train loss: 0.095237 Train acc: 0.945000\n",
      "Epoch: 499/750 Iteration: 4500 Train loss: 0.071879 Train acc: 0.966667\n",
      "Epoch: 499/750 Iteration: 4500 Validation loss: 0.073514 Validation acc: 0.965555\n",
      "Epoch: 500/750 Iteration: 4505 Train loss: 0.072994 Train acc: 0.970000\n",
      "Epoch: 501/750 Iteration: 4510 Train loss: 0.067450 Train acc: 0.968333\n",
      "Epoch: 501/750 Iteration: 4510 Validation loss: 0.072919 Validation acc: 0.965555\n",
      "Epoch: 501/750 Iteration: 4515 Train loss: 0.062589 Train acc: 0.971667\n",
      "Epoch: 502/750 Iteration: 4520 Train loss: 0.059750 Train acc: 0.976667\n",
      "Epoch: 502/750 Iteration: 4520 Validation loss: 0.073522 Validation acc: 0.965555\n",
      "Epoch: 502/750 Iteration: 4525 Train loss: 0.066207 Train acc: 0.971667\n",
      "Epoch: 503/750 Iteration: 4530 Train loss: 0.084182 Train acc: 0.953333\n",
      "Epoch: 503/750 Iteration: 4530 Validation loss: 0.072565 Validation acc: 0.964444\n",
      "Epoch: 503/750 Iteration: 4535 Train loss: 0.050372 Train acc: 0.980000\n",
      "Epoch: 504/750 Iteration: 4540 Train loss: 0.097288 Train acc: 0.946667\n",
      "Epoch: 504/750 Iteration: 4540 Validation loss: 0.072741 Validation acc: 0.965000\n",
      "Epoch: 504/750 Iteration: 4545 Train loss: 0.069832 Train acc: 0.973333\n",
      "Epoch: 505/750 Iteration: 4550 Train loss: 0.074992 Train acc: 0.971667\n",
      "Epoch: 505/750 Iteration: 4550 Validation loss: 0.072697 Validation acc: 0.963889\n",
      "Epoch: 506/750 Iteration: 4555 Train loss: 0.061849 Train acc: 0.976667\n",
      "Epoch: 506/750 Iteration: 4560 Train loss: 0.061557 Train acc: 0.973333\n",
      "Epoch: 506/750 Iteration: 4560 Validation loss: 0.072235 Validation acc: 0.965000\n",
      "Epoch: 507/750 Iteration: 4565 Train loss: 0.058237 Train acc: 0.975000\n",
      "Epoch: 507/750 Iteration: 4570 Train loss: 0.070025 Train acc: 0.971667\n",
      "Epoch: 507/750 Iteration: 4570 Validation loss: 0.072422 Validation acc: 0.965555\n",
      "Epoch: 508/750 Iteration: 4575 Train loss: 0.083298 Train acc: 0.951667\n",
      "Epoch: 508/750 Iteration: 4580 Train loss: 0.047506 Train acc: 0.980000\n",
      "Epoch: 508/750 Iteration: 4580 Validation loss: 0.072842 Validation acc: 0.967222\n",
      "Epoch: 509/750 Iteration: 4585 Train loss: 0.094225 Train acc: 0.951667\n",
      "Epoch: 509/750 Iteration: 4590 Train loss: 0.071080 Train acc: 0.968333\n",
      "Epoch: 509/750 Iteration: 4590 Validation loss: 0.072262 Validation acc: 0.965000\n",
      "Epoch: 510/750 Iteration: 4595 Train loss: 0.077639 Train acc: 0.968333\n",
      "Epoch: 511/750 Iteration: 4600 Train loss: 0.065223 Train acc: 0.975000\n",
      "Epoch: 511/750 Iteration: 4600 Validation loss: 0.072367 Validation acc: 0.966111\n",
      "Epoch: 511/750 Iteration: 4605 Train loss: 0.064752 Train acc: 0.965000\n",
      "Epoch: 512/750 Iteration: 4610 Train loss: 0.060190 Train acc: 0.973333\n",
      "Epoch: 512/750 Iteration: 4610 Validation loss: 0.071943 Validation acc: 0.964444\n",
      "Epoch: 512/750 Iteration: 4615 Train loss: 0.071906 Train acc: 0.970000\n",
      "Epoch: 513/750 Iteration: 4620 Train loss: 0.088150 Train acc: 0.960000\n",
      "Epoch: 513/750 Iteration: 4620 Validation loss: 0.072843 Validation acc: 0.965000\n",
      "Epoch: 513/750 Iteration: 4625 Train loss: 0.048991 Train acc: 0.980000\n",
      "Epoch: 514/750 Iteration: 4630 Train loss: 0.090725 Train acc: 0.946667\n",
      "Epoch: 514/750 Iteration: 4630 Validation loss: 0.072016 Validation acc: 0.964444\n",
      "Epoch: 514/750 Iteration: 4635 Train loss: 0.065251 Train acc: 0.973333\n",
      "Epoch: 515/750 Iteration: 4640 Train loss: 0.071288 Train acc: 0.965000\n",
      "Epoch: 515/750 Iteration: 4640 Validation loss: 0.071328 Validation acc: 0.964444\n",
      "Epoch: 516/750 Iteration: 4645 Train loss: 0.060989 Train acc: 0.970000\n",
      "Epoch: 516/750 Iteration: 4650 Train loss: 0.062646 Train acc: 0.970000\n",
      "Epoch: 516/750 Iteration: 4650 Validation loss: 0.072015 Validation acc: 0.966111\n",
      "Epoch: 517/750 Iteration: 4655 Train loss: 0.060592 Train acc: 0.971667\n",
      "Epoch: 517/750 Iteration: 4660 Train loss: 0.064714 Train acc: 0.973333\n",
      "Epoch: 517/750 Iteration: 4660 Validation loss: 0.072492 Validation acc: 0.966667\n",
      "Epoch: 518/750 Iteration: 4665 Train loss: 0.082495 Train acc: 0.961667\n",
      "Epoch: 518/750 Iteration: 4670 Train loss: 0.049406 Train acc: 0.983333\n",
      "Epoch: 518/750 Iteration: 4670 Validation loss: 0.070996 Validation acc: 0.967222\n",
      "Epoch: 519/750 Iteration: 4675 Train loss: 0.095402 Train acc: 0.948333\n",
      "Epoch: 519/750 Iteration: 4680 Train loss: 0.067716 Train acc: 0.965000\n",
      "Epoch: 519/750 Iteration: 4680 Validation loss: 0.072051 Validation acc: 0.967222\n",
      "Epoch: 520/750 Iteration: 4685 Train loss: 0.069876 Train acc: 0.968333\n",
      "Epoch: 521/750 Iteration: 4690 Train loss: 0.065535 Train acc: 0.973333\n",
      "Epoch: 521/750 Iteration: 4690 Validation loss: 0.071147 Validation acc: 0.966667\n",
      "Epoch: 521/750 Iteration: 4695 Train loss: 0.060253 Train acc: 0.975000\n",
      "Epoch: 522/750 Iteration: 4700 Train loss: 0.060196 Train acc: 0.970000\n",
      "Epoch: 522/750 Iteration: 4700 Validation loss: 0.070996 Validation acc: 0.963889\n",
      "Epoch: 522/750 Iteration: 4705 Train loss: 0.071668 Train acc: 0.973333\n",
      "Epoch: 523/750 Iteration: 4710 Train loss: 0.084718 Train acc: 0.955000\n",
      "Epoch: 523/750 Iteration: 4710 Validation loss: 0.070883 Validation acc: 0.964444\n",
      "Epoch: 523/750 Iteration: 4715 Train loss: 0.043940 Train acc: 0.983333\n",
      "Epoch: 524/750 Iteration: 4720 Train loss: 0.098702 Train acc: 0.953333\n",
      "Epoch: 524/750 Iteration: 4720 Validation loss: 0.070734 Validation acc: 0.963333\n",
      "Epoch: 524/750 Iteration: 4725 Train loss: 0.070571 Train acc: 0.968333\n",
      "Epoch: 525/750 Iteration: 4730 Train loss: 0.075483 Train acc: 0.970000\n",
      "Epoch: 525/750 Iteration: 4730 Validation loss: 0.070500 Validation acc: 0.966667\n",
      "Epoch: 526/750 Iteration: 4735 Train loss: 0.064810 Train acc: 0.971667\n",
      "Epoch: 526/750 Iteration: 4740 Train loss: 0.061496 Train acc: 0.973333\n",
      "Epoch: 526/750 Iteration: 4740 Validation loss: 0.070619 Validation acc: 0.966667\n",
      "Epoch: 527/750 Iteration: 4745 Train loss: 0.060122 Train acc: 0.968333\n",
      "Epoch: 527/750 Iteration: 4750 Train loss: 0.069841 Train acc: 0.970000\n",
      "Epoch: 527/750 Iteration: 4750 Validation loss: 0.070527 Validation acc: 0.967222\n",
      "Epoch: 528/750 Iteration: 4755 Train loss: 0.089494 Train acc: 0.953333\n",
      "Epoch: 528/750 Iteration: 4760 Train loss: 0.042369 Train acc: 0.986667\n",
      "Epoch: 528/750 Iteration: 4760 Validation loss: 0.071040 Validation acc: 0.967222\n",
      "Epoch: 529/750 Iteration: 4765 Train loss: 0.102486 Train acc: 0.945000\n",
      "Epoch: 529/750 Iteration: 4770 Train loss: 0.066528 Train acc: 0.975000\n",
      "Epoch: 529/750 Iteration: 4770 Validation loss: 0.071054 Validation acc: 0.966111\n",
      "Epoch: 530/750 Iteration: 4775 Train loss: 0.074701 Train acc: 0.966667\n",
      "Epoch: 531/750 Iteration: 4780 Train loss: 0.055824 Train acc: 0.976667\n",
      "Epoch: 531/750 Iteration: 4780 Validation loss: 0.070396 Validation acc: 0.966667\n",
      "Epoch: 531/750 Iteration: 4785 Train loss: 0.059824 Train acc: 0.968333\n",
      "Epoch: 532/750 Iteration: 4790 Train loss: 0.054995 Train acc: 0.971667\n",
      "Epoch: 532/750 Iteration: 4790 Validation loss: 0.069734 Validation acc: 0.965000\n",
      "Epoch: 532/750 Iteration: 4795 Train loss: 0.060471 Train acc: 0.975000\n",
      "Epoch: 533/750 Iteration: 4800 Train loss: 0.080767 Train acc: 0.958333\n",
      "Epoch: 533/750 Iteration: 4800 Validation loss: 0.070165 Validation acc: 0.965000\n",
      "Epoch: 533/750 Iteration: 4805 Train loss: 0.046821 Train acc: 0.980000\n",
      "Epoch: 534/750 Iteration: 4810 Train loss: 0.095692 Train acc: 0.953333\n",
      "Epoch: 534/750 Iteration: 4810 Validation loss: 0.069879 Validation acc: 0.965000\n",
      "Epoch: 534/750 Iteration: 4815 Train loss: 0.068911 Train acc: 0.971667\n",
      "Epoch: 535/750 Iteration: 4820 Train loss: 0.068592 Train acc: 0.970000\n",
      "Epoch: 535/750 Iteration: 4820 Validation loss: 0.070328 Validation acc: 0.966667\n",
      "Epoch: 536/750 Iteration: 4825 Train loss: 0.062815 Train acc: 0.970000\n",
      "Epoch: 536/750 Iteration: 4830 Train loss: 0.056025 Train acc: 0.976667\n",
      "Epoch: 536/750 Iteration: 4830 Validation loss: 0.069985 Validation acc: 0.966667\n",
      "Epoch: 537/750 Iteration: 4835 Train loss: 0.057118 Train acc: 0.968333\n",
      "Epoch: 537/750 Iteration: 4840 Train loss: 0.064494 Train acc: 0.970000\n",
      "Epoch: 537/750 Iteration: 4840 Validation loss: 0.069639 Validation acc: 0.966667\n",
      "Epoch: 538/750 Iteration: 4845 Train loss: 0.082157 Train acc: 0.955000\n",
      "Epoch: 538/750 Iteration: 4850 Train loss: 0.047460 Train acc: 0.981667\n",
      "Epoch: 538/750 Iteration: 4850 Validation loss: 0.070108 Validation acc: 0.967778\n",
      "Epoch: 539/750 Iteration: 4855 Train loss: 0.095598 Train acc: 0.946667\n",
      "Epoch: 539/750 Iteration: 4860 Train loss: 0.068926 Train acc: 0.971667\n",
      "Epoch: 539/750 Iteration: 4860 Validation loss: 0.069598 Validation acc: 0.966111\n",
      "Epoch: 540/750 Iteration: 4865 Train loss: 0.071733 Train acc: 0.966667\n",
      "Epoch: 541/750 Iteration: 4870 Train loss: 0.060305 Train acc: 0.975000\n",
      "Epoch: 541/750 Iteration: 4870 Validation loss: 0.069316 Validation acc: 0.967222\n",
      "Epoch: 541/750 Iteration: 4875 Train loss: 0.058789 Train acc: 0.975000\n",
      "Epoch: 542/750 Iteration: 4880 Train loss: 0.061617 Train acc: 0.971667\n",
      "Epoch: 542/750 Iteration: 4880 Validation loss: 0.069642 Validation acc: 0.966667\n",
      "Epoch: 542/750 Iteration: 4885 Train loss: 0.071840 Train acc: 0.973333\n",
      "Epoch: 543/750 Iteration: 4890 Train loss: 0.083156 Train acc: 0.960000\n",
      "Epoch: 543/750 Iteration: 4890 Validation loss: 0.069188 Validation acc: 0.966667\n",
      "Epoch: 543/750 Iteration: 4895 Train loss: 0.042417 Train acc: 0.985000\n",
      "Epoch: 544/750 Iteration: 4900 Train loss: 0.095255 Train acc: 0.946667\n",
      "Epoch: 544/750 Iteration: 4900 Validation loss: 0.068845 Validation acc: 0.966667\n",
      "Epoch: 544/750 Iteration: 4905 Train loss: 0.061614 Train acc: 0.970000\n",
      "Epoch: 545/750 Iteration: 4910 Train loss: 0.070634 Train acc: 0.968333\n",
      "Epoch: 545/750 Iteration: 4910 Validation loss: 0.069012 Validation acc: 0.966111\n",
      "Epoch: 546/750 Iteration: 4915 Train loss: 0.055873 Train acc: 0.976667\n",
      "Epoch: 546/750 Iteration: 4920 Train loss: 0.057167 Train acc: 0.975000\n",
      "Epoch: 546/750 Iteration: 4920 Validation loss: 0.068787 Validation acc: 0.967222\n",
      "Epoch: 547/750 Iteration: 4925 Train loss: 0.055333 Train acc: 0.975000\n",
      "Epoch: 547/750 Iteration: 4930 Train loss: 0.070277 Train acc: 0.971667\n",
      "Epoch: 547/750 Iteration: 4930 Validation loss: 0.069212 Validation acc: 0.966667\n",
      "Epoch: 548/750 Iteration: 4935 Train loss: 0.079545 Train acc: 0.960000\n",
      "Epoch: 548/750 Iteration: 4940 Train loss: 0.045882 Train acc: 0.983333\n",
      "Epoch: 548/750 Iteration: 4940 Validation loss: 0.068970 Validation acc: 0.966667\n",
      "Epoch: 549/750 Iteration: 4945 Train loss: 0.098549 Train acc: 0.950000\n",
      "Epoch: 549/750 Iteration: 4950 Train loss: 0.062384 Train acc: 0.976667\n",
      "Epoch: 549/750 Iteration: 4950 Validation loss: 0.068549 Validation acc: 0.966667\n",
      "Epoch: 550/750 Iteration: 4955 Train loss: 0.068961 Train acc: 0.966667\n",
      "Epoch: 551/750 Iteration: 4960 Train loss: 0.062523 Train acc: 0.971667\n",
      "Epoch: 551/750 Iteration: 4960 Validation loss: 0.068358 Validation acc: 0.966667\n",
      "Epoch: 551/750 Iteration: 4965 Train loss: 0.057183 Train acc: 0.976667\n",
      "Epoch: 552/750 Iteration: 4970 Train loss: 0.060033 Train acc: 0.973333\n",
      "Epoch: 552/750 Iteration: 4970 Validation loss: 0.068173 Validation acc: 0.966667\n",
      "Epoch: 552/750 Iteration: 4975 Train loss: 0.066487 Train acc: 0.968333\n",
      "Epoch: 553/750 Iteration: 4980 Train loss: 0.082217 Train acc: 0.958333\n",
      "Epoch: 553/750 Iteration: 4980 Validation loss: 0.068284 Validation acc: 0.966111\n",
      "Epoch: 553/750 Iteration: 4985 Train loss: 0.040576 Train acc: 0.983333\n",
      "Epoch: 554/750 Iteration: 4990 Train loss: 0.099293 Train acc: 0.945000\n",
      "Epoch: 554/750 Iteration: 4990 Validation loss: 0.068260 Validation acc: 0.966667\n",
      "Epoch: 554/750 Iteration: 4995 Train loss: 0.063205 Train acc: 0.970000\n",
      "Epoch: 555/750 Iteration: 5000 Train loss: 0.072169 Train acc: 0.970000\n",
      "Epoch: 555/750 Iteration: 5000 Validation loss: 0.067946 Validation acc: 0.966111\n",
      "Epoch: 556/750 Iteration: 5005 Train loss: 0.061422 Train acc: 0.976667\n",
      "Epoch: 556/750 Iteration: 5010 Train loss: 0.057149 Train acc: 0.975000\n",
      "Epoch: 556/750 Iteration: 5010 Validation loss: 0.067962 Validation acc: 0.966111\n",
      "Epoch: 557/750 Iteration: 5015 Train loss: 0.053100 Train acc: 0.978333\n",
      "Epoch: 557/750 Iteration: 5020 Train loss: 0.066826 Train acc: 0.973333\n",
      "Epoch: 557/750 Iteration: 5020 Validation loss: 0.067751 Validation acc: 0.966111\n",
      "Epoch: 558/750 Iteration: 5025 Train loss: 0.083413 Train acc: 0.955000\n",
      "Epoch: 558/750 Iteration: 5030 Train loss: 0.043859 Train acc: 0.980000\n",
      "Epoch: 558/750 Iteration: 5030 Validation loss: 0.068039 Validation acc: 0.966111\n",
      "Epoch: 559/750 Iteration: 5035 Train loss: 0.094972 Train acc: 0.948333\n",
      "Epoch: 559/750 Iteration: 5040 Train loss: 0.061260 Train acc: 0.978333\n",
      "Epoch: 559/750 Iteration: 5040 Validation loss: 0.068378 Validation acc: 0.966111\n",
      "Epoch: 560/750 Iteration: 5045 Train loss: 0.071246 Train acc: 0.968333\n",
      "Epoch: 561/750 Iteration: 5050 Train loss: 0.065724 Train acc: 0.975000\n",
      "Epoch: 561/750 Iteration: 5050 Validation loss: 0.067574 Validation acc: 0.966111\n",
      "Epoch: 561/750 Iteration: 5055 Train loss: 0.056873 Train acc: 0.971667\n",
      "Epoch: 562/750 Iteration: 5060 Train loss: 0.054282 Train acc: 0.975000\n",
      "Epoch: 562/750 Iteration: 5060 Validation loss: 0.067366 Validation acc: 0.966667\n",
      "Epoch: 562/750 Iteration: 5065 Train loss: 0.068546 Train acc: 0.976667\n",
      "Epoch: 563/750 Iteration: 5070 Train loss: 0.079454 Train acc: 0.960000\n",
      "Epoch: 563/750 Iteration: 5070 Validation loss: 0.067248 Validation acc: 0.966667\n",
      "Epoch: 563/750 Iteration: 5075 Train loss: 0.044169 Train acc: 0.983333\n",
      "Epoch: 564/750 Iteration: 5080 Train loss: 0.092362 Train acc: 0.953333\n",
      "Epoch: 564/750 Iteration: 5080 Validation loss: 0.067784 Validation acc: 0.965555\n",
      "Epoch: 564/750 Iteration: 5085 Train loss: 0.056863 Train acc: 0.973333\n",
      "Epoch: 565/750 Iteration: 5090 Train loss: 0.070194 Train acc: 0.970000\n",
      "Epoch: 565/750 Iteration: 5090 Validation loss: 0.067574 Validation acc: 0.966111\n",
      "Epoch: 566/750 Iteration: 5095 Train loss: 0.061338 Train acc: 0.976667\n",
      "Epoch: 566/750 Iteration: 5100 Train loss: 0.055064 Train acc: 0.973333\n",
      "Epoch: 566/750 Iteration: 5100 Validation loss: 0.067050 Validation acc: 0.966111\n",
      "Epoch: 567/750 Iteration: 5105 Train loss: 0.052100 Train acc: 0.975000\n",
      "Epoch: 567/750 Iteration: 5110 Train loss: 0.063746 Train acc: 0.973333\n",
      "Epoch: 567/750 Iteration: 5110 Validation loss: 0.066809 Validation acc: 0.965555\n",
      "Epoch: 568/750 Iteration: 5115 Train loss: 0.083728 Train acc: 0.955000\n",
      "Epoch: 568/750 Iteration: 5120 Train loss: 0.038442 Train acc: 0.985000\n",
      "Epoch: 568/750 Iteration: 5120 Validation loss: 0.067015 Validation acc: 0.967222\n",
      "Epoch: 569/750 Iteration: 5125 Train loss: 0.082786 Train acc: 0.951667\n",
      "Epoch: 569/750 Iteration: 5130 Train loss: 0.060484 Train acc: 0.975000\n",
      "Epoch: 569/750 Iteration: 5130 Validation loss: 0.067718 Validation acc: 0.967222\n",
      "Epoch: 570/750 Iteration: 5135 Train loss: 0.073738 Train acc: 0.968333\n",
      "Epoch: 571/750 Iteration: 5140 Train loss: 0.061281 Train acc: 0.973333\n",
      "Epoch: 571/750 Iteration: 5140 Validation loss: 0.067314 Validation acc: 0.966111\n",
      "Epoch: 571/750 Iteration: 5145 Train loss: 0.059204 Train acc: 0.971667\n",
      "Epoch: 572/750 Iteration: 5150 Train loss: 0.055194 Train acc: 0.975000\n",
      "Epoch: 572/750 Iteration: 5150 Validation loss: 0.066794 Validation acc: 0.966111\n",
      "Epoch: 572/750 Iteration: 5155 Train loss: 0.060196 Train acc: 0.970000\n",
      "Epoch: 573/750 Iteration: 5160 Train loss: 0.075789 Train acc: 0.961667\n",
      "Epoch: 573/750 Iteration: 5160 Validation loss: 0.066357 Validation acc: 0.966111\n",
      "Epoch: 573/750 Iteration: 5165 Train loss: 0.039607 Train acc: 0.986667\n",
      "Epoch: 574/750 Iteration: 5170 Train loss: 0.091757 Train acc: 0.950000\n",
      "Epoch: 574/750 Iteration: 5170 Validation loss: 0.066778 Validation acc: 0.966667\n",
      "Epoch: 574/750 Iteration: 5175 Train loss: 0.058163 Train acc: 0.980000\n",
      "Epoch: 575/750 Iteration: 5180 Train loss: 0.068499 Train acc: 0.965000\n",
      "Epoch: 575/750 Iteration: 5180 Validation loss: 0.066648 Validation acc: 0.966111\n",
      "Epoch: 576/750 Iteration: 5185 Train loss: 0.054364 Train acc: 0.980000\n",
      "Epoch: 576/750 Iteration: 5190 Train loss: 0.056311 Train acc: 0.973333\n",
      "Epoch: 576/750 Iteration: 5190 Validation loss: 0.066679 Validation acc: 0.966111\n",
      "Epoch: 577/750 Iteration: 5195 Train loss: 0.055870 Train acc: 0.975000\n",
      "Epoch: 577/750 Iteration: 5200 Train loss: 0.059524 Train acc: 0.973333\n",
      "Epoch: 577/750 Iteration: 5200 Validation loss: 0.066633 Validation acc: 0.966667\n",
      "Epoch: 578/750 Iteration: 5205 Train loss: 0.082364 Train acc: 0.950000\n",
      "Epoch: 578/750 Iteration: 5210 Train loss: 0.041170 Train acc: 0.986667\n",
      "Epoch: 578/750 Iteration: 5210 Validation loss: 0.065945 Validation acc: 0.967222\n",
      "Epoch: 579/750 Iteration: 5215 Train loss: 0.087312 Train acc: 0.951667\n",
      "Epoch: 579/750 Iteration: 5220 Train loss: 0.059781 Train acc: 0.971667\n",
      "Epoch: 579/750 Iteration: 5220 Validation loss: 0.066206 Validation acc: 0.966667\n",
      "Epoch: 580/750 Iteration: 5225 Train loss: 0.071777 Train acc: 0.968333\n",
      "Epoch: 581/750 Iteration: 5230 Train loss: 0.056530 Train acc: 0.978333\n",
      "Epoch: 581/750 Iteration: 5230 Validation loss: 0.067043 Validation acc: 0.965555\n",
      "Epoch: 581/750 Iteration: 5235 Train loss: 0.055227 Train acc: 0.976667\n",
      "Epoch: 582/750 Iteration: 5240 Train loss: 0.054687 Train acc: 0.980000\n",
      "Epoch: 582/750 Iteration: 5240 Validation loss: 0.065959 Validation acc: 0.967222\n",
      "Epoch: 582/750 Iteration: 5245 Train loss: 0.060666 Train acc: 0.970000\n",
      "Epoch: 583/750 Iteration: 5250 Train loss: 0.075877 Train acc: 0.965000\n",
      "Epoch: 583/750 Iteration: 5250 Validation loss: 0.066318 Validation acc: 0.967222\n",
      "Epoch: 583/750 Iteration: 5255 Train loss: 0.038759 Train acc: 0.985000\n",
      "Epoch: 584/750 Iteration: 5260 Train loss: 0.093805 Train acc: 0.955000\n",
      "Epoch: 584/750 Iteration: 5260 Validation loss: 0.066044 Validation acc: 0.966111\n",
      "Epoch: 584/750 Iteration: 5265 Train loss: 0.058742 Train acc: 0.980000\n",
      "Epoch: 585/750 Iteration: 5270 Train loss: 0.067720 Train acc: 0.970000\n",
      "Epoch: 585/750 Iteration: 5270 Validation loss: 0.066055 Validation acc: 0.966667\n",
      "Epoch: 586/750 Iteration: 5275 Train loss: 0.063285 Train acc: 0.971667\n",
      "Epoch: 586/750 Iteration: 5280 Train loss: 0.057543 Train acc: 0.970000\n",
      "Epoch: 586/750 Iteration: 5280 Validation loss: 0.065595 Validation acc: 0.968333\n",
      "Epoch: 587/750 Iteration: 5285 Train loss: 0.054910 Train acc: 0.973333\n",
      "Epoch: 587/750 Iteration: 5290 Train loss: 0.063521 Train acc: 0.970000\n",
      "Epoch: 587/750 Iteration: 5290 Validation loss: 0.065490 Validation acc: 0.967778\n",
      "Epoch: 588/750 Iteration: 5295 Train loss: 0.078121 Train acc: 0.961667\n",
      "Epoch: 588/750 Iteration: 5300 Train loss: 0.037517 Train acc: 0.988333\n",
      "Epoch: 588/750 Iteration: 5300 Validation loss: 0.065690 Validation acc: 0.966667\n",
      "Epoch: 589/750 Iteration: 5305 Train loss: 0.093608 Train acc: 0.950000\n",
      "Epoch: 589/750 Iteration: 5310 Train loss: 0.059364 Train acc: 0.968333\n",
      "Epoch: 589/750 Iteration: 5310 Validation loss: 0.065807 Validation acc: 0.967222\n",
      "Epoch: 590/750 Iteration: 5315 Train loss: 0.065424 Train acc: 0.975000\n",
      "Epoch: 591/750 Iteration: 5320 Train loss: 0.056274 Train acc: 0.975000\n",
      "Epoch: 591/750 Iteration: 5320 Validation loss: 0.065688 Validation acc: 0.967222\n",
      "Epoch: 591/750 Iteration: 5325 Train loss: 0.050917 Train acc: 0.978333\n",
      "Epoch: 592/750 Iteration: 5330 Train loss: 0.053774 Train acc: 0.975000\n",
      "Epoch: 592/750 Iteration: 5330 Validation loss: 0.065498 Validation acc: 0.966667\n",
      "Epoch: 592/750 Iteration: 5335 Train loss: 0.057024 Train acc: 0.975000\n",
      "Epoch: 593/750 Iteration: 5340 Train loss: 0.077212 Train acc: 0.958333\n",
      "Epoch: 593/750 Iteration: 5340 Validation loss: 0.065002 Validation acc: 0.967222\n",
      "Epoch: 593/750 Iteration: 5345 Train loss: 0.042489 Train acc: 0.985000\n",
      "Epoch: 594/750 Iteration: 5350 Train loss: 0.088665 Train acc: 0.953333\n",
      "Epoch: 594/750 Iteration: 5350 Validation loss: 0.066082 Validation acc: 0.965555\n",
      "Epoch: 594/750 Iteration: 5355 Train loss: 0.058559 Train acc: 0.973333\n",
      "Epoch: 595/750 Iteration: 5360 Train loss: 0.064496 Train acc: 0.971667\n",
      "Epoch: 595/750 Iteration: 5360 Validation loss: 0.065592 Validation acc: 0.965000\n",
      "Epoch: 596/750 Iteration: 5365 Train loss: 0.059774 Train acc: 0.978333\n",
      "Epoch: 596/750 Iteration: 5370 Train loss: 0.059165 Train acc: 0.973333\n",
      "Epoch: 596/750 Iteration: 5370 Validation loss: 0.065120 Validation acc: 0.967778\n",
      "Epoch: 597/750 Iteration: 5375 Train loss: 0.057757 Train acc: 0.973333\n",
      "Epoch: 597/750 Iteration: 5380 Train loss: 0.064771 Train acc: 0.971667\n",
      "Epoch: 597/750 Iteration: 5380 Validation loss: 0.065538 Validation acc: 0.967778\n",
      "Epoch: 598/750 Iteration: 5385 Train loss: 0.074034 Train acc: 0.961667\n",
      "Epoch: 598/750 Iteration: 5390 Train loss: 0.037917 Train acc: 0.985000\n",
      "Epoch: 598/750 Iteration: 5390 Validation loss: 0.064825 Validation acc: 0.967222\n",
      "Epoch: 599/750 Iteration: 5395 Train loss: 0.084667 Train acc: 0.961667\n",
      "Epoch: 599/750 Iteration: 5400 Train loss: 0.059046 Train acc: 0.971667\n",
      "Epoch: 599/750 Iteration: 5400 Validation loss: 0.065322 Validation acc: 0.966111\n",
      "Epoch: 600/750 Iteration: 5405 Train loss: 0.069549 Train acc: 0.970000\n",
      "Epoch: 601/750 Iteration: 5410 Train loss: 0.058454 Train acc: 0.975000\n",
      "Epoch: 601/750 Iteration: 5410 Validation loss: 0.064690 Validation acc: 0.967222\n",
      "Epoch: 601/750 Iteration: 5415 Train loss: 0.051907 Train acc: 0.980000\n",
      "Epoch: 602/750 Iteration: 5420 Train loss: 0.045437 Train acc: 0.980000\n",
      "Epoch: 602/750 Iteration: 5420 Validation loss: 0.064444 Validation acc: 0.967778\n",
      "Epoch: 602/750 Iteration: 5425 Train loss: 0.054887 Train acc: 0.975000\n",
      "Epoch: 603/750 Iteration: 5430 Train loss: 0.077145 Train acc: 0.960000\n",
      "Epoch: 603/750 Iteration: 5430 Validation loss: 0.064366 Validation acc: 0.966667\n",
      "Epoch: 603/750 Iteration: 5435 Train loss: 0.035750 Train acc: 0.985000\n",
      "Epoch: 604/750 Iteration: 5440 Train loss: 0.092572 Train acc: 0.953333\n",
      "Epoch: 604/750 Iteration: 5440 Validation loss: 0.064595 Validation acc: 0.966111\n",
      "Epoch: 604/750 Iteration: 5445 Train loss: 0.054733 Train acc: 0.980000\n",
      "Epoch: 605/750 Iteration: 5450 Train loss: 0.068266 Train acc: 0.975000\n",
      "Epoch: 605/750 Iteration: 5450 Validation loss: 0.064375 Validation acc: 0.967778\n",
      "Epoch: 606/750 Iteration: 5455 Train loss: 0.062568 Train acc: 0.978333\n",
      "Epoch: 606/750 Iteration: 5460 Train loss: 0.053111 Train acc: 0.978333\n",
      "Epoch: 606/750 Iteration: 5460 Validation loss: 0.064440 Validation acc: 0.968333\n",
      "Epoch: 607/750 Iteration: 5465 Train loss: 0.055778 Train acc: 0.978333\n",
      "Epoch: 607/750 Iteration: 5470 Train loss: 0.059615 Train acc: 0.976667\n",
      "Epoch: 607/750 Iteration: 5470 Validation loss: 0.064769 Validation acc: 0.966667\n",
      "Epoch: 608/750 Iteration: 5475 Train loss: 0.077937 Train acc: 0.956667\n",
      "Epoch: 608/750 Iteration: 5480 Train loss: 0.037640 Train acc: 0.983333\n",
      "Epoch: 608/750 Iteration: 5480 Validation loss: 0.064118 Validation acc: 0.967778\n",
      "Epoch: 609/750 Iteration: 5485 Train loss: 0.084225 Train acc: 0.953333\n",
      "Epoch: 609/750 Iteration: 5490 Train loss: 0.057091 Train acc: 0.976667\n",
      "Epoch: 609/750 Iteration: 5490 Validation loss: 0.064565 Validation acc: 0.967778\n",
      "Epoch: 610/750 Iteration: 5495 Train loss: 0.067473 Train acc: 0.966667\n",
      "Epoch: 611/750 Iteration: 5500 Train loss: 0.053779 Train acc: 0.983333\n",
      "Epoch: 611/750 Iteration: 5500 Validation loss: 0.064987 Validation acc: 0.967778\n",
      "Epoch: 611/750 Iteration: 5505 Train loss: 0.053125 Train acc: 0.973333\n",
      "Epoch: 612/750 Iteration: 5510 Train loss: 0.049113 Train acc: 0.978333\n",
      "Epoch: 612/750 Iteration: 5510 Validation loss: 0.063963 Validation acc: 0.967222\n",
      "Epoch: 612/750 Iteration: 5515 Train loss: 0.057794 Train acc: 0.971667\n",
      "Epoch: 613/750 Iteration: 5520 Train loss: 0.075312 Train acc: 0.965000\n",
      "Epoch: 613/750 Iteration: 5520 Validation loss: 0.064276 Validation acc: 0.966667\n",
      "Epoch: 613/750 Iteration: 5525 Train loss: 0.037821 Train acc: 0.988333\n",
      "Epoch: 614/750 Iteration: 5530 Train loss: 0.089638 Train acc: 0.958333\n",
      "Epoch: 614/750 Iteration: 5530 Validation loss: 0.064069 Validation acc: 0.968333\n",
      "Epoch: 614/750 Iteration: 5535 Train loss: 0.057209 Train acc: 0.971667\n",
      "Epoch: 615/750 Iteration: 5540 Train loss: 0.064519 Train acc: 0.970000\n",
      "Epoch: 615/750 Iteration: 5540 Validation loss: 0.064581 Validation acc: 0.965000\n",
      "Epoch: 616/750 Iteration: 5545 Train loss: 0.061426 Train acc: 0.971667\n",
      "Epoch: 616/750 Iteration: 5550 Train loss: 0.049645 Train acc: 0.981667\n",
      "Epoch: 616/750 Iteration: 5550 Validation loss: 0.063790 Validation acc: 0.967222\n",
      "Epoch: 617/750 Iteration: 5555 Train loss: 0.051761 Train acc: 0.975000\n",
      "Epoch: 617/750 Iteration: 5560 Train loss: 0.063937 Train acc: 0.970000\n",
      "Epoch: 617/750 Iteration: 5560 Validation loss: 0.064118 Validation acc: 0.967778\n",
      "Epoch: 618/750 Iteration: 5565 Train loss: 0.073140 Train acc: 0.960000\n",
      "Epoch: 618/750 Iteration: 5570 Train loss: 0.036818 Train acc: 0.985000\n",
      "Epoch: 618/750 Iteration: 5570 Validation loss: 0.063749 Validation acc: 0.967222\n",
      "Epoch: 619/750 Iteration: 5575 Train loss: 0.080555 Train acc: 0.956667\n",
      "Epoch: 619/750 Iteration: 5580 Train loss: 0.060677 Train acc: 0.966667\n",
      "Epoch: 619/750 Iteration: 5580 Validation loss: 0.064424 Validation acc: 0.966111\n",
      "Epoch: 620/750 Iteration: 5585 Train loss: 0.064505 Train acc: 0.973333\n",
      "Epoch: 621/750 Iteration: 5590 Train loss: 0.056606 Train acc: 0.975000\n",
      "Epoch: 621/750 Iteration: 5590 Validation loss: 0.063694 Validation acc: 0.967222\n",
      "Epoch: 621/750 Iteration: 5595 Train loss: 0.052197 Train acc: 0.976667\n",
      "Epoch: 622/750 Iteration: 5600 Train loss: 0.048548 Train acc: 0.976667\n",
      "Epoch: 622/750 Iteration: 5600 Validation loss: 0.064345 Validation acc: 0.967222\n",
      "Epoch: 622/750 Iteration: 5605 Train loss: 0.059646 Train acc: 0.970000\n",
      "Epoch: 623/750 Iteration: 5610 Train loss: 0.076809 Train acc: 0.955000\n",
      "Epoch: 623/750 Iteration: 5610 Validation loss: 0.064031 Validation acc: 0.965555\n",
      "Epoch: 623/750 Iteration: 5615 Train loss: 0.037686 Train acc: 0.985000\n",
      "Epoch: 624/750 Iteration: 5620 Train loss: 0.084641 Train acc: 0.958333\n",
      "Epoch: 624/750 Iteration: 5620 Validation loss: 0.064202 Validation acc: 0.967222\n",
      "Epoch: 624/750 Iteration: 5625 Train loss: 0.058153 Train acc: 0.976667\n",
      "Epoch: 625/750 Iteration: 5630 Train loss: 0.069089 Train acc: 0.968333\n",
      "Epoch: 625/750 Iteration: 5630 Validation loss: 0.063864 Validation acc: 0.967778\n",
      "Epoch: 626/750 Iteration: 5635 Train loss: 0.054144 Train acc: 0.980000\n",
      "Epoch: 626/750 Iteration: 5640 Train loss: 0.054548 Train acc: 0.976667\n",
      "Epoch: 626/750 Iteration: 5640 Validation loss: 0.063128 Validation acc: 0.967778\n",
      "Epoch: 627/750 Iteration: 5645 Train loss: 0.054875 Train acc: 0.975000\n",
      "Epoch: 627/750 Iteration: 5650 Train loss: 0.057116 Train acc: 0.973333\n",
      "Epoch: 627/750 Iteration: 5650 Validation loss: 0.063329 Validation acc: 0.967222\n",
      "Epoch: 628/750 Iteration: 5655 Train loss: 0.073692 Train acc: 0.961667\n",
      "Epoch: 628/750 Iteration: 5660 Train loss: 0.036876 Train acc: 0.985000\n",
      "Epoch: 628/750 Iteration: 5660 Validation loss: 0.063757 Validation acc: 0.966667\n",
      "Epoch: 629/750 Iteration: 5665 Train loss: 0.079942 Train acc: 0.960000\n",
      "Epoch: 629/750 Iteration: 5670 Train loss: 0.057183 Train acc: 0.976667\n",
      "Epoch: 629/750 Iteration: 5670 Validation loss: 0.063128 Validation acc: 0.967222\n",
      "Epoch: 630/750 Iteration: 5675 Train loss: 0.065101 Train acc: 0.968333\n",
      "Epoch: 631/750 Iteration: 5680 Train loss: 0.059078 Train acc: 0.978333\n",
      "Epoch: 631/750 Iteration: 5680 Validation loss: 0.063727 Validation acc: 0.968333\n",
      "Epoch: 631/750 Iteration: 5685 Train loss: 0.052023 Train acc: 0.973333\n",
      "Epoch: 632/750 Iteration: 5690 Train loss: 0.050273 Train acc: 0.976667\n",
      "Epoch: 632/750 Iteration: 5690 Validation loss: 0.063547 Validation acc: 0.968333\n",
      "Epoch: 632/750 Iteration: 5695 Train loss: 0.054146 Train acc: 0.973333\n",
      "Epoch: 633/750 Iteration: 5700 Train loss: 0.070784 Train acc: 0.958333\n",
      "Epoch: 633/750 Iteration: 5700 Validation loss: 0.063182 Validation acc: 0.968333\n",
      "Epoch: 633/750 Iteration: 5705 Train loss: 0.035105 Train acc: 0.985000\n",
      "Epoch: 634/750 Iteration: 5710 Train loss: 0.081975 Train acc: 0.961667\n",
      "Epoch: 634/750 Iteration: 5710 Validation loss: 0.062881 Validation acc: 0.968333\n",
      "Epoch: 634/750 Iteration: 5715 Train loss: 0.056122 Train acc: 0.968333\n",
      "Epoch: 635/750 Iteration: 5720 Train loss: 0.068819 Train acc: 0.968333\n",
      "Epoch: 635/750 Iteration: 5720 Validation loss: 0.062802 Validation acc: 0.968333\n",
      "Epoch: 636/750 Iteration: 5725 Train loss: 0.057293 Train acc: 0.973333\n",
      "Epoch: 636/750 Iteration: 5730 Train loss: 0.051268 Train acc: 0.976667\n",
      "Epoch: 636/750 Iteration: 5730 Validation loss: 0.062698 Validation acc: 0.966667\n",
      "Epoch: 637/750 Iteration: 5735 Train loss: 0.047524 Train acc: 0.981667\n",
      "Epoch: 637/750 Iteration: 5740 Train loss: 0.055931 Train acc: 0.971667\n",
      "Epoch: 637/750 Iteration: 5740 Validation loss: 0.063168 Validation acc: 0.968333\n",
      "Epoch: 638/750 Iteration: 5745 Train loss: 0.073829 Train acc: 0.963333\n",
      "Epoch: 638/750 Iteration: 5750 Train loss: 0.033084 Train acc: 0.990000\n",
      "Epoch: 638/750 Iteration: 5750 Validation loss: 0.063111 Validation acc: 0.968333\n",
      "Epoch: 639/750 Iteration: 5755 Train loss: 0.080611 Train acc: 0.960000\n",
      "Epoch: 639/750 Iteration: 5760 Train loss: 0.055798 Train acc: 0.971667\n",
      "Epoch: 639/750 Iteration: 5760 Validation loss: 0.062726 Validation acc: 0.968333\n",
      "Epoch: 640/750 Iteration: 5765 Train loss: 0.059782 Train acc: 0.968333\n",
      "Epoch: 641/750 Iteration: 5770 Train loss: 0.053768 Train acc: 0.980000\n",
      "Epoch: 641/750 Iteration: 5770 Validation loss: 0.062801 Validation acc: 0.968333\n",
      "Epoch: 641/750 Iteration: 5775 Train loss: 0.047740 Train acc: 0.981667\n",
      "Epoch: 642/750 Iteration: 5780 Train loss: 0.044838 Train acc: 0.981667\n",
      "Epoch: 642/750 Iteration: 5780 Validation loss: 0.062334 Validation acc: 0.967778\n",
      "Epoch: 642/750 Iteration: 5785 Train loss: 0.055303 Train acc: 0.971667\n",
      "Epoch: 643/750 Iteration: 5790 Train loss: 0.072338 Train acc: 0.958333\n",
      "Epoch: 643/750 Iteration: 5790 Validation loss: 0.062489 Validation acc: 0.967222\n",
      "Epoch: 643/750 Iteration: 5795 Train loss: 0.035325 Train acc: 0.988333\n",
      "Epoch: 644/750 Iteration: 5800 Train loss: 0.082403 Train acc: 0.955000\n",
      "Epoch: 644/750 Iteration: 5800 Validation loss: 0.062897 Validation acc: 0.968333\n",
      "Epoch: 644/750 Iteration: 5805 Train loss: 0.059663 Train acc: 0.973333\n",
      "Epoch: 645/750 Iteration: 5810 Train loss: 0.062152 Train acc: 0.973333\n",
      "Epoch: 645/750 Iteration: 5810 Validation loss: 0.062062 Validation acc: 0.970000\n",
      "Epoch: 646/750 Iteration: 5815 Train loss: 0.049030 Train acc: 0.978333\n",
      "Epoch: 646/750 Iteration: 5820 Train loss: 0.048561 Train acc: 0.981667\n",
      "Epoch: 646/750 Iteration: 5820 Validation loss: 0.062866 Validation acc: 0.968333\n",
      "Epoch: 647/750 Iteration: 5825 Train loss: 0.044168 Train acc: 0.983333\n",
      "Epoch: 647/750 Iteration: 5830 Train loss: 0.055697 Train acc: 0.975000\n",
      "Epoch: 647/750 Iteration: 5830 Validation loss: 0.062510 Validation acc: 0.968889\n",
      "Epoch: 648/750 Iteration: 5835 Train loss: 0.071001 Train acc: 0.961667\n",
      "Epoch: 648/750 Iteration: 5840 Train loss: 0.036897 Train acc: 0.986667\n",
      "Epoch: 648/750 Iteration: 5840 Validation loss: 0.061921 Validation acc: 0.969444\n",
      "Epoch: 649/750 Iteration: 5845 Train loss: 0.081579 Train acc: 0.956667\n",
      "Epoch: 649/750 Iteration: 5850 Train loss: 0.053627 Train acc: 0.973333\n",
      "Epoch: 649/750 Iteration: 5850 Validation loss: 0.062202 Validation acc: 0.968333\n",
      "Epoch: 650/750 Iteration: 5855 Train loss: 0.062499 Train acc: 0.970000\n",
      "Epoch: 651/750 Iteration: 5860 Train loss: 0.053024 Train acc: 0.980000\n",
      "Epoch: 651/750 Iteration: 5860 Validation loss: 0.062629 Validation acc: 0.967222\n",
      "Epoch: 651/750 Iteration: 5865 Train loss: 0.050591 Train acc: 0.976667\n",
      "Epoch: 652/750 Iteration: 5870 Train loss: 0.047781 Train acc: 0.976667\n",
      "Epoch: 652/750 Iteration: 5870 Validation loss: 0.062480 Validation acc: 0.970556\n",
      "Epoch: 652/750 Iteration: 5875 Train loss: 0.056551 Train acc: 0.968333\n",
      "Epoch: 653/750 Iteration: 5880 Train loss: 0.073452 Train acc: 0.961667\n",
      "Epoch: 653/750 Iteration: 5880 Validation loss: 0.062206 Validation acc: 0.967778\n",
      "Epoch: 653/750 Iteration: 5885 Train loss: 0.037410 Train acc: 0.985000\n",
      "Epoch: 654/750 Iteration: 5890 Train loss: 0.081976 Train acc: 0.953333\n",
      "Epoch: 654/750 Iteration: 5890 Validation loss: 0.061774 Validation acc: 0.968889\n",
      "Epoch: 654/750 Iteration: 5895 Train loss: 0.056900 Train acc: 0.975000\n",
      "Epoch: 655/750 Iteration: 5900 Train loss: 0.065568 Train acc: 0.971667\n",
      "Epoch: 655/750 Iteration: 5900 Validation loss: 0.061681 Validation acc: 0.970000\n",
      "Epoch: 656/750 Iteration: 5905 Train loss: 0.052997 Train acc: 0.980000\n",
      "Epoch: 656/750 Iteration: 5910 Train loss: 0.052037 Train acc: 0.980000\n",
      "Epoch: 656/750 Iteration: 5910 Validation loss: 0.061706 Validation acc: 0.969444\n",
      "Epoch: 657/750 Iteration: 5915 Train loss: 0.043326 Train acc: 0.976667\n",
      "Epoch: 657/750 Iteration: 5920 Train loss: 0.050971 Train acc: 0.976667\n",
      "Epoch: 657/750 Iteration: 5920 Validation loss: 0.061483 Validation acc: 0.968333\n",
      "Epoch: 658/750 Iteration: 5925 Train loss: 0.075961 Train acc: 0.960000\n",
      "Epoch: 658/750 Iteration: 5930 Train loss: 0.037639 Train acc: 0.985000\n",
      "Epoch: 658/750 Iteration: 5930 Validation loss: 0.061433 Validation acc: 0.968333\n",
      "Epoch: 659/750 Iteration: 5935 Train loss: 0.077300 Train acc: 0.961667\n",
      "Epoch: 659/750 Iteration: 5940 Train loss: 0.053856 Train acc: 0.976667\n",
      "Epoch: 659/750 Iteration: 5940 Validation loss: 0.061680 Validation acc: 0.967778\n",
      "Epoch: 660/750 Iteration: 5945 Train loss: 0.064843 Train acc: 0.966667\n",
      "Epoch: 661/750 Iteration: 5950 Train loss: 0.054116 Train acc: 0.980000\n",
      "Epoch: 661/750 Iteration: 5950 Validation loss: 0.063680 Validation acc: 0.969444\n",
      "Epoch: 661/750 Iteration: 5955 Train loss: 0.051880 Train acc: 0.976667\n",
      "Epoch: 662/750 Iteration: 5960 Train loss: 0.046911 Train acc: 0.981667\n",
      "Epoch: 662/750 Iteration: 5960 Validation loss: 0.062323 Validation acc: 0.968333\n",
      "Epoch: 662/750 Iteration: 5965 Train loss: 0.056677 Train acc: 0.973333\n",
      "Epoch: 663/750 Iteration: 5970 Train loss: 0.071001 Train acc: 0.965000\n",
      "Epoch: 663/750 Iteration: 5970 Validation loss: 0.061044 Validation acc: 0.969444\n",
      "Epoch: 663/750 Iteration: 5975 Train loss: 0.034606 Train acc: 0.986667\n",
      "Epoch: 664/750 Iteration: 5980 Train loss: 0.082367 Train acc: 0.958333\n",
      "Epoch: 664/750 Iteration: 5980 Validation loss: 0.061805 Validation acc: 0.968889\n",
      "Epoch: 664/750 Iteration: 5985 Train loss: 0.051005 Train acc: 0.980000\n",
      "Epoch: 665/750 Iteration: 5990 Train loss: 0.068760 Train acc: 0.963333\n",
      "Epoch: 665/750 Iteration: 5990 Validation loss: 0.061021 Validation acc: 0.970000\n",
      "Epoch: 666/750 Iteration: 5995 Train loss: 0.055144 Train acc: 0.973333\n",
      "Epoch: 666/750 Iteration: 6000 Train loss: 0.051185 Train acc: 0.978333\n",
      "Epoch: 666/750 Iteration: 6000 Validation loss: 0.061219 Validation acc: 0.970000\n",
      "Epoch: 667/750 Iteration: 6005 Train loss: 0.046223 Train acc: 0.978333\n",
      "Epoch: 667/750 Iteration: 6010 Train loss: 0.053400 Train acc: 0.978333\n",
      "Epoch: 667/750 Iteration: 6010 Validation loss: 0.061955 Validation acc: 0.968333\n",
      "Epoch: 668/750 Iteration: 6015 Train loss: 0.078694 Train acc: 0.955000\n",
      "Epoch: 668/750 Iteration: 6020 Train loss: 0.034249 Train acc: 0.988333\n",
      "Epoch: 668/750 Iteration: 6020 Validation loss: 0.061492 Validation acc: 0.968889\n",
      "Epoch: 669/750 Iteration: 6025 Train loss: 0.087668 Train acc: 0.958333\n",
      "Epoch: 669/750 Iteration: 6030 Train loss: 0.051640 Train acc: 0.976667\n",
      "Epoch: 669/750 Iteration: 6030 Validation loss: 0.061717 Validation acc: 0.968889\n",
      "Epoch: 670/750 Iteration: 6035 Train loss: 0.066588 Train acc: 0.970000\n",
      "Epoch: 671/750 Iteration: 6040 Train loss: 0.051435 Train acc: 0.971667\n",
      "Epoch: 671/750 Iteration: 6040 Validation loss: 0.061541 Validation acc: 0.969444\n",
      "Epoch: 671/750 Iteration: 6045 Train loss: 0.045553 Train acc: 0.983333\n",
      "Epoch: 672/750 Iteration: 6050 Train loss: 0.047124 Train acc: 0.980000\n",
      "Epoch: 672/750 Iteration: 6050 Validation loss: 0.063092 Validation acc: 0.967778\n",
      "Epoch: 672/750 Iteration: 6055 Train loss: 0.049609 Train acc: 0.976667\n",
      "Epoch: 673/750 Iteration: 6060 Train loss: 0.074575 Train acc: 0.960000\n",
      "Epoch: 673/750 Iteration: 6060 Validation loss: 0.060707 Validation acc: 0.970000\n",
      "Epoch: 673/750 Iteration: 6065 Train loss: 0.035441 Train acc: 0.986667\n",
      "Epoch: 674/750 Iteration: 6070 Train loss: 0.080248 Train acc: 0.953333\n",
      "Epoch: 674/750 Iteration: 6070 Validation loss: 0.060640 Validation acc: 0.970000\n",
      "Epoch: 674/750 Iteration: 6075 Train loss: 0.051383 Train acc: 0.980000\n",
      "Epoch: 675/750 Iteration: 6080 Train loss: 0.061355 Train acc: 0.975000\n",
      "Epoch: 675/750 Iteration: 6080 Validation loss: 0.060896 Validation acc: 0.970555\n",
      "Epoch: 676/750 Iteration: 6085 Train loss: 0.048186 Train acc: 0.980000\n",
      "Epoch: 676/750 Iteration: 6090 Train loss: 0.049227 Train acc: 0.983333\n",
      "Epoch: 676/750 Iteration: 6090 Validation loss: 0.061261 Validation acc: 0.970556\n",
      "Epoch: 677/750 Iteration: 6095 Train loss: 0.042289 Train acc: 0.983333\n",
      "Epoch: 677/750 Iteration: 6100 Train loss: 0.056334 Train acc: 0.971667\n",
      "Epoch: 677/750 Iteration: 6100 Validation loss: 0.060487 Validation acc: 0.968889\n",
      "Epoch: 678/750 Iteration: 6105 Train loss: 0.067975 Train acc: 0.963333\n",
      "Epoch: 678/750 Iteration: 6110 Train loss: 0.037311 Train acc: 0.985000\n",
      "Epoch: 678/750 Iteration: 6110 Validation loss: 0.060703 Validation acc: 0.970000\n",
      "Epoch: 679/750 Iteration: 6115 Train loss: 0.083338 Train acc: 0.955000\n",
      "Epoch: 679/750 Iteration: 6120 Train loss: 0.054038 Train acc: 0.970000\n",
      "Epoch: 679/750 Iteration: 6120 Validation loss: 0.060938 Validation acc: 0.971111\n",
      "Epoch: 680/750 Iteration: 6125 Train loss: 0.059836 Train acc: 0.973333\n",
      "Epoch: 681/750 Iteration: 6130 Train loss: 0.051872 Train acc: 0.981667\n",
      "Epoch: 681/750 Iteration: 6130 Validation loss: 0.060857 Validation acc: 0.971111\n",
      "Epoch: 681/750 Iteration: 6135 Train loss: 0.048198 Train acc: 0.978333\n",
      "Epoch: 682/750 Iteration: 6140 Train loss: 0.044359 Train acc: 0.981667\n",
      "Epoch: 682/750 Iteration: 6140 Validation loss: 0.060412 Validation acc: 0.970000\n",
      "Epoch: 682/750 Iteration: 6145 Train loss: 0.052776 Train acc: 0.973333\n",
      "Epoch: 683/750 Iteration: 6150 Train loss: 0.070817 Train acc: 0.958333\n",
      "Epoch: 683/750 Iteration: 6150 Validation loss: 0.060443 Validation acc: 0.967222\n",
      "Epoch: 683/750 Iteration: 6155 Train loss: 0.033792 Train acc: 0.988333\n",
      "Epoch: 684/750 Iteration: 6160 Train loss: 0.076903 Train acc: 0.958333\n",
      "Epoch: 684/750 Iteration: 6160 Validation loss: 0.060281 Validation acc: 0.970556\n",
      "Epoch: 684/750 Iteration: 6165 Train loss: 0.052142 Train acc: 0.976667\n",
      "Epoch: 685/750 Iteration: 6170 Train loss: 0.064867 Train acc: 0.970000\n",
      "Epoch: 685/750 Iteration: 6170 Validation loss: 0.060123 Validation acc: 0.970000\n",
      "Epoch: 686/750 Iteration: 6175 Train loss: 0.051264 Train acc: 0.980000\n",
      "Epoch: 686/750 Iteration: 6180 Train loss: 0.051002 Train acc: 0.980000\n",
      "Epoch: 686/750 Iteration: 6180 Validation loss: 0.060347 Validation acc: 0.970556\n",
      "Epoch: 687/750 Iteration: 6185 Train loss: 0.044892 Train acc: 0.981667\n",
      "Epoch: 687/750 Iteration: 6190 Train loss: 0.054374 Train acc: 0.973333\n",
      "Epoch: 687/750 Iteration: 6190 Validation loss: 0.060371 Validation acc: 0.970000\n",
      "Epoch: 688/750 Iteration: 6195 Train loss: 0.069222 Train acc: 0.966667\n",
      "Epoch: 688/750 Iteration: 6200 Train loss: 0.028797 Train acc: 0.991667\n",
      "Epoch: 688/750 Iteration: 6200 Validation loss: 0.060162 Validation acc: 0.971667\n",
      "Epoch: 689/750 Iteration: 6205 Train loss: 0.078262 Train acc: 0.958333\n",
      "Epoch: 689/750 Iteration: 6210 Train loss: 0.052605 Train acc: 0.978333\n",
      "Epoch: 689/750 Iteration: 6210 Validation loss: 0.060462 Validation acc: 0.971667\n",
      "Epoch: 690/750 Iteration: 6215 Train loss: 0.056780 Train acc: 0.973333\n",
      "Epoch: 691/750 Iteration: 6220 Train loss: 0.044698 Train acc: 0.980000\n",
      "Epoch: 691/750 Iteration: 6220 Validation loss: 0.060414 Validation acc: 0.972222\n",
      "Epoch: 691/750 Iteration: 6225 Train loss: 0.053382 Train acc: 0.973333\n",
      "Epoch: 692/750 Iteration: 6230 Train loss: 0.041775 Train acc: 0.983333\n",
      "Epoch: 692/750 Iteration: 6230 Validation loss: 0.060341 Validation acc: 0.970555\n",
      "Epoch: 692/750 Iteration: 6235 Train loss: 0.048679 Train acc: 0.980000\n",
      "Epoch: 693/750 Iteration: 6240 Train loss: 0.077363 Train acc: 0.961667\n",
      "Epoch: 693/750 Iteration: 6240 Validation loss: 0.059590 Validation acc: 0.970556\n",
      "Epoch: 693/750 Iteration: 6245 Train loss: 0.034272 Train acc: 0.988333\n",
      "Epoch: 694/750 Iteration: 6250 Train loss: 0.075527 Train acc: 0.960000\n",
      "Epoch: 694/750 Iteration: 6250 Validation loss: 0.059657 Validation acc: 0.971111\n",
      "Epoch: 694/750 Iteration: 6255 Train loss: 0.047035 Train acc: 0.980000\n",
      "Epoch: 695/750 Iteration: 6260 Train loss: 0.056469 Train acc: 0.975000\n",
      "Epoch: 695/750 Iteration: 6260 Validation loss: 0.060297 Validation acc: 0.971111\n",
      "Epoch: 696/750 Iteration: 6265 Train loss: 0.049226 Train acc: 0.981667\n",
      "Epoch: 696/750 Iteration: 6270 Train loss: 0.048430 Train acc: 0.981667\n",
      "Epoch: 696/750 Iteration: 6270 Validation loss: 0.060285 Validation acc: 0.972222\n",
      "Epoch: 697/750 Iteration: 6275 Train loss: 0.045044 Train acc: 0.980000\n",
      "Epoch: 697/750 Iteration: 6280 Train loss: 0.055221 Train acc: 0.971667\n",
      "Epoch: 697/750 Iteration: 6280 Validation loss: 0.059663 Validation acc: 0.972222\n",
      "Epoch: 698/750 Iteration: 6285 Train loss: 0.067511 Train acc: 0.968333\n",
      "Epoch: 698/750 Iteration: 6290 Train loss: 0.032434 Train acc: 0.990000\n",
      "Epoch: 698/750 Iteration: 6290 Validation loss: 0.059902 Validation acc: 0.970000\n",
      "Epoch: 699/750 Iteration: 6295 Train loss: 0.074408 Train acc: 0.961667\n",
      "Epoch: 699/750 Iteration: 6300 Train loss: 0.048797 Train acc: 0.980000\n",
      "Epoch: 699/750 Iteration: 6300 Validation loss: 0.059392 Validation acc: 0.972222\n",
      "Epoch: 700/750 Iteration: 6305 Train loss: 0.059179 Train acc: 0.975000\n",
      "Epoch: 701/750 Iteration: 6310 Train loss: 0.054499 Train acc: 0.980000\n",
      "Epoch: 701/750 Iteration: 6310 Validation loss: 0.059585 Validation acc: 0.970555\n",
      "Epoch: 701/750 Iteration: 6315 Train loss: 0.047706 Train acc: 0.980000\n",
      "Epoch: 702/750 Iteration: 6320 Train loss: 0.043184 Train acc: 0.976667\n",
      "Epoch: 702/750 Iteration: 6320 Validation loss: 0.059925 Validation acc: 0.971667\n",
      "Epoch: 702/750 Iteration: 6325 Train loss: 0.045946 Train acc: 0.978333\n",
      "Epoch: 703/750 Iteration: 6330 Train loss: 0.068884 Train acc: 0.963333\n",
      "Epoch: 703/750 Iteration: 6330 Validation loss: 0.059679 Validation acc: 0.971667\n",
      "Epoch: 703/750 Iteration: 6335 Train loss: 0.035129 Train acc: 0.986667\n",
      "Epoch: 704/750 Iteration: 6340 Train loss: 0.072467 Train acc: 0.963333\n",
      "Epoch: 704/750 Iteration: 6340 Validation loss: 0.059576 Validation acc: 0.972222\n",
      "Epoch: 704/750 Iteration: 6345 Train loss: 0.046409 Train acc: 0.981667\n",
      "Epoch: 705/750 Iteration: 6350 Train loss: 0.058637 Train acc: 0.970000\n",
      "Epoch: 705/750 Iteration: 6350 Validation loss: 0.059342 Validation acc: 0.972222\n",
      "Epoch: 706/750 Iteration: 6355 Train loss: 0.050236 Train acc: 0.980000\n",
      "Epoch: 706/750 Iteration: 6360 Train loss: 0.048001 Train acc: 0.980000\n",
      "Epoch: 706/750 Iteration: 6360 Validation loss: 0.059523 Validation acc: 0.971667\n",
      "Epoch: 707/750 Iteration: 6365 Train loss: 0.042437 Train acc: 0.983333\n",
      "Epoch: 707/750 Iteration: 6370 Train loss: 0.045457 Train acc: 0.980000\n",
      "Epoch: 707/750 Iteration: 6370 Validation loss: 0.059531 Validation acc: 0.972222\n",
      "Epoch: 708/750 Iteration: 6375 Train loss: 0.066727 Train acc: 0.963333\n",
      "Epoch: 708/750 Iteration: 6380 Train loss: 0.032867 Train acc: 0.985000\n",
      "Epoch: 708/750 Iteration: 6380 Validation loss: 0.059998 Validation acc: 0.971667\n",
      "Epoch: 709/750 Iteration: 6385 Train loss: 0.079226 Train acc: 0.956667\n",
      "Epoch: 709/750 Iteration: 6390 Train loss: 0.044168 Train acc: 0.986667\n",
      "Epoch: 709/750 Iteration: 6390 Validation loss: 0.059336 Validation acc: 0.970556\n",
      "Epoch: 710/750 Iteration: 6395 Train loss: 0.057413 Train acc: 0.970000\n",
      "Epoch: 711/750 Iteration: 6400 Train loss: 0.047540 Train acc: 0.978333\n",
      "Epoch: 711/750 Iteration: 6400 Validation loss: 0.059475 Validation acc: 0.972222\n",
      "Epoch: 711/750 Iteration: 6405 Train loss: 0.048880 Train acc: 0.978333\n",
      "Epoch: 712/750 Iteration: 6410 Train loss: 0.044476 Train acc: 0.978333\n",
      "Epoch: 712/750 Iteration: 6410 Validation loss: 0.059937 Validation acc: 0.970555\n",
      "Epoch: 712/750 Iteration: 6415 Train loss: 0.052333 Train acc: 0.975000\n",
      "Epoch: 713/750 Iteration: 6420 Train loss: 0.065290 Train acc: 0.965000\n",
      "Epoch: 713/750 Iteration: 6420 Validation loss: 0.059196 Validation acc: 0.972222\n",
      "Epoch: 713/750 Iteration: 6425 Train loss: 0.032450 Train acc: 0.990000\n",
      "Epoch: 714/750 Iteration: 6430 Train loss: 0.079472 Train acc: 0.960000\n",
      "Epoch: 714/750 Iteration: 6430 Validation loss: 0.060866 Validation acc: 0.971111\n",
      "Epoch: 714/750 Iteration: 6435 Train loss: 0.043409 Train acc: 0.978333\n",
      "Epoch: 715/750 Iteration: 6440 Train loss: 0.058408 Train acc: 0.970000\n",
      "Epoch: 715/750 Iteration: 6440 Validation loss: 0.059334 Validation acc: 0.971667\n",
      "Epoch: 716/750 Iteration: 6445 Train loss: 0.048012 Train acc: 0.981667\n",
      "Epoch: 716/750 Iteration: 6450 Train loss: 0.046014 Train acc: 0.981667\n",
      "Epoch: 716/750 Iteration: 6450 Validation loss: 0.059295 Validation acc: 0.972222\n",
      "Epoch: 717/750 Iteration: 6455 Train loss: 0.038168 Train acc: 0.983333\n",
      "Epoch: 717/750 Iteration: 6460 Train loss: 0.049168 Train acc: 0.978333\n",
      "Epoch: 717/750 Iteration: 6460 Validation loss: 0.059492 Validation acc: 0.971111\n",
      "Epoch: 718/750 Iteration: 6465 Train loss: 0.066644 Train acc: 0.965000\n",
      "Epoch: 718/750 Iteration: 6470 Train loss: 0.030548 Train acc: 0.990000\n",
      "Epoch: 718/750 Iteration: 6470 Validation loss: 0.060421 Validation acc: 0.968889\n",
      "Epoch: 719/750 Iteration: 6475 Train loss: 0.075924 Train acc: 0.960000\n",
      "Epoch: 719/750 Iteration: 6480 Train loss: 0.048745 Train acc: 0.980000\n",
      "Epoch: 719/750 Iteration: 6480 Validation loss: 0.060573 Validation acc: 0.971111\n",
      "Epoch: 720/750 Iteration: 6485 Train loss: 0.054601 Train acc: 0.973333\n",
      "Epoch: 721/750 Iteration: 6490 Train loss: 0.051391 Train acc: 0.983333\n",
      "Epoch: 721/750 Iteration: 6490 Validation loss: 0.059342 Validation acc: 0.972778\n",
      "Epoch: 721/750 Iteration: 6495 Train loss: 0.050165 Train acc: 0.983333\n",
      "Epoch: 722/750 Iteration: 6500 Train loss: 0.040664 Train acc: 0.978333\n",
      "Epoch: 722/750 Iteration: 6500 Validation loss: 0.058430 Validation acc: 0.972778\n",
      "Epoch: 722/750 Iteration: 6505 Train loss: 0.050132 Train acc: 0.973333\n",
      "Epoch: 723/750 Iteration: 6510 Train loss: 0.071161 Train acc: 0.966667\n",
      "Epoch: 723/750 Iteration: 6510 Validation loss: 0.059003 Validation acc: 0.972778\n",
      "Epoch: 723/750 Iteration: 6515 Train loss: 0.034453 Train acc: 0.985000\n",
      "Epoch: 724/750 Iteration: 6520 Train loss: 0.076501 Train acc: 0.958333\n",
      "Epoch: 724/750 Iteration: 6520 Validation loss: 0.059298 Validation acc: 0.971111\n",
      "Epoch: 724/750 Iteration: 6525 Train loss: 0.052191 Train acc: 0.970000\n",
      "Epoch: 725/750 Iteration: 6530 Train loss: 0.059180 Train acc: 0.973333\n",
      "Epoch: 725/750 Iteration: 6530 Validation loss: 0.058637 Validation acc: 0.971667\n",
      "Epoch: 726/750 Iteration: 6535 Train loss: 0.049894 Train acc: 0.983333\n",
      "Epoch: 726/750 Iteration: 6540 Train loss: 0.044802 Train acc: 0.985000\n",
      "Epoch: 726/750 Iteration: 6540 Validation loss: 0.060271 Validation acc: 0.971667\n",
      "Epoch: 727/750 Iteration: 6545 Train loss: 0.041702 Train acc: 0.980000\n",
      "Epoch: 727/750 Iteration: 6550 Train loss: 0.046515 Train acc: 0.976667\n",
      "Epoch: 727/750 Iteration: 6550 Validation loss: 0.059396 Validation acc: 0.971111\n",
      "Epoch: 728/750 Iteration: 6555 Train loss: 0.067370 Train acc: 0.965000\n",
      "Epoch: 728/750 Iteration: 6560 Train loss: 0.031338 Train acc: 0.988333\n",
      "Epoch: 728/750 Iteration: 6560 Validation loss: 0.058987 Validation acc: 0.972778\n",
      "Epoch: 729/750 Iteration: 6565 Train loss: 0.078355 Train acc: 0.960000\n",
      "Epoch: 729/750 Iteration: 6570 Train loss: 0.045347 Train acc: 0.981667\n",
      "Epoch: 729/750 Iteration: 6570 Validation loss: 0.058690 Validation acc: 0.972778\n",
      "Epoch: 730/750 Iteration: 6575 Train loss: 0.053579 Train acc: 0.973333\n",
      "Epoch: 731/750 Iteration: 6580 Train loss: 0.052285 Train acc: 0.973333\n",
      "Epoch: 731/750 Iteration: 6580 Validation loss: 0.059216 Validation acc: 0.971111\n",
      "Epoch: 731/750 Iteration: 6585 Train loss: 0.045117 Train acc: 0.983333\n",
      "Epoch: 732/750 Iteration: 6590 Train loss: 0.041075 Train acc: 0.980000\n",
      "Epoch: 732/750 Iteration: 6590 Validation loss: 0.058355 Validation acc: 0.972778\n",
      "Epoch: 732/750 Iteration: 6595 Train loss: 0.048484 Train acc: 0.975000\n",
      "Epoch: 733/750 Iteration: 6600 Train loss: 0.064981 Train acc: 0.970000\n",
      "Epoch: 733/750 Iteration: 6600 Validation loss: 0.058527 Validation acc: 0.972222\n",
      "Epoch: 733/750 Iteration: 6605 Train loss: 0.031491 Train acc: 0.985000\n",
      "Epoch: 734/750 Iteration: 6610 Train loss: 0.073230 Train acc: 0.968333\n",
      "Epoch: 734/750 Iteration: 6610 Validation loss: 0.058168 Validation acc: 0.973889\n",
      "Epoch: 734/750 Iteration: 6615 Train loss: 0.047376 Train acc: 0.980000\n",
      "Epoch: 735/750 Iteration: 6620 Train loss: 0.059403 Train acc: 0.973333\n",
      "Epoch: 735/750 Iteration: 6620 Validation loss: 0.057761 Validation acc: 0.973333\n",
      "Epoch: 736/750 Iteration: 6625 Train loss: 0.050384 Train acc: 0.975000\n",
      "Epoch: 736/750 Iteration: 6630 Train loss: 0.050926 Train acc: 0.980000\n",
      "Epoch: 736/750 Iteration: 6630 Validation loss: 0.058364 Validation acc: 0.972222\n",
      "Epoch: 737/750 Iteration: 6635 Train loss: 0.043343 Train acc: 0.981667\n",
      "Epoch: 737/750 Iteration: 6640 Train loss: 0.050025 Train acc: 0.978333\n",
      "Epoch: 737/750 Iteration: 6640 Validation loss: 0.058577 Validation acc: 0.973333\n",
      "Epoch: 738/750 Iteration: 6645 Train loss: 0.064650 Train acc: 0.965000\n",
      "Epoch: 738/750 Iteration: 6650 Train loss: 0.030757 Train acc: 0.985000\n",
      "Epoch: 738/750 Iteration: 6650 Validation loss: 0.058551 Validation acc: 0.973333\n",
      "Epoch: 739/750 Iteration: 6655 Train loss: 0.077908 Train acc: 0.960000\n",
      "Epoch: 739/750 Iteration: 6660 Train loss: 0.045320 Train acc: 0.976667\n",
      "Epoch: 739/750 Iteration: 6660 Validation loss: 0.059292 Validation acc: 0.972778\n",
      "Epoch: 740/750 Iteration: 6665 Train loss: 0.063439 Train acc: 0.966667\n",
      "Epoch: 741/750 Iteration: 6670 Train loss: 0.048207 Train acc: 0.981667\n",
      "Epoch: 741/750 Iteration: 6670 Validation loss: 0.058946 Validation acc: 0.971111\n",
      "Epoch: 741/750 Iteration: 6675 Train loss: 0.044592 Train acc: 0.985000\n",
      "Epoch: 742/750 Iteration: 6680 Train loss: 0.039080 Train acc: 0.981667\n",
      "Epoch: 742/750 Iteration: 6680 Validation loss: 0.058001 Validation acc: 0.973889\n",
      "Epoch: 742/750 Iteration: 6685 Train loss: 0.046780 Train acc: 0.978333\n",
      "Epoch: 743/750 Iteration: 6690 Train loss: 0.068812 Train acc: 0.963333\n",
      "Epoch: 743/750 Iteration: 6690 Validation loss: 0.058008 Validation acc: 0.973333\n",
      "Epoch: 743/750 Iteration: 6695 Train loss: 0.030718 Train acc: 0.986667\n",
      "Epoch: 744/750 Iteration: 6700 Train loss: 0.077871 Train acc: 0.965000\n",
      "Epoch: 744/750 Iteration: 6700 Validation loss: 0.059005 Validation acc: 0.969444\n",
      "Epoch: 744/750 Iteration: 6705 Train loss: 0.054988 Train acc: 0.968333\n",
      "Epoch: 745/750 Iteration: 6710 Train loss: 0.057548 Train acc: 0.973333\n",
      "Epoch: 745/750 Iteration: 6710 Validation loss: 0.058941 Validation acc: 0.971111\n",
      "Epoch: 746/750 Iteration: 6715 Train loss: 0.051722 Train acc: 0.980000\n",
      "Epoch: 746/750 Iteration: 6720 Train loss: 0.047341 Train acc: 0.975000\n",
      "Epoch: 746/750 Iteration: 6720 Validation loss: 0.058578 Validation acc: 0.972222\n",
      "Epoch: 747/750 Iteration: 6725 Train loss: 0.035744 Train acc: 0.985000\n",
      "Epoch: 747/750 Iteration: 6730 Train loss: 0.061141 Train acc: 0.973333\n",
      "Epoch: 747/750 Iteration: 6730 Validation loss: 0.057780 Validation acc: 0.972778\n",
      "Epoch: 748/750 Iteration: 6735 Train loss: 0.069822 Train acc: 0.965000\n",
      "Epoch: 748/750 Iteration: 6740 Train loss: 0.031761 Train acc: 0.986667\n",
      "Epoch: 748/750 Iteration: 6740 Validation loss: 0.058456 Validation acc: 0.972222\n",
      "Epoch: 749/750 Iteration: 6745 Train loss: 0.075187 Train acc: 0.960000\n",
      "Epoch: 749/750 Iteration: 6750 Train loss: 0.041597 Train acc: 0.983333\n",
      "Epoch: 749/750 Iteration: 6750 Validation loss: 0.058803 Validation acc: 0.972778\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAF3CAYAAABkPHbIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxxLmG8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc14951d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAF3CAYAAAC7cgzXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW9//HXJyEhAYMgUEFRQMQFFEHRYrUq1tZdq7WK\ny68Va3Ft1S63eO/V9koXrbWtWkTRql2sSwUVrdZW61JssYAiBRTZJWUxoiBCAlk+vz++M5lJMplM\nQiYz4byfj8c85pwz58z5JITzOee7mrsjIiLSnIJcByAiIvlNiUJERNJSohARkbSUKEREJC0lChER\nSUuJQkRE0lKiEBGRtJQoREQkLSUKERFJS4lCRETS6pLrAFqrT58+PmjQoFyHISLSqcydO/cDd+/b\nlmM7XaIYNGgQc+bMyXUYIiKdipmtauuxKnoSEZG0lChERCQtJQoREUmr09VRiMjOpbq6mvLycqqq\nqnIdyk6hpKSEAQMGUFRU1G7fqUQhIjlVXl5OWVkZgwYNwsxyHU6n5u5s2LCB8vJyBg8e3G7fq6In\nEcmpqqoqevfurSTRDsyM3r17t/vTWdYShZndb2bvm9mCZj43M7vDzJaa2XwzOzRbsYhIflOSaD/Z\n+F1m84niQeCkNJ+fDAyNvSYAU7IYi4hIShs3buSuu+5q9XGnnHIKGzduzEJE+SdricLdXwU+TLPL\nmcBvPZgF9DSz/tmKR0QkleYSRW1tbdrjnn32WXr27JmtsPJKLiuz9wRWJ62Xx7atzU04IhJFEydO\nZNmyZYwcOZKioiJ22WUX+vfvz7x581i0aBFf/OIXWb16NVVVVVxzzTVMmDABSIwS8cknn3DyySdz\n9NFH849//IM999yTp556itLS0hz/ZO0nl4kiVUGap9zRbAKheIq99947mzGJSC5dey3Mm9e+3zly\nJPzyl81+fPPNN7NgwQLmzZvHyy+/zKmnnsqCBQvqWw3df//97LbbblRWVnL44YfzpS99id69ezf4\njiVLlvDwww9z7733cu655zJt2jQuuuii9v05ciiXrZ7Kgb2S1gcAa1Lt6O5T3X20u4/u27dNY1qJ\niGTkiCOOaNC09I477uCQQw5hzJgxrF69miVLljQ5ZvDgwYwcORKAww47jJUrV4YP3GEn6B+SyyeK\nGcDVZvYI8Glgk7ur2EkkytLc+aflscKITFv81NU1u2/37t3DQlUVLz/9NC+88AL//Oc/6VZaynFj\nx1K1eTO8916DY7oWFsLHH0OPHhQWFlK5dSvU1sKbb4YdRoyA4uIQ57p1UFYG3bs3jCEekxmsWQM9\ne0JJCZSXQ//+0I4d6Fora4nCzB4GjgP6mFk58H2gCMDd7waeBU4BlgJbgfHZikVEWqGuDqZOhfHj\noWvX1h3rDvfcA1/9KiSX0a9eDa+/Dueck/q4zZuhoCBxwd9ll8Rn27fDqlUwaBBUV8OHH8Juu0G3\nbuHzTz6BFStg2zYYOBD69GmaBD7+GLp0Ccds3QqLFoV93CkrKmLzpk2wcSNs2hQ+d4d332XTe+/R\nq7SUbh9+yDuzZjHrn/+E5cuhV6/we3rnnXDe6mp4910oLAzxrl2bSBIANTVh/wVJvQUKCsLP0atX\neOpYHauyjce4JqmA5f334eCDW//v0U6ylijc/fwWPnfgqmydX0RiXn0Vjj46XJhSeeABuOSSxHqP\nHuHCuno1/OhHcOutMHkyfPvb8M1vhn1Wrgyv/faDPfYI237xC9h7b7jiCnj88XDcxo1w/PENz/fP\nf8KRR4bvuv12qKyExYtb/jneeiuxvG5dSESVlQ33WbUqvDIRS0q9q6s5avhwDjrsMEq7dmX33r1h\n7lwATjrySO6eNo0RY8ey/8CBjDnooMTxNTXhAr91a2JbbS2sX9/0XIsWNd1WVwcffBBeyZK/L9m/\n/x1+3z16ZPbztSNzT1l/nLdGjx7tmo9Cdiru4Y5x993T77dtW7gw9uwZLka9eoXjdt013MnW1MAz\nz4Q72zfegPPOg6uuCnfJAKeeCrfdFu72X389bLvjjsTFv7EjjoAlS+Cjj9rvZ03h7eee48A+fbJ6\njp1GWRnsv3+Lu7399tsceOCBDbaZ2Vx3H92W02qsJ5GO9v778Otfw8SJIUnsu28oOnnzzdBCB8Ld\n+pNPhqKaRx8NF4jLLgufFRSEu9FkZWWh+CbZ0083XP/Tn8IrWXNJAuBf/2r1jyY7ZiulvMP+dGU7\nFmsEajj7sowiqne+oieRjNTWwrRp8OUvZ1YRWVERiiBOOGHHzrtsWXjk//SnwwW6pCSUgT//fPj8\npJPCXfpTT4XPjjkm8cj/pz/BaaeFIp0ePUIl47Bh4S6/X7+wz+DBISGccQZ8/vPhrn7MmHC++JPD\nzJnw7LOJmEaNSsQ2ZEhYvu66prE3ThLQNElIq22niOXswxCWh4tyClspZTH7M5CVrGIQQ1hGOQOo\noiTtdzvgFGDU1fcLKKKabXSt3xbfB6CShn0w3uJgCnAOKPmEbjv2Y7aJEoVk5oMPwoXuqadg+PBQ\ngXjYYfDDH8KJJ6YuN920KZRHn3hiwyQwdmy4YN58M9x5Z7gYVlbCgAFh+ZBD4Pe/h5/+FL77XVi4\nMLQQcQ/HVVSE8x99NNxySygi+eijEOOkSeFO+sc/huuvD8csWhRihlAss2ULHJrB0GJf/GK4q0+2\n666Jopxjjkls/973QixxK1aE94cfDq9UkpNEsniS6KTW0o9xPMKjnEc/UpTXt0L8wrw/i+lGZf36\nEJaxhj3YgzUsZV8AurKNAuoYyCreY2+GsJxqutRf2FcSmrwWs53tFDc5l+HUUlh/UYamF/i62IV8\nOeHf6F2GkrpLWGpe/82wja6NtqX7HqMOWFTeg9H9Mj5du1EdRVS4h5YZBQXhol1Y2HSf+fNh+nT4\nwQ8abl+xAvbZJyyfc064I/7MZ+DCC8O20lK46KLwWHziifDyy+EiHz/HRReF1iHXXQfjxiW2P/hg\nqKC77bawPmRIuJtOdthh9RWLKe21V6j827Ch6WcvvwxnnRWSyOGHhwrQ1aub7hcR8Qv4HXyDy7gH\nAybxP3yRJ3EK2JdlOLCUfTCMgaxiJXsDBRjOgbzDd7mZ83mEblTxFKfzXW7lbQ6gihJKYsUl2yii\njiIKqaY4dmfuGFUU1++TvP7kcyvo2+eAlHfddUldvQqoa7DeMifzi3gm/X/za+DC0WlqG9q7jkKJ\nIipuuSWUiUMoE587N9zpjhgRin+mToXf/S58vm1baPMN4bMu7fjgef75zd9h78TmMYLjeIVX+Sx1\nFPAZZlJFKUNYynr6cx+XcAkPNLhgL2FIgwswpL/gNrdPYlsJxO6LE31tW3MxbSzVsRkPuFDvuefe\noU+fA1J8kl8X5o6T7t/EKSoyhg5NtA5ORZXZUVFXF8rAjzsurM+aFdpRxzsDxfd55ZXwhDB2bNg2\nc2Yokok7+GC49NJEkgBYujQUoTTn44/Dxfz990PRUnvKcZJoXCwyjxEcw6vsxxJ+zSVcxj1Uh+4+\nVFPESgZxH5dwKfczmJV0Yyt3cxnjuZ932Y8hrKi/C4/feSffiUP8Ih3KnA/hTQyrL4teSmjBch6P\n18c4nxENYq6i6ZhBjbe1vE/yhaewme2ttSN36239rnyW6gkkXZJM97k3u1+8O0hH0hNFvvrpT0O5\n93PPhWfMvn1DmfkTTyT2+dKXQlHRDmrPMuXWnPMsplNNUf0FeSZH05cPOJWneZf96M9aljGkQQuQ\nxjK5o05er6YLtRRRQDV1FDS4aGfPznARzJ7nnnubPn0ObHnHZrX0VJT8eXw5/vfU3HLzjjmmjFdf\n3UxFxRp+9rNruOWWPzbZ57LLxnLNNbcybFjzN/B/+MMvOfvsCZSUhKv+Ndecyg9/+BBlZT1j0YS/\n3cY/R1GRccgh6WPUE0VUxDsglZeHFjUQiotmzQo9Q/v2TZkkksuhv8md3MD/pSyDLgRe4zP05QNG\n8gbv04+J/ISf8N+cytMsZWiTC/cBvNvkrnsrpbzL/uzDUv7DnqQaPizVxXw7xdQ2+vM7hLcopLZ+\n+1LKgNR3y41ldteduA2ri1Vmdq7bpGxJvlDuyHp7xJCZDz6A//7v0GYhdMFo6Xhv5XLL+vbdoz5J\nFFBHEdWUEjoAFlHNPiynLwOppoh9SdS9LWUIRVQz7ZGf8f9OOYmykn7syzJeu/0mSLFfXyqooG/4\nnsF10GhAwo6gRJGPvvc9uP/+sPz1r8Ps2WF59erQoxVC6x8Sd+Zb6cZyBlNENRvZjZG8CRTweV4g\n/h+6cZHGIcwn+U7sN4znN4wn/h/mkNh3xPeZy2GM5C1SiRehpJO4cDd392fU7tSz8za+s4XEXazR\n9M64o9NY4/O1dr3j3HdfGGT2vvuSS1Wbf7IwHMOpwyjjk/pWT0NYxtV33k//fnvzP18+gQr6ctvU\n2+htG3n1jTf4aPNmqmtq+OEVV3DmsccCISn0ZCPr1ixjwnXn89yjr7G5qoYf3nQxi1as4MBBg/Bt\nmyhhGwN5jytuvpnZixZRWVXFOZ/7HP932WXc8dRTrK14n69cfjp9evbkpUcfZdBnP8uc3/6WPj17\n8vOHHuL+GTMAuPTMM7n2ggtYuWYNB/6/7+VkOHMlilz5z39C+/zevUOP2lGjwu3Riy+GYQ2SrD38\ndM7iH2ylW6Is/PXQCWc1e/IR8TuMVOXQbSn2iB8TlT+PTCp0U+2T6sJPM9toZps3894RnBIq6yu5\nh7CMISzjbxxPHcY5TAPgGU6jiq4MZiVDWMZf+TwOfIG/sowhrKU/J/I802lmHKcWvM1zHMiWjPYt\nPepQqrYnbiamTQuvkuI6Kl97o03n/8YXDuXa226j25ePYiDv8cILf+TPd9zBdeefT49dduGDjRsZ\nM348ZxxzTP00o/uyjC6sCc1x9+nCzyf9hG4lJcyfPZv5ixdz6FFH1TcI+dEVV7DbrrtSW1vL5668\nkvnFxXzz+9/n57/+NS/NmEGfAQNC8/JYa8C5b7/NA08/zesPPoi78+mLL+bYww6jV1lZzoYzj8qV\nIP8MGBDea2tD2/8FC0LnLBo+JSxlH7bTlVqajhw5nxYKKjuVVHfTqcqMMytHbtv527JPptsSnw1g\nNeUMoBuVdGMrtRTgFLCF7tRSyGBWUEkJXdnOSOa1+QK8M1r+1L/5zi8H8OTLPdm6rZBuXWs5a+xG\nfnZNM82ei4pC7e+BB4b/axs2hOLcpN7to449lvdvuIE1FRVUfPQRvcrK6N+nD9f9/ve8+uqrFNTV\n8Z+KCtbvthv9Gg9nUloKu+3GqytW8M1rr4WePRnx6U8zYsSI+v4wj73wAlOfeIIaM9ZWVLBo0aLw\neXExfOpTiT5IsbG4Zr7zDmedey7dP/tZAM4eO5a/v/kmZ5x3XvPDmWeZEkWuffvbDYZWnscIjuBf\nVNd3CGqPitDmLsKt2Sd9k722VAqm/p50681ta6uG8XZlW6wTlFFADXUUUkgNhdRRTVF9G/8itlNN\nMU4B3fmEo3iNf3Ik2ylmD9ZwOKGocDaH60Lfkj59wsU2PhBhOrvsQn8+oUf/7lRtL6CkuI6q6gJ6\ndK+lX5+asM+gQWEMrPjIrcm1vgUFoed8fE6bmpqQNPbYg3MuvJDH581jXXk5477yFR5atIiKigrm\nzp1LUVERgwYNoqqwMDz5FxSE721UV2CNRxYwY0VVFT975BFmT5tGr5EjufiSS6hqbn4KMxg+HF+w\nIIyQG9evXzhXnz50TRrCo7CwkMrGgyJmiRJFR1u4EG64IbH+y18yjxEczd/ZQhk7lhiauwsnxba2\n7JP+Tjmz/Rof48QrwI06CqihlmIKqeZYXuUAFrOW0BW1P+uYwFSmMoG19NMFON+sWZMYSRYSd+2P\nPx7uro87LtGrPe7aa8Nd9X77hU6hW7aEp4C6urDuHp4EzMLQ42as3wSXXwETJhhTp8LaRUlP2/EB\nEkeMSD3UCSQ6fBYW1t/1jxs3jq9//et88MEHvPLKKzz22GN86lOfoqioiJdeeolV8RFp48cWFTUY\nbeCYY47hoYceYuzYsSxYsID58+cD8HFZGd179GDXkSNZX1HBc889x3GxJu9lZWVs3ryZPskDIhYV\nccwxx3DxxRczceJE3J0nnnqK3/3ud5nPtZEFShQdxT2MUZ88TDHhCeIw5lJHIZkniXStThouJw8s\nNpgV/Ic92UZXHKOQMHl8vJVR8oU6fnwJW2OthQyjjmK21991d+MT6iikiGoOZzYrYkMkPMHZWb2Y\nT+bqdv/OncbXvhYGHEz2uc+Fuq/WKCwMF2iAr3wFfvObMCLtk0/CBRfAAQeEz++7LySCF14Ik+v8\n4x/hLr20NPThmTcPzjwzfM83vtGwX87dd4c5L+K98ePJoAXJjf0mTwZWbIQNNOyqXNx0iI50hg8f\nzubNm9lzzz3p378/F154IaeffjqjR49m5MiRHHBAqg6BCVdccQXjx49nxIgRjBw5kiOOOAKAQw45\nhFGjRjF8+HD22WcfjjrqqPpjJkyYwMknn0z//v156aWX6rcfeuihXHzxxfXfcemllzJq1KgOK2ZK\nyd071euwww7zTukXv4jfH/ka+vkoZjvUeeK2qblXXUYvo8YL2ebH81e/kl/5WTze0hfrla+vESPC\n+3e+437DDe7vvtvw87Fj3QcPdr/lFvfZsxPbt251r6wMy+eeG9avvdZ9wwb3mhr3bdvcr7vOff16\n97q6sO35593vv9+9ttb9ppvcR44My3V14T2+nE5835bE97v/fve//KV+86JFi3bs/1ZdXcsxRkyq\n3ykwx71t1902HZTLV6dIFFu3uj/6aFiuq3O/9NL6/8xr6Oe9We8tJ4nGyaDWC9nue/Ced2Ozd2Oz\nn8vDfi4P+2CWKjG05+uPf0z/+dSpzX/22mvuH37ovnKl+6pV7p/5jPs3vuG+cKH7vHnhAvm1r7mX\nlTU8rrjY/U9/cj/22NQX3QcecB8+3H3JkqafffSR+7p1ifWVK92rqrLxl50VO5wopAklis6QKK64\nIvxqb7+9wcWgmKoMrlOJxFDMVi9jo/enPPcXz1y/Xnml4frkyS0fc9BB7k8+6X700Yltgwal3jf5\nrt093H3PmJH4N62pcX/iicSd68qV7vfem7hwJx+bKXAvLXV/6qlI3xErUbQ/JYrOkCiOPLLBRWgN\n/dyozSA5xF81O19y+P733Y8/PvVnN9+cWP7Tn9xffNH9Rz9y37Ilsd3d/be/df/3vxO/56uuCp8d\nckjYN+6MM8L2J55o+O9y553u5eXuQ4aEz3/1K/f33kt8PnZs4lyt9e9/u//ud6075te/Dgkq4pQo\n2p8SRT4nihkz3B97rMFFcA39PH0xU0gOBVR7H9blpn5h/Hj3Aw5I/dn//m8o7x440H3SpOa/w919\n8+bE+hVXuD/8cMPP3UMRSvJxd94Ztv/85+6PPNL0dzp5svuDD6b+fdfUuG/c2HT7jTeG7541K/Vx\nlZXun3zSdPu2be4ff9zcv65kyaJFi7wuwk9U7a2urq7dE4UGBWxPjZqvlVDJtmZnvor/3msppI5P\nUcEaBmQnrh//OMR2/fVNPxs/PgwXsnhxaMkS17t300nf495+O8xJYRaaQz73XGKU24oK2LgRhg4N\nzRMHDICf/CTM0wyhffiee8LZZ4cWMvEJftpTbW0Y9mTMmPb/bml3K1asoKysjN69ezftiyCt4u5s\n2LCBzZs3M3jw4AafaT6KfPDeezBwYP1qJkmiiO304YP2TRALF4bXuecmOjF98kmYg/mgg2DGjJAA\njjwyNEs89dRw3KZN0LMn3HQT3HhjeE/u7yGSJdXV1ZSXlzffEU1apaSkhAEDBlBU1HA0ByWKXHv0\n0TBzG6FfxCjmka4XcxeqKWZ768fHmTgxjB67997w298mtl96Kdx7b4pTeU476YhI/tiRRLEzD9XZ\ncSZOZC39OJaXOZQ3SZckjFr6UsEWyppPEq+9lnr7T34CL70UOjxB6Mg0bFgYbTYVJQkRaQfqmd0O\n1q6sYg/W0NLkKV3YTt+WipoOPzzMR/3++2FogzFjwlNEshNPhKefhpNOat9pSkVEUtBVZgeVljhV\nrE2zRyja24XNfJ6/tlzU9K9/hfe+fUPREYSK2TVrGu532mltC1hEpJWUKHZAaSlUbWtpCkYo42NO\n4IWmSeLvf4epU8PYPM88A2+lnhSIww9vn4BFRNpAldk7oLjYqa5OlSjiv9M6ulHZfKV1J/vdi0jn\npTmzO9jatfHRlJtPEr3YwHG8oqGwRaTTU6Jog+Qh9xtyiqmiK9spYVv6JLHXXtkITUSk3al5bCuU\nlqZrcerswsecyrN8TM+GLZviPSQrKmDVqlAxvWhRtsMVEWkXeqJoheYmzIr3jyjjk9RPEcuXZzMs\nEZGs0hNFK5xxRnzJk96dAmoppjp1/4jvfrdjghMRyRI9UWSgtBQaDkNjSe/O7qxvvhPdTTdlNzgR\nkSzTE0UG0hU5Hc+L6XtalzQ3MKCISOegRNGC0lLYvr25T50X+XzTzY2G9xUR6cxU9JRG0yKnZKHI\nKaVRo+DOO2HbtmyFJiLSYZQo0mi+47SzN6tYRTNPDu6JeR5ERDo5FT01o7S0uQcCpzubOYy5HR2S\niEhOKFE0I90wTF/IZBRYEZGdhBJFM1asCDOJJtuVTZzMs+mTxNe/Dr/6VXaDExHpQKqjSKG5SuxN\nlPEsLcwDMXVqdoISEckRPVGksHw5DB2aWC8shKH7OifzXPoDm5tPQkSkE9MTRSOpniZqa2HJUmM1\nxzd/oBmMGJHd4EREckBPFI0sXw5nndV0+x6Us6K55rAiIjsxJYpG+veH3Xdvuv1MZtCvuQ52IiI7\nMRU9pbB+fRiFIz5V9ezZsG5Fiuxx773Qrx+cfrqmNRWRnZYSRQrTp8O8eXDccfDqqzCix0oYnKJJ\n7KWXphsxUERkp6Cip2ZcdBFs2gQXXEDoVNEcMzj4YHjooQ6LTUSkI+mJopHGU50uXAh2/FigDk+V\nV81g/vwOiU1EJBf0RNHIm2/CwIENtw3qV8lbqOmriESTEkUjI0dC9+4Nt3Wv2cQIFuQmIBGRHFOi\nSGHDBujWDe65B4YPhw8/qM11SCIiOaNEkcLZZ4fe2fPmwYIFpJ7q9M9/7vjARERywLyTtf8fPXq0\nz5kzJyvf3dxggCVUUkm3hhs72e9NRKLNzOa6++i2HKsniiTLl4fmsF1ibcG6dIELj9PQHSISbWoe\nm2SffRo+UdTUwEMvD2AaK5o+UYiIRISeKJIsXw4DBoRhxSG8D+C9pk8U++/f8cGJiOSIEkWS/v3h\ntNNC9UNJSXg/nWcaDgbYs2fobCEiEhFKFI2sXw+XXw6zZoX3dTQaDLBXr1DrLSISEaqjaGT69MTy\n5J9vg7saDQbYeIwPEZGdXFafKMzsJDNbbGZLzWxiis/3NrOXzOxNM5tvZqdkM55W27696TYlChGJ\nmKwlCjMrBCYDJwPDgPPNbFij3f4XeMzdRwHjgLuyFU+bpOor8atfdXwcIiI5lM0niiOApe6+3N23\nA48AZzbax4EeseVdgTVZjCcja9fCscfCunXAAw803WHs2A6PSUQkl7KZKPYEVietl8e2JfsBcJGZ\nlQPPAt/IYjwZmTQJZs6Em24Crr226Q4qehKRiMlmokh1RW1clnM+8KC7DwBOAX5nZk1iMrMJZjbH\nzOZUVFRkIdTQkMkMpkwJk9ZNmQKGU8rWxsFk5fwiIvkqm4miHNgraX0ATYuWvgY8BuDu/wRKgD6N\nv8jdp7r7aHcf3bdv36wEGx++o1usA3a3bnAhv2/a2U6JQkQiJpuJYjYw1MwGm1kxobJ6RqN93gM+\nB2BmBxISRXYeGVrQvz/06AGVlVBQEN578HHDznYh0FyEJyKSM1lLFO5eA1wNPA+8TWjdtNDMbjKz\nM2K7fRv4upm9BTwMXOw5HM52/XoYNiw0dho2LEVnOxGRCNIw4zEZDTF+1FHw97/rqUJEOh0NM94O\nmtRRlHrTOoqZM5UkRCRylChi4nUUVVVhQMCqSk9dRyEiEjFKFElWrYLdd4dnnoHLmdKwjuLuu3MX\nmIhIDmlQwCSDBsHzz8O0aXAXVzf8cMKEnMQkIpJrShQ0rcieMgWm4A0rslU3ISIRpaInWtHZTkQk\ngpQoSFGRXdVMZzsRkQhSoohpcWY7EZGIUoe75iTXSZiFkQJFRDopdbjLtldeyXUEIiI5o0SRpMGk\nRck++9mcxCMikg+UKJI0mLRIREQA9aMAMuxHISISUXqioIUBAU8/PbfBiYjkmBIFLfSjKCzMdXgi\nIjmlRBHTYEDAXo8m+lEUF+c2MBGRHFMdRUyDAQE/PD/xwahROYtJRCQfRL7DXYsz223fDkVF7XY+\nEZFcUIe7HRCvyC4tDeulpY0GBCyI/K9IRCIu8lfBeEV2ZWVYr6xsNCCgEoWIRFzkr4KlpU0nr5vC\nlZSyNaxoHgoRibjIJwrNRSEikl7kE4XmohARSS/yiQI0F4WISDqRbx7bxLZt4dEirpP9fkREUlHz\n2PbiDuedl+soRETyihJFzNq1cOyQctY9NSvXoYiI5BUliphJk2Dmij25iRtzHYqISF6JfKIoLQ1d\nJaZMgToKmMKVGJ7oRyEiEnGRTxTLl8NZZyU6YHdji/pRiIgkiXyi6N8fFi+GujoopJYqShL9KI4+\nOtfhiYjkXKQTRbzYadGisF5LIXUUcg+XhQ233pq74ERE8kSkE0WT4TsKq7iQ3/Mf9gwbxozJXXAi\nInki0omiyfAdtUUavkNEpJFIJwpoNHwHd2v4DhGRRiI/Fer06YnlyVydu0BERPJU5J8o6mlMJxGR\nlJQo4rZsabh+wQW5iUNEJM8oUcQVFqZfFxGJKCWK5nTtmusIRETyghJFc9TZTkQEUKJIaFyZ3bNn\nbuIQEckzShTE5qIYa+pDISKSghIFsbkoZpdoLgoRkRQinSgazEXhprkoRERSiHSiaDIooOaiEBFp\nItKJosGggFQ2nItCRESAiCcKgFWrYPfd4RlO1aCAIiIpRH5QwEGD4PnnYRrncBdX5TocEZG8E9kn\nigYV2XXFkdneAAAWL0lEQVSoIltEpBmRTRSqyBYRyUxki57iFdmVlU4BTqUqskVEUorsEwWE2e2G\n7bEJxxnGokRF9iOP5DYwEZE8EtknitLS0CwWwphOCzmYhRxMKVupPK80p7GJiOSTyD5R1NdRFNcA\nqqMQEWlOZBNFfWe76kJ1thMRSSOyiQJCHcXlYxczizHqbCci0owW6yjMrNDdazsimI42fTrw4Cz4\n23wmc3WuwxERyUuZPFEsNbNbzWxY1qPpYGvXwrE/OUlPEiIiaWSSKEYA7wL3mdksM5tgZj2yHFeH\nmDQJZi7ZXfNQiIikYd54CtB0O5sdAzxMaFP6ODDJ3ZdmKbaURo8e7XPmzNmh70g0jW2ohEoq6dZ0\nWlQRkU7OzOa6++i2HNviE4WZFZrZGWb2BHA7cBuwD/A08GwLx55kZovNbKmZTWxmn3PNbJGZLTSz\nP7ThZ2g1Dd8hIpK5TDrcLQFeAm51938kbX889oSRkpkVApOBzwPlwGwzm+Hui5L2GQpcDxzl7h+Z\n2afa8kO0luahEBHJXEZ1FO7+tUZJAgB3/2aa444Alrr7cnffDjwCnNlon68Dk939o9j3vZ9h3Dts\n/Xq4/HLUNFZEpAWZPFHUmNlVwHCgJL7R3S9p4bg9gdVJ6+XApxvtsx+Amb0GFAI/cPc/ZxDTDps+\nPbZwl5rGioikk8kTxe+AfsCJwCvAAGBzBsdZim2Na4m7AEOB44DzCS2rejb5otDSao6ZzamoqMjg\n1DvgKk1eJCKSLJNEsa+73wBscfffAKcCB2dwXDmwV9L6AGBNin2ecvdqd18BLCYkjgbcfaq7j3b3\n0X379s3g1CIi0l4ySRTVsfeNZnYQsCswKIPjZgNDzWywmRUD44AZjfZ5EhgLYGZ9CEVRyzP47nax\ndi0cy8uqnxARSSOTRDHVzHoB/0u40C8CbmnpIHevAa4GngfeBh5z94VmdpOZnRHb7Xlgg5ktIrSs\n+q67b2jDz9EmkybBTI5u2OFOfShERBpI2+HOzAqAc9z9sY4LKb2sd7i7/FthIm0RkZ1I1jrcuXsd\n7HxNgtJ2uLvsstwGJyKSZzJpHvtXM/sO8CiwJb7R3T/MWlRZluhw55RQlehwt2Qm7LtvrsMTEckr\nmSSKeH+J5HajThjGo9Navx4uvwwmTBnDVCawln6qnxARSaFVgwLmg/aoo6hXVweFhYn1d9+FoU1a\n54qIdHo7UkeRycRFX0m13d1/25YT5pXGSbKTJU0RkY6QSdHT4UnLJcDngDeAzp8olnboCOkiIp1S\ni4nC3b+RvG5muxKG9ej8vvzlXEcgIpL3Mulw19hWUgyz0SmtW5frCERE8l4mdRRPkxjMrwAYBuRN\nB7y2WrsWxlX8kUc5LzEPheooRESayKSO4mdJyzXAKncvz1I8HSZ5+I674i1/e/XKbVAiInmoxeax\nZjYYWOvuVbH1UmB3d1+Z/fCa2tHmsc0O39G1jsqqtpTEiYjkv6zOmQ38EahLWq+NbeuUmh2+Y6WS\nhIhIKplcHbvEpjIFILZcnL2QsqvZ+bL75ToyEZH8lEmiqEgaFhwzOxP4IHshZZ/myxYRyVwmdRRD\ngIeAPWKbyoGvuHtOequ16xAeljRbq1o8ichOLKt1FO6+zN3HEJrFDnf3z+QqSbQnzW4nIpKZFhOF\nmf3YzHq6+yfuvtnMepnZDzsiuGxKObudiIg0kUkdxcnuvjG+4u4fAadkL6TsKi0NJU5TpkAdhUzh\nSgyntDTXkYmI5KdMEkWhmXWNr8T6UXRNs39ea7Z57IrcxiUikq8y6Zn9e+BFM3sgtj4e+E32Qsou\nNY8VEWmdTCqzfwr8EDiQUKH9Z2BgluPKKjWPFRHJXCZPFADrCL2zzwVWANOyFlEHmD49tnDXfCZz\nNVx1FfClXIYkIpK3mk0UZrYfMA44H9gAPErodzG2g2LrOD175joCEZG8le6J4h3g78Dp8X4TZnZd\nh0TVEZI72F1/fe7iEBHJc+nqKL5EKHJ6yczuNbPPAZZm/84lOVF07567OERE8lyzicLdn3D384AD\ngJeB64DdzWyKmX2hg+LLnrq6lvcREZGMWj1tcfeH3P00YAAwD5iY9ciy7Yknch2BiEin0KpJGNz9\nQ3e/x92Pz1ZAHWbJklxHICLSKUR3th4VPYmIZESJQkRE0lKiEBGRtCKZKNauhWMf+KqG7hARyUAk\nE8WkSTBz9UDNRSEikoFIJYoGc1F4geaiEBHJQKQSheaiEBFpvUglCs1FISLSepFKFKC5KEREWss8\neXC8TmD06NE+Z86cHf8iSxrfsJP9DkREWsvM5rr76LYcG7knChERaR0lChERSUuJQkRE0lKiEBGR\ntJQoREQkLSUKERFJS4lCRETSUqIYMSLXEYiI5DUlih/8INcRiIjkNSWKI4/MdQQiInlNiULDd4iI\npKVEISIiaSlR6IlCRCQtJQolChGRtJQoREQkLSUKPVGIiKSlRKFEISKSlhLFLrvkOgIRkbymRNGr\nV64jEBHJa0oUIiKSVjQTxeuv5zoCEZFOI5qJYsWKXEcgItJpRDNRqKWTiEjGspoozOwkM1tsZkvN\nbGKa/c4xMzez0dmMp15dXYecRkRkZ5C1RGFmhcBk4GRgGHC+mQ1LsV8Z8E2g4yoOlChERDKWzSeK\nI4Cl7r7c3bcDjwBnpthvEvBToCqLsTSkRCEikrFsJoo9gdVJ6+WxbfXMbBSwl7s/k8U4mnqmY08n\nItKZZTNRWIpt9bXIZlYA/AL4dotfZDbBzOaY2ZyKioodj+zxx3f8O0REIiKbiaIc2CtpfQCwJmm9\nDDgIeNnMVgJjgBmpKrTdfaq7j3b30X379s1iyCIi0lg2E8VsYKiZDTazYmAcMCP+obtvcvc+7j7I\n3QcBs4Az3H1OFmMSEZFWylqicPca4GrgeeBt4DF3X2hmN5nZGdk6r4iItK8u2fxyd38WeLbRthub\n2fe4bMYiIiJtE82e2SIikjElChERSUuJQkRE0opkolhLP47lZdaxe65DERHJe5FMFJO4gZkczU2k\nrFcXEZEkkUoUpaVgBlO4kjoKmcKVmIXtIiKSWqQSxfLlcMEF0I0tAHQrqOLCCzWPkYhIOpFKFP37\nQ48eUEUJJVRS5cX06AH9+uU6MhGR/BWpRAGwfj1czt3MYgyXj/oX69blOiIRkfyW1Z7Z+Wj6dFhr\nP2Qcj/Do0S/R7/YxuQ5JRCSvRe6JApJaPS04O9ehiIjkvUgliiatnv62v1o9iYi0IFKJokmrp1JX\nqycRkRZEKlE0afW0DbV6EhFpQaQSBcD6NTWJVk+X1qrVk4hICyLX6mnyz7czbsZB7M56Jt9eAyWR\n+xWIiLRK5J4oJv2kS2Kcp5KSXIcjIpL3InM7XVoKVVUAxUBo+TTFQq6orMxpaCIieS0yTxT1LZ66\n1gKh5ZNaPImItCwyiaK+xdN2Cy2eKFGLJxGRDEQmUUBsnKfD5oQWT9ytFk8iIhmITB0FhHGeuPEZ\nmDOfyVwN06/KdUgiInkvUk8UANTV5ToCEZFOJXKJYu3H3TVftohIK0QuUUx6cC/Nly0i0gqRSRT1\nI8duvkjzZYuItEJkEkV9P4rCbQB0s63qRyEikoHIJIr6fhS1RbH5stWPQkQkE5FJFBDrR7HPX0I/\nil6Pqh+FiEgGoteP4qfz4XvzmXxbFYzPdUQiIvkvUk8UAPTuHd5POCG3cYiIdBLRSxQ1NeG9S6Qe\npkRE2kyJQkRE0lKiEBGRtKKVKNzhv/4rLCtRiIhkJFqJYvVq2L49LCtRiIhkJFKJYu36gsSAgEoU\nIiIZiVSimHRHj8SAgIWFuQ5HRKRTiMRtdWkpVFUB9ABgClcypRBKSqCyMqehiYjkvUg8UdQPCFgS\nJi3qxhYNCCgikqFIJIr6AQGrCAMCogEBRUQyFYlEAbEBAZkSBgTkbg0IKCKSIXP3XMfQKqNHj/Y5\nc+a07WCzxHIn+7lFRHaEmc1199FtOTYyTxQiItI2ShQiIpKWEoWIiKSlRCEiImkpUYiISFqRShRr\n6ZcY60lERDISqUQxiRsSYz2JiEhGIpEoSktDF4opXEkdhUzhSszCdhERSS8SiaJ+rCe2ABrrSUSk\nNSKRKPr3hx5lThUlGutJRKSVIpEoANYvrOBy7tZYTyIirRSJ+SgApt/4FnzhagAmj7wPpl+V44hE\nRDqHyDxRNJjRLnlwQBERSSs6iaK4OLFcEJ0fW0RkR0XnipmcKH70o9zFISLSyUQzUZx4Yu7iEBHp\nZKKTKEREpE2ikyjq6sL72LG5jUNEpJPJaqIws5PMbLGZLTWziSk+/5aZLTKz+Wb2opkNzFow8UTx\nrW9l7RQiIjujrCUKMysEJgMnA8OA881sWKPd3gRGu/sI4HHgp9mKh5Urw3ttbdZOISKyM8rmE8UR\nwFJ3X+7u24FHgDOTd3D3l9x9a2x1FjAga9GMHx/eX301a6cQEdkZZTNR7AmsTlovj21rzteA57IW\nTbzoSX0oRERaJZtDeKTq/uwpdzS7CBgNHNvM5xOACQB7771326JRohARaZNsXjXLgb2S1gcAaxrv\nZGYnAP8DnOHu21J9kbtPdffR7j66b9++bYtGiUJEpE2yedWcDQw1s8FmVgyMA2Yk72Bmo4B7CEni\n/SzGAu7xk2b1NCIiO5usJQp3rwGuBp4H3gYec/eFZnaTmZ0R2+1WYBfgj2Y2z8xmNPN17RFQ1r5a\nRGRnltVhxt39WeDZRttuTFo+IZvnb6CmJrxv395hpxQR2RlEr8A+XlchIiIZiV6iUB2FiEirRC9R\nJI8iKyIiLYpOoujXL7yPG5fbOEREOpnoJIpevcJ7l8hMEy4i0i6ikyjidRNqJisi0irRSRTxJwkl\nChGRVolOOcy0aXDnnTB8eK4jERHpVKKTKPbdF26/PddRiIh0OtEpehIRkTZRohARkbQikyjWroVj\nj4V163IdiYhI5xKZRDFpEsycCTfdlOtIREQ6l50+UZSWhi4UU6aE8QCnTAnrpaW5jkxEpHPY6RPF\n8uVwwQXQrVtY79YNLrwQVqzIbVwiIp3FTp8o+veHHj2gqgpKSsJ7jx6JoZ9ERCS9nT5RAKxfD5df\nDrNmhXdVaIuIZC4SHe6mT08sT56cuzhERDqjSDxRiIhI2ylRiIhIWkoUIiKSlhKFiIikpUQhIiJp\nKVGIiEhaShQiIpKWEoWIiKSlRCEiImkpUYiISFpKFCIikpa5e65jaBUzqwBWtfHwPsAH7RhOR1DM\nHaczxq2YO8bOEPNAd+/bli/qdIliR5jZHHcfnes4WkMxd5zOGLdi7hhRj1lFTyIikpYShYiIpBW1\nRDE11wG0gWLuOJ0xbsXcMSIdc6TqKEREpPWi9kQhIiKtFJlEYWYnmdliM1tqZhNzHMv9Zva+mS1I\n2rabmf3VzJbE3nvFtpuZ3RGLe76ZHZp0zFdj+y8xs69mOea9zOwlM3vbzBaa2TX5HreZlZjZv8zs\nrVjM/xfbPtjMXo+d/1EzK45t7xpbXxr7fFDSd10f277YzE7MVsxJ5ys0szfN7JnOELOZrTSzf5vZ\nPDObE9uWt38bsXP1NLPHzeyd2N/1kfkcs5ntH/v9xl8fm9m1HRKzu+/0L6AQWAbsAxQDbwHDchjP\nMcChwIKkbT8FJsaWJwK3xJZPAZ4DDBgDvB7bvhuwPPbeK7bcK4sx9wcOjS2XAe8Cw/I57ti5d4kt\nFwGvx2J5DBgX2343cEVs+Urg7tjyOODR2PKw2N9MV2Bw7G+pMMt/I98C/gA8E1vP65iBlUCfRtvy\n9m8jdr7fAJfGlouBnvkec1LshcA6YGBHxJzVHyZfXsCRwPNJ69cD1+c4pkE0TBSLgf6x5f7A4tjy\nPcD5jfcDzgfuSdreYL8OiP8p4POdJW6gG/AG8GlCJ6Qujf82gOeBI2PLXWL7WeO/l+T9shTrAOBF\n4HjgmVgM+R7zSpomirz92wB6ACuI1dN2hpgbxfkF4LWOijkqRU97AquT1stj2/LJ7u6+FiD2/qnY\n9uZiz9nPFCveGEW4Q8/ruGNFOPOA94G/Eu6sN7p7TYrz18cW+3wT0LujYwZ+CfwXUBdb790JYnbg\nL2Y218wmxLbl89/GPkAF8ECsiO8+M+ue5zEnGwc8HFvOesxRSRSWYltnae7VXOw5+ZnMbBdgGnCt\nu3+cbtcU2zo8bnevdfeRhLv0I4AD05w/5zGb2WnA++4+N3lzmvPnPOaYo9z9UOBk4CozOybNvvkQ\ncxdC8e8Udx8FbCEU2zQnH2IOgYT6qTOAP7a0a4ptbYo5KomiHNgraX0AsCZHsTRnvZn1B4i9vx/b\n3lzsHf4zmVkRIUk85O7TO0vcAO6+EXiZUFbb08y6pDh/fWyxz3cFPuzgmI8CzjCzlcAjhOKnX+Z5\nzLj7mtj7+8AThKScz38b5UC5u78eW3+ckDjyOea4k4E33H19bD3rMUclUcwGhsZajhQTHttm5Dim\nxmYA8dYHXyXUAcS3fyXWgmEMsCn2ePk88AUz6xVr5fCF2LasMDMDfg287e4/7wxxm1lfM+sZWy4F\nTgDeBl4Czmkm5vjPcg7wNw+FuDOAcbEWRoOBocC/shGzu1/v7gPcfRDh7/Rv7n5hPsdsZt3NrCy+\nTPg3XUAe/224+zpgtZntH9v0OWBRPsec5HwSxU7x2LIbc7YrXfLlRWgB8C6hjPp/chzLw8BaoJqQ\n3b9GKFd+EVgSe98ttq8Bk2Nx/xsYnfQ9lwBLY6/xWY75aMLj6XxgXux1Sj7HDYwA3ozFvAC4MbZ9\nH8JFcynh8b1rbHtJbH1p7PN9kr7rf2I/y2Lg5A76OzmORKunvI05FttbsdfC+P+vfP7biJ1rJDAn\n9vfxJKEFUL7H3A3YAOyatC3rMatntoiIpBWVoicREWkjJQoREUlLiUJERNJSohARkbSUKEREJC0l\nCoksM/tH7H2QmV3Qzt/936nOJdIZqXmsRJ6ZHQd8x91Pa8Uxhe5em+bzT9x9l/aITyTX9EQhkWVm\nn8QWbwY+Gxvj/7rYQIK3mtns2Dj+l8X2P87CnBx/IHRgwsyejA2EtzA+GJ6Z3QyUxr7voeRzxXrJ\n3mpmCyzM33Be0ne/bIn5ER6K9YYXybkuLe8istObSNITReyCv8ndDzezrsBrZvaX2L5HAAe5+4rY\n+iXu/mFsiJDZZjbN3Sea2dUeBiNs7GxCj+BDgD6xY16NfTYKGE4Yd+c1wrhPM9v/xxVpHT1RiDT1\nBcIYOfMIQ6n3JoyVBPCvpCQB8E0zewuYRRhobSjpHQ087GFU2/XAK8DhSd9d7u51hCFSBrXLTyOy\ng/REIdKUAd9w9wYDpcXqMrY0Wj+BMCHQVjN7mTD2Ukvf3ZxtScu16P+n5Ak9UYjAZsL0rnHPA1fE\nhlXHzPaLjYra2K7AR7EkcQBhCPO46vjxjbwKnBerB+lLmBY3K6O6irQX3bGIhNFDa2JFSA8CtxOK\nfd6IVShXAF9McdyfgcvNbD5hhNZZSZ9NBeab2RsehgmPe4IwlelbhNF4/8vd18USjUheUvNYERFJ\nS0VPIiKSlhKFiIikpUQhIiJpKVGIiEhaShQiIpKWEoWIiKSlRCEiImkpUYiISFr/Hyxu57i3BNpU\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc144769c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.922083\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
