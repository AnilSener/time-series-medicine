{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "#X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 750\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_3, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/750 Iteration: 5 Train loss: 1.809161 Train acc: 0.135000\n",
      "Epoch: 1/750 Iteration: 10 Train loss: 1.783577 Train acc: 0.178333\n",
      "Epoch: 1/750 Iteration: 10 Validation loss: 1.768949 Validation acc: 0.130000\n",
      "Epoch: 1/750 Iteration: 15 Train loss: 1.769089 Train acc: 0.188333\n",
      "Epoch: 2/750 Iteration: 20 Train loss: 1.742896 Train acc: 0.203333\n",
      "Epoch: 2/750 Iteration: 20 Validation loss: 1.740176 Validation acc: 0.150556\n",
      "Epoch: 2/750 Iteration: 25 Train loss: 1.732991 Train acc: 0.205000\n",
      "Epoch: 3/750 Iteration: 30 Train loss: 1.723878 Train acc: 0.220000\n",
      "Epoch: 3/750 Iteration: 30 Validation loss: 1.713178 Validation acc: 0.243889\n",
      "Epoch: 3/750 Iteration: 35 Train loss: 1.722077 Train acc: 0.220000\n",
      "Epoch: 4/750 Iteration: 40 Train loss: 1.705119 Train acc: 0.241667\n",
      "Epoch: 4/750 Iteration: 40 Validation loss: 1.686501 Validation acc: 0.287222\n",
      "Epoch: 4/750 Iteration: 45 Train loss: 1.681569 Train acc: 0.270000\n",
      "Epoch: 5/750 Iteration: 50 Train loss: 1.671226 Train acc: 0.288333\n",
      "Epoch: 5/750 Iteration: 50 Validation loss: 1.658461 Validation acc: 0.318333\n",
      "Epoch: 6/750 Iteration: 55 Train loss: 1.652390 Train acc: 0.311667\n",
      "Epoch: 6/750 Iteration: 60 Train loss: 1.645328 Train acc: 0.328333\n",
      "Epoch: 6/750 Iteration: 60 Validation loss: 1.627620 Validation acc: 0.342222\n",
      "Epoch: 7/750 Iteration: 65 Train loss: 1.614943 Train acc: 0.340000\n",
      "Epoch: 7/750 Iteration: 70 Train loss: 1.605317 Train acc: 0.350000\n",
      "Epoch: 7/750 Iteration: 70 Validation loss: 1.592918 Validation acc: 0.351667\n",
      "Epoch: 8/750 Iteration: 75 Train loss: 1.590197 Train acc: 0.356667\n",
      "Epoch: 8/750 Iteration: 80 Train loss: 1.561103 Train acc: 0.381667\n",
      "Epoch: 8/750 Iteration: 80 Validation loss: 1.553619 Validation acc: 0.355556\n",
      "Epoch: 9/750 Iteration: 85 Train loss: 1.546719 Train acc: 0.405000\n",
      "Epoch: 9/750 Iteration: 90 Train loss: 1.527349 Train acc: 0.406667\n",
      "Epoch: 9/750 Iteration: 90 Validation loss: 1.509574 Validation acc: 0.383333\n",
      "Epoch: 10/750 Iteration: 95 Train loss: 1.495545 Train acc: 0.428333\n",
      "Epoch: 11/750 Iteration: 100 Train loss: 1.472928 Train acc: 0.485000\n",
      "Epoch: 11/750 Iteration: 100 Validation loss: 1.460806 Validation acc: 0.526667\n",
      "Epoch: 11/750 Iteration: 105 Train loss: 1.453161 Train acc: 0.486667\n",
      "Epoch: 12/750 Iteration: 110 Train loss: 1.416341 Train acc: 0.525000\n",
      "Epoch: 12/750 Iteration: 110 Validation loss: 1.407712 Validation acc: 0.578333\n",
      "Epoch: 12/750 Iteration: 115 Train loss: 1.399282 Train acc: 0.521667\n",
      "Epoch: 13/750 Iteration: 120 Train loss: 1.371676 Train acc: 0.545000\n",
      "Epoch: 13/750 Iteration: 120 Validation loss: 1.351138 Validation acc: 0.604444\n",
      "Epoch: 13/750 Iteration: 125 Train loss: 1.352663 Train acc: 0.553333\n",
      "Epoch: 14/750 Iteration: 130 Train loss: 1.322720 Train acc: 0.556667\n",
      "Epoch: 14/750 Iteration: 130 Validation loss: 1.292932 Validation acc: 0.616111\n",
      "Epoch: 14/750 Iteration: 135 Train loss: 1.316676 Train acc: 0.553333\n",
      "Epoch: 15/750 Iteration: 140 Train loss: 1.235328 Train acc: 0.600000\n",
      "Epoch: 15/750 Iteration: 140 Validation loss: 1.234923 Validation acc: 0.625000\n",
      "Epoch: 16/750 Iteration: 145 Train loss: 1.208390 Train acc: 0.618333\n",
      "Epoch: 16/750 Iteration: 150 Train loss: 1.191660 Train acc: 0.585000\n",
      "Epoch: 16/750 Iteration: 150 Validation loss: 1.178660 Validation acc: 0.630000\n",
      "Epoch: 17/750 Iteration: 155 Train loss: 1.169582 Train acc: 0.581667\n",
      "Epoch: 17/750 Iteration: 160 Train loss: 1.136931 Train acc: 0.635000\n",
      "Epoch: 17/750 Iteration: 160 Validation loss: 1.125203 Validation acc: 0.637222\n",
      "Epoch: 18/750 Iteration: 165 Train loss: 1.135183 Train acc: 0.583333\n",
      "Epoch: 18/750 Iteration: 170 Train loss: 1.108989 Train acc: 0.610000\n",
      "Epoch: 18/750 Iteration: 170 Validation loss: 1.074740 Validation acc: 0.649444\n",
      "Epoch: 19/750 Iteration: 175 Train loss: 1.095184 Train acc: 0.586667\n",
      "Epoch: 19/750 Iteration: 180 Train loss: 1.092184 Train acc: 0.598333\n",
      "Epoch: 19/750 Iteration: 180 Validation loss: 1.027597 Validation acc: 0.655556\n",
      "Epoch: 20/750 Iteration: 185 Train loss: 1.006305 Train acc: 0.638333\n",
      "Epoch: 21/750 Iteration: 190 Train loss: 1.002780 Train acc: 0.628333\n",
      "Epoch: 21/750 Iteration: 190 Validation loss: 0.983980 Validation acc: 0.669444\n",
      "Epoch: 21/750 Iteration: 195 Train loss: 0.976039 Train acc: 0.628333\n",
      "Epoch: 22/750 Iteration: 200 Train loss: 0.976426 Train acc: 0.593333\n",
      "Epoch: 22/750 Iteration: 200 Validation loss: 0.944008 Validation acc: 0.676667\n",
      "Epoch: 22/750 Iteration: 205 Train loss: 0.961604 Train acc: 0.628333\n",
      "Epoch: 23/750 Iteration: 210 Train loss: 0.961765 Train acc: 0.601667\n",
      "Epoch: 23/750 Iteration: 210 Validation loss: 0.907799 Validation acc: 0.683333\n",
      "Epoch: 23/750 Iteration: 215 Train loss: 0.932635 Train acc: 0.651667\n",
      "Epoch: 24/750 Iteration: 220 Train loss: 0.938330 Train acc: 0.595000\n",
      "Epoch: 24/750 Iteration: 220 Validation loss: 0.875100 Validation acc: 0.688333\n",
      "Epoch: 24/750 Iteration: 225 Train loss: 0.945197 Train acc: 0.596667\n",
      "Epoch: 25/750 Iteration: 230 Train loss: 0.856498 Train acc: 0.670000\n",
      "Epoch: 25/750 Iteration: 230 Validation loss: 0.845438 Validation acc: 0.701111\n",
      "Epoch: 26/750 Iteration: 235 Train loss: 0.847602 Train acc: 0.661667\n",
      "Epoch: 26/750 Iteration: 240 Train loss: 0.834276 Train acc: 0.648333\n",
      "Epoch: 26/750 Iteration: 240 Validation loss: 0.818729 Validation acc: 0.702778\n",
      "Epoch: 27/750 Iteration: 245 Train loss: 0.843814 Train acc: 0.645000\n",
      "Epoch: 27/750 Iteration: 250 Train loss: 0.852414 Train acc: 0.641667\n",
      "Epoch: 27/750 Iteration: 250 Validation loss: 0.794488 Validation acc: 0.713889\n",
      "Epoch: 28/750 Iteration: 255 Train loss: 0.844001 Train acc: 0.646667\n",
      "Epoch: 28/750 Iteration: 260 Train loss: 0.818517 Train acc: 0.666667\n",
      "Epoch: 28/750 Iteration: 260 Validation loss: 0.772184 Validation acc: 0.721667\n",
      "Epoch: 29/750 Iteration: 265 Train loss: 0.832945 Train acc: 0.628333\n",
      "Epoch: 29/750 Iteration: 270 Train loss: 0.795386 Train acc: 0.670000\n",
      "Epoch: 29/750 Iteration: 270 Validation loss: 0.751796 Validation acc: 0.721667\n",
      "Epoch: 30/750 Iteration: 275 Train loss: 0.767672 Train acc: 0.695000\n",
      "Epoch: 31/750 Iteration: 280 Train loss: 0.774093 Train acc: 0.666667\n",
      "Epoch: 31/750 Iteration: 280 Validation loss: 0.732812 Validation acc: 0.731111\n",
      "Epoch: 31/750 Iteration: 285 Train loss: 0.737317 Train acc: 0.695000\n",
      "Epoch: 32/750 Iteration: 290 Train loss: 0.769738 Train acc: 0.646667\n",
      "Epoch: 32/750 Iteration: 290 Validation loss: 0.714487 Validation acc: 0.747778\n",
      "Epoch: 32/750 Iteration: 295 Train loss: 0.763438 Train acc: 0.668333\n",
      "Epoch: 33/750 Iteration: 300 Train loss: 0.751653 Train acc: 0.675000\n",
      "Epoch: 33/750 Iteration: 300 Validation loss: 0.697532 Validation acc: 0.759444\n",
      "Epoch: 33/750 Iteration: 305 Train loss: 0.748851 Train acc: 0.695000\n",
      "Epoch: 34/750 Iteration: 310 Train loss: 0.758580 Train acc: 0.646667\n",
      "Epoch: 34/750 Iteration: 310 Validation loss: 0.681552 Validation acc: 0.761111\n",
      "Epoch: 34/750 Iteration: 315 Train loss: 0.717060 Train acc: 0.726667\n",
      "Epoch: 35/750 Iteration: 320 Train loss: 0.703088 Train acc: 0.703333\n",
      "Epoch: 35/750 Iteration: 320 Validation loss: 0.666010 Validation acc: 0.767222\n",
      "Epoch: 36/750 Iteration: 325 Train loss: 0.679434 Train acc: 0.735000\n",
      "Epoch: 36/750 Iteration: 330 Train loss: 0.669296 Train acc: 0.720000\n",
      "Epoch: 36/750 Iteration: 330 Validation loss: 0.651378 Validation acc: 0.771667\n",
      "Epoch: 37/750 Iteration: 335 Train loss: 0.688927 Train acc: 0.703333\n",
      "Epoch: 37/750 Iteration: 340 Train loss: 0.680562 Train acc: 0.703333\n",
      "Epoch: 37/750 Iteration: 340 Validation loss: 0.637289 Validation acc: 0.780556\n",
      "Epoch: 38/750 Iteration: 345 Train loss: 0.671664 Train acc: 0.716667\n",
      "Epoch: 38/750 Iteration: 350 Train loss: 0.675356 Train acc: 0.723333\n",
      "Epoch: 38/750 Iteration: 350 Validation loss: 0.623744 Validation acc: 0.790556\n",
      "Epoch: 39/750 Iteration: 355 Train loss: 0.678363 Train acc: 0.700000\n",
      "Epoch: 39/750 Iteration: 360 Train loss: 0.659804 Train acc: 0.738333\n",
      "Epoch: 39/750 Iteration: 360 Validation loss: 0.610441 Validation acc: 0.797778\n",
      "Epoch: 40/750 Iteration: 365 Train loss: 0.639740 Train acc: 0.730000\n",
      "Epoch: 41/750 Iteration: 370 Train loss: 0.634817 Train acc: 0.753333\n",
      "Epoch: 41/750 Iteration: 370 Validation loss: 0.597460 Validation acc: 0.800556\n",
      "Epoch: 41/750 Iteration: 375 Train loss: 0.603517 Train acc: 0.756667\n",
      "Epoch: 42/750 Iteration: 380 Train loss: 0.640611 Train acc: 0.716667\n",
      "Epoch: 42/750 Iteration: 380 Validation loss: 0.584820 Validation acc: 0.803889\n",
      "Epoch: 42/750 Iteration: 385 Train loss: 0.624285 Train acc: 0.728333\n",
      "Epoch: 43/750 Iteration: 390 Train loss: 0.638820 Train acc: 0.720000\n",
      "Epoch: 43/750 Iteration: 390 Validation loss: 0.572553 Validation acc: 0.811111\n",
      "Epoch: 43/750 Iteration: 395 Train loss: 0.608563 Train acc: 0.753333\n",
      "Epoch: 44/750 Iteration: 400 Train loss: 0.629275 Train acc: 0.745000\n",
      "Epoch: 44/750 Iteration: 400 Validation loss: 0.560713 Validation acc: 0.817778\n",
      "Epoch: 44/750 Iteration: 405 Train loss: 0.608266 Train acc: 0.755000\n",
      "Epoch: 45/750 Iteration: 410 Train loss: 0.574948 Train acc: 0.750000\n",
      "Epoch: 45/750 Iteration: 410 Validation loss: 0.548908 Validation acc: 0.816667\n",
      "Epoch: 46/750 Iteration: 415 Train loss: 0.572447 Train acc: 0.780000\n",
      "Epoch: 46/750 Iteration: 420 Train loss: 0.545080 Train acc: 0.783333\n",
      "Epoch: 46/750 Iteration: 420 Validation loss: 0.537424 Validation acc: 0.820000\n",
      "Epoch: 47/750 Iteration: 425 Train loss: 0.559829 Train acc: 0.778333\n",
      "Epoch: 47/750 Iteration: 430 Train loss: 0.569643 Train acc: 0.761667\n",
      "Epoch: 47/750 Iteration: 430 Validation loss: 0.525935 Validation acc: 0.827222\n",
      "Epoch: 48/750 Iteration: 435 Train loss: 0.583961 Train acc: 0.746667\n",
      "Epoch: 48/750 Iteration: 440 Train loss: 0.555237 Train acc: 0.771667\n",
      "Epoch: 48/750 Iteration: 440 Validation loss: 0.514932 Validation acc: 0.827222\n",
      "Epoch: 49/750 Iteration: 445 Train loss: 0.565984 Train acc: 0.745000\n",
      "Epoch: 49/750 Iteration: 450 Train loss: 0.565576 Train acc: 0.755000\n",
      "Epoch: 49/750 Iteration: 450 Validation loss: 0.504278 Validation acc: 0.831667\n",
      "Epoch: 50/750 Iteration: 455 Train loss: 0.544130 Train acc: 0.773333\n",
      "Epoch: 51/750 Iteration: 460 Train loss: 0.520254 Train acc: 0.805000\n",
      "Epoch: 51/750 Iteration: 460 Validation loss: 0.493948 Validation acc: 0.835556\n",
      "Epoch: 51/750 Iteration: 465 Train loss: 0.492010 Train acc: 0.810000\n",
      "Epoch: 52/750 Iteration: 470 Train loss: 0.526235 Train acc: 0.810000\n",
      "Epoch: 52/750 Iteration: 470 Validation loss: 0.483770 Validation acc: 0.836111\n",
      "Epoch: 52/750 Iteration: 475 Train loss: 0.516184 Train acc: 0.785000\n",
      "Epoch: 53/750 Iteration: 480 Train loss: 0.554710 Train acc: 0.748333\n",
      "Epoch: 53/750 Iteration: 480 Validation loss: 0.473960 Validation acc: 0.841667\n",
      "Epoch: 53/750 Iteration: 485 Train loss: 0.509479 Train acc: 0.801667\n",
      "Epoch: 54/750 Iteration: 490 Train loss: 0.570173 Train acc: 0.753333\n",
      "Epoch: 54/750 Iteration: 490 Validation loss: 0.464587 Validation acc: 0.841667\n",
      "Epoch: 54/750 Iteration: 495 Train loss: 0.507303 Train acc: 0.801667\n",
      "Epoch: 55/750 Iteration: 500 Train loss: 0.493998 Train acc: 0.808333\n",
      "Epoch: 55/750 Iteration: 500 Validation loss: 0.455106 Validation acc: 0.851667\n",
      "Epoch: 56/750 Iteration: 505 Train loss: 0.477173 Train acc: 0.833333\n",
      "Epoch: 56/750 Iteration: 510 Train loss: 0.441195 Train acc: 0.831667\n",
      "Epoch: 56/750 Iteration: 510 Validation loss: 0.446138 Validation acc: 0.848889\n",
      "Epoch: 57/750 Iteration: 515 Train loss: 0.484167 Train acc: 0.808333\n",
      "Epoch: 57/750 Iteration: 520 Train loss: 0.477540 Train acc: 0.815000\n",
      "Epoch: 57/750 Iteration: 520 Validation loss: 0.437274 Validation acc: 0.856111\n",
      "Epoch: 58/750 Iteration: 525 Train loss: 0.471330 Train acc: 0.825000\n",
      "Epoch: 58/750 Iteration: 530 Train loss: 0.448854 Train acc: 0.826667\n",
      "Epoch: 58/750 Iteration: 530 Validation loss: 0.428999 Validation acc: 0.856667\n",
      "Epoch: 59/750 Iteration: 535 Train loss: 0.515313 Train acc: 0.763333\n",
      "Epoch: 59/750 Iteration: 540 Train loss: 0.485420 Train acc: 0.796667\n",
      "Epoch: 59/750 Iteration: 540 Validation loss: 0.420588 Validation acc: 0.860000\n",
      "Epoch: 60/750 Iteration: 545 Train loss: 0.421045 Train acc: 0.851667\n",
      "Epoch: 61/750 Iteration: 550 Train loss: 0.436354 Train acc: 0.828333\n",
      "Epoch: 61/750 Iteration: 550 Validation loss: 0.412976 Validation acc: 0.858333\n",
      "Epoch: 61/750 Iteration: 555 Train loss: 0.421984 Train acc: 0.821667\n",
      "Epoch: 62/750 Iteration: 560 Train loss: 0.443118 Train acc: 0.830000\n",
      "Epoch: 62/750 Iteration: 560 Validation loss: 0.405005 Validation acc: 0.862778\n",
      "Epoch: 62/750 Iteration: 565 Train loss: 0.434287 Train acc: 0.828333\n",
      "Epoch: 63/750 Iteration: 570 Train loss: 0.437299 Train acc: 0.843333\n",
      "Epoch: 63/750 Iteration: 570 Validation loss: 0.397615 Validation acc: 0.865000\n",
      "Epoch: 63/750 Iteration: 575 Train loss: 0.429217 Train acc: 0.838333\n",
      "Epoch: 64/750 Iteration: 580 Train loss: 0.470465 Train acc: 0.815000\n",
      "Epoch: 64/750 Iteration: 580 Validation loss: 0.390225 Validation acc: 0.866111\n",
      "Epoch: 64/750 Iteration: 585 Train loss: 0.433720 Train acc: 0.838333\n",
      "Epoch: 65/750 Iteration: 590 Train loss: 0.415358 Train acc: 0.840000\n",
      "Epoch: 65/750 Iteration: 590 Validation loss: 0.383087 Validation acc: 0.867778\n",
      "Epoch: 66/750 Iteration: 595 Train loss: 0.402432 Train acc: 0.858333\n",
      "Epoch: 66/750 Iteration: 600 Train loss: 0.402013 Train acc: 0.836667\n",
      "Epoch: 66/750 Iteration: 600 Validation loss: 0.376104 Validation acc: 0.870000\n",
      "Epoch: 67/750 Iteration: 605 Train loss: 0.410819 Train acc: 0.845000\n",
      "Epoch: 67/750 Iteration: 610 Train loss: 0.409070 Train acc: 0.850000\n",
      "Epoch: 67/750 Iteration: 610 Validation loss: 0.369550 Validation acc: 0.872778\n",
      "Epoch: 68/750 Iteration: 615 Train loss: 0.428460 Train acc: 0.835000\n",
      "Epoch: 68/750 Iteration: 620 Train loss: 0.393421 Train acc: 0.838333\n",
      "Epoch: 68/750 Iteration: 620 Validation loss: 0.363399 Validation acc: 0.874444\n",
      "Epoch: 69/750 Iteration: 625 Train loss: 0.438485 Train acc: 0.815000\n",
      "Epoch: 69/750 Iteration: 630 Train loss: 0.388793 Train acc: 0.868333\n",
      "Epoch: 69/750 Iteration: 630 Validation loss: 0.357239 Validation acc: 0.874444\n",
      "Epoch: 70/750 Iteration: 635 Train loss: 0.393107 Train acc: 0.840000\n",
      "Epoch: 71/750 Iteration: 640 Train loss: 0.367964 Train acc: 0.873333\n",
      "Epoch: 71/750 Iteration: 640 Validation loss: 0.351313 Validation acc: 0.877222\n",
      "Epoch: 71/750 Iteration: 645 Train loss: 0.362495 Train acc: 0.878333\n",
      "Epoch: 72/750 Iteration: 650 Train loss: 0.372588 Train acc: 0.878333\n",
      "Epoch: 72/750 Iteration: 650 Validation loss: 0.345804 Validation acc: 0.876111\n",
      "Epoch: 72/750 Iteration: 655 Train loss: 0.374701 Train acc: 0.866667\n",
      "Epoch: 73/750 Iteration: 660 Train loss: 0.377487 Train acc: 0.863333\n",
      "Epoch: 73/750 Iteration: 660 Validation loss: 0.340030 Validation acc: 0.878889\n",
      "Epoch: 73/750 Iteration: 665 Train loss: 0.342749 Train acc: 0.875000\n",
      "Epoch: 74/750 Iteration: 670 Train loss: 0.394549 Train acc: 0.830000\n",
      "Epoch: 74/750 Iteration: 670 Validation loss: 0.335191 Validation acc: 0.880000\n",
      "Epoch: 74/750 Iteration: 675 Train loss: 0.376905 Train acc: 0.858333\n",
      "Epoch: 75/750 Iteration: 680 Train loss: 0.354870 Train acc: 0.868333\n",
      "Epoch: 75/750 Iteration: 680 Validation loss: 0.329559 Validation acc: 0.882222\n",
      "Epoch: 76/750 Iteration: 685 Train loss: 0.336833 Train acc: 0.880000\n",
      "Epoch: 76/750 Iteration: 690 Train loss: 0.324217 Train acc: 0.873333\n",
      "Epoch: 76/750 Iteration: 690 Validation loss: 0.324803 Validation acc: 0.882778\n",
      "Epoch: 77/750 Iteration: 695 Train loss: 0.347547 Train acc: 0.886667\n",
      "Epoch: 77/750 Iteration: 700 Train loss: 0.357664 Train acc: 0.858333\n",
      "Epoch: 77/750 Iteration: 700 Validation loss: 0.320086 Validation acc: 0.883889\n",
      "Epoch: 78/750 Iteration: 705 Train loss: 0.375852 Train acc: 0.841667\n",
      "Epoch: 78/750 Iteration: 710 Train loss: 0.329261 Train acc: 0.878333\n",
      "Epoch: 78/750 Iteration: 710 Validation loss: 0.315517 Validation acc: 0.884444\n",
      "Epoch: 79/750 Iteration: 715 Train loss: 0.375869 Train acc: 0.853333\n",
      "Epoch: 79/750 Iteration: 720 Train loss: 0.355644 Train acc: 0.863333\n",
      "Epoch: 79/750 Iteration: 720 Validation loss: 0.311392 Validation acc: 0.885000\n",
      "Epoch: 80/750 Iteration: 725 Train loss: 0.332236 Train acc: 0.870000\n",
      "Epoch: 81/750 Iteration: 730 Train loss: 0.318036 Train acc: 0.878333\n",
      "Epoch: 81/750 Iteration: 730 Validation loss: 0.307038 Validation acc: 0.888333\n",
      "Epoch: 81/750 Iteration: 735 Train loss: 0.300143 Train acc: 0.896667\n",
      "Epoch: 82/750 Iteration: 740 Train loss: 0.328299 Train acc: 0.895000\n",
      "Epoch: 82/750 Iteration: 740 Validation loss: 0.302789 Validation acc: 0.888889\n",
      "Epoch: 82/750 Iteration: 745 Train loss: 0.321132 Train acc: 0.878333\n",
      "Epoch: 83/750 Iteration: 750 Train loss: 0.335346 Train acc: 0.870000\n",
      "Epoch: 83/750 Iteration: 750 Validation loss: 0.298750 Validation acc: 0.889444\n",
      "Epoch: 83/750 Iteration: 755 Train loss: 0.303615 Train acc: 0.888333\n",
      "Epoch: 84/750 Iteration: 760 Train loss: 0.343358 Train acc: 0.871667\n",
      "Epoch: 84/750 Iteration: 760 Validation loss: 0.294690 Validation acc: 0.892222\n",
      "Epoch: 84/750 Iteration: 765 Train loss: 0.339154 Train acc: 0.875000\n",
      "Epoch: 85/750 Iteration: 770 Train loss: 0.316712 Train acc: 0.883333\n",
      "Epoch: 85/750 Iteration: 770 Validation loss: 0.290651 Validation acc: 0.893889\n",
      "Epoch: 86/750 Iteration: 775 Train loss: 0.297802 Train acc: 0.893333\n",
      "Epoch: 86/750 Iteration: 780 Train loss: 0.293533 Train acc: 0.883333\n",
      "Epoch: 86/750 Iteration: 780 Validation loss: 0.286883 Validation acc: 0.894444\n",
      "Epoch: 87/750 Iteration: 785 Train loss: 0.321586 Train acc: 0.896667\n",
      "Epoch: 87/750 Iteration: 790 Train loss: 0.302748 Train acc: 0.896667\n",
      "Epoch: 87/750 Iteration: 790 Validation loss: 0.283471 Validation acc: 0.894444\n",
      "Epoch: 88/750 Iteration: 795 Train loss: 0.309650 Train acc: 0.883333\n",
      "Epoch: 88/750 Iteration: 800 Train loss: 0.292571 Train acc: 0.895000\n",
      "Epoch: 88/750 Iteration: 800 Validation loss: 0.279722 Validation acc: 0.894444\n",
      "Epoch: 89/750 Iteration: 805 Train loss: 0.341141 Train acc: 0.868333\n",
      "Epoch: 89/750 Iteration: 810 Train loss: 0.321984 Train acc: 0.866667\n",
      "Epoch: 89/750 Iteration: 810 Validation loss: 0.276629 Validation acc: 0.895000\n",
      "Epoch: 90/750 Iteration: 815 Train loss: 0.294236 Train acc: 0.891667\n",
      "Epoch: 91/750 Iteration: 820 Train loss: 0.287011 Train acc: 0.896667\n",
      "Epoch: 91/750 Iteration: 820 Validation loss: 0.272552 Validation acc: 0.895555\n",
      "Epoch: 91/750 Iteration: 825 Train loss: 0.279717 Train acc: 0.895000\n",
      "Epoch: 92/750 Iteration: 830 Train loss: 0.298634 Train acc: 0.901667\n",
      "Epoch: 92/750 Iteration: 830 Validation loss: 0.269490 Validation acc: 0.896111\n",
      "Epoch: 92/750 Iteration: 835 Train loss: 0.302765 Train acc: 0.876667\n",
      "Epoch: 93/750 Iteration: 840 Train loss: 0.292877 Train acc: 0.895000\n",
      "Epoch: 93/750 Iteration: 840 Validation loss: 0.266533 Validation acc: 0.897778\n",
      "Epoch: 93/750 Iteration: 845 Train loss: 0.275619 Train acc: 0.901667\n",
      "Epoch: 94/750 Iteration: 850 Train loss: 0.320980 Train acc: 0.883333\n",
      "Epoch: 94/750 Iteration: 850 Validation loss: 0.263012 Validation acc: 0.900556\n",
      "Epoch: 94/750 Iteration: 855 Train loss: 0.291812 Train acc: 0.895000\n",
      "Epoch: 95/750 Iteration: 860 Train loss: 0.289877 Train acc: 0.895000\n",
      "Epoch: 95/750 Iteration: 860 Validation loss: 0.260298 Validation acc: 0.900000\n",
      "Epoch: 96/750 Iteration: 865 Train loss: 0.258757 Train acc: 0.905000\n",
      "Epoch: 96/750 Iteration: 870 Train loss: 0.271983 Train acc: 0.880000\n",
      "Epoch: 96/750 Iteration: 870 Validation loss: 0.257275 Validation acc: 0.900000\n",
      "Epoch: 97/750 Iteration: 875 Train loss: 0.281481 Train acc: 0.900000\n",
      "Epoch: 97/750 Iteration: 880 Train loss: 0.274339 Train acc: 0.916667\n",
      "Epoch: 97/750 Iteration: 880 Validation loss: 0.254078 Validation acc: 0.902778\n",
      "Epoch: 98/750 Iteration: 885 Train loss: 0.273628 Train acc: 0.900000\n",
      "Epoch: 98/750 Iteration: 890 Train loss: 0.244879 Train acc: 0.916667\n",
      "Epoch: 98/750 Iteration: 890 Validation loss: 0.251841 Validation acc: 0.903333\n",
      "Epoch: 99/750 Iteration: 895 Train loss: 0.286628 Train acc: 0.910000\n",
      "Epoch: 99/750 Iteration: 900 Train loss: 0.274779 Train acc: 0.893333\n",
      "Epoch: 99/750 Iteration: 900 Validation loss: 0.248657 Validation acc: 0.904444\n",
      "Epoch: 100/750 Iteration: 905 Train loss: 0.286212 Train acc: 0.898333\n",
      "Epoch: 101/750 Iteration: 910 Train loss: 0.258189 Train acc: 0.910000\n",
      "Epoch: 101/750 Iteration: 910 Validation loss: 0.245665 Validation acc: 0.906667\n",
      "Epoch: 101/750 Iteration: 915 Train loss: 0.236140 Train acc: 0.911667\n",
      "Epoch: 102/750 Iteration: 920 Train loss: 0.261110 Train acc: 0.921667\n",
      "Epoch: 102/750 Iteration: 920 Validation loss: 0.242859 Validation acc: 0.907222\n",
      "Epoch: 102/750 Iteration: 925 Train loss: 0.256448 Train acc: 0.911667\n",
      "Epoch: 103/750 Iteration: 930 Train loss: 0.264293 Train acc: 0.906667\n",
      "Epoch: 103/750 Iteration: 930 Validation loss: 0.240441 Validation acc: 0.908333\n",
      "Epoch: 103/750 Iteration: 935 Train loss: 0.228627 Train acc: 0.910000\n",
      "Epoch: 104/750 Iteration: 940 Train loss: 0.295590 Train acc: 0.886667\n",
      "Epoch: 104/750 Iteration: 940 Validation loss: 0.237708 Validation acc: 0.906667\n",
      "Epoch: 104/750 Iteration: 945 Train loss: 0.259904 Train acc: 0.916667\n",
      "Epoch: 105/750 Iteration: 950 Train loss: 0.251678 Train acc: 0.918333\n",
      "Epoch: 105/750 Iteration: 950 Validation loss: 0.235101 Validation acc: 0.907222\n",
      "Epoch: 106/750 Iteration: 955 Train loss: 0.250001 Train acc: 0.910000\n",
      "Epoch: 106/750 Iteration: 960 Train loss: 0.214707 Train acc: 0.910000\n",
      "Epoch: 106/750 Iteration: 960 Validation loss: 0.232892 Validation acc: 0.910000\n",
      "Epoch: 107/750 Iteration: 965 Train loss: 0.251244 Train acc: 0.915000\n",
      "Epoch: 107/750 Iteration: 970 Train loss: 0.251355 Train acc: 0.918333\n",
      "Epoch: 107/750 Iteration: 970 Validation loss: 0.230129 Validation acc: 0.911111\n",
      "Epoch: 108/750 Iteration: 975 Train loss: 0.255162 Train acc: 0.911667\n",
      "Epoch: 108/750 Iteration: 980 Train loss: 0.218989 Train acc: 0.923333\n",
      "Epoch: 108/750 Iteration: 980 Validation loss: 0.228241 Validation acc: 0.911111\n",
      "Epoch: 109/750 Iteration: 985 Train loss: 0.276619 Train acc: 0.891667\n",
      "Epoch: 109/750 Iteration: 990 Train loss: 0.260228 Train acc: 0.903333\n",
      "Epoch: 109/750 Iteration: 990 Validation loss: 0.225487 Validation acc: 0.911111\n",
      "Epoch: 110/750 Iteration: 995 Train loss: 0.248501 Train acc: 0.913333\n",
      "Epoch: 111/750 Iteration: 1000 Train loss: 0.207937 Train acc: 0.931667\n",
      "Epoch: 111/750 Iteration: 1000 Validation loss: 0.222988 Validation acc: 0.912222\n",
      "Epoch: 111/750 Iteration: 1005 Train loss: 0.206294 Train acc: 0.930000\n",
      "Epoch: 112/750 Iteration: 1010 Train loss: 0.226960 Train acc: 0.930000\n",
      "Epoch: 112/750 Iteration: 1010 Validation loss: 0.220999 Validation acc: 0.911667\n",
      "Epoch: 112/750 Iteration: 1015 Train loss: 0.239123 Train acc: 0.916667\n",
      "Epoch: 113/750 Iteration: 1020 Train loss: 0.238507 Train acc: 0.913333\n",
      "Epoch: 113/750 Iteration: 1020 Validation loss: 0.218422 Validation acc: 0.912222\n",
      "Epoch: 113/750 Iteration: 1025 Train loss: 0.210354 Train acc: 0.923333\n",
      "Epoch: 114/750 Iteration: 1030 Train loss: 0.262509 Train acc: 0.910000\n",
      "Epoch: 114/750 Iteration: 1030 Validation loss: 0.216497 Validation acc: 0.913889\n",
      "Epoch: 114/750 Iteration: 1035 Train loss: 0.235176 Train acc: 0.918333\n",
      "Epoch: 115/750 Iteration: 1040 Train loss: 0.224281 Train acc: 0.920000\n",
      "Epoch: 115/750 Iteration: 1040 Validation loss: 0.214326 Validation acc: 0.915000\n",
      "Epoch: 116/750 Iteration: 1045 Train loss: 0.224168 Train acc: 0.908333\n",
      "Epoch: 116/750 Iteration: 1050 Train loss: 0.206025 Train acc: 0.925000\n",
      "Epoch: 116/750 Iteration: 1050 Validation loss: 0.212169 Validation acc: 0.916111\n",
      "Epoch: 117/750 Iteration: 1055 Train loss: 0.228769 Train acc: 0.925000\n",
      "Epoch: 117/750 Iteration: 1060 Train loss: 0.233306 Train acc: 0.913333\n",
      "Epoch: 117/750 Iteration: 1060 Validation loss: 0.209910 Validation acc: 0.917222\n",
      "Epoch: 118/750 Iteration: 1065 Train loss: 0.231781 Train acc: 0.913333\n",
      "Epoch: 118/750 Iteration: 1070 Train loss: 0.186331 Train acc: 0.935000\n",
      "Epoch: 118/750 Iteration: 1070 Validation loss: 0.208072 Validation acc: 0.918889\n",
      "Epoch: 119/750 Iteration: 1075 Train loss: 0.252236 Train acc: 0.901667\n",
      "Epoch: 119/750 Iteration: 1080 Train loss: 0.227051 Train acc: 0.923333\n",
      "Epoch: 119/750 Iteration: 1080 Validation loss: 0.205932 Validation acc: 0.920556\n",
      "Epoch: 120/750 Iteration: 1085 Train loss: 0.213622 Train acc: 0.938333\n",
      "Epoch: 121/750 Iteration: 1090 Train loss: 0.198914 Train acc: 0.921667\n",
      "Epoch: 121/750 Iteration: 1090 Validation loss: 0.204295 Validation acc: 0.920000\n",
      "Epoch: 121/750 Iteration: 1095 Train loss: 0.188472 Train acc: 0.933333\n",
      "Epoch: 122/750 Iteration: 1100 Train loss: 0.213662 Train acc: 0.940000\n",
      "Epoch: 122/750 Iteration: 1100 Validation loss: 0.202120 Validation acc: 0.922222\n",
      "Epoch: 122/750 Iteration: 1105 Train loss: 0.208933 Train acc: 0.935000\n",
      "Epoch: 123/750 Iteration: 1110 Train loss: 0.226334 Train acc: 0.901667\n",
      "Epoch: 123/750 Iteration: 1110 Validation loss: 0.200273 Validation acc: 0.921111\n",
      "Epoch: 123/750 Iteration: 1115 Train loss: 0.199347 Train acc: 0.926667\n",
      "Epoch: 124/750 Iteration: 1120 Train loss: 0.237160 Train acc: 0.921667\n",
      "Epoch: 124/750 Iteration: 1120 Validation loss: 0.198520 Validation acc: 0.921667\n",
      "Epoch: 124/750 Iteration: 1125 Train loss: 0.213941 Train acc: 0.930000\n",
      "Epoch: 125/750 Iteration: 1130 Train loss: 0.215899 Train acc: 0.928333\n",
      "Epoch: 125/750 Iteration: 1130 Validation loss: 0.196215 Validation acc: 0.925000\n",
      "Epoch: 126/750 Iteration: 1135 Train loss: 0.197981 Train acc: 0.931667\n",
      "Epoch: 126/750 Iteration: 1140 Train loss: 0.185690 Train acc: 0.933333\n",
      "Epoch: 126/750 Iteration: 1140 Validation loss: 0.194756 Validation acc: 0.924444\n",
      "Epoch: 127/750 Iteration: 1145 Train loss: 0.202442 Train acc: 0.928333\n",
      "Epoch: 127/750 Iteration: 1150 Train loss: 0.202371 Train acc: 0.933333\n",
      "Epoch: 127/750 Iteration: 1150 Validation loss: 0.193023 Validation acc: 0.925556\n",
      "Epoch: 128/750 Iteration: 1155 Train loss: 0.222976 Train acc: 0.903333\n",
      "Epoch: 128/750 Iteration: 1160 Train loss: 0.171497 Train acc: 0.938333\n",
      "Epoch: 128/750 Iteration: 1160 Validation loss: 0.191100 Validation acc: 0.928889\n",
      "Epoch: 129/750 Iteration: 1165 Train loss: 0.227457 Train acc: 0.918333\n",
      "Epoch: 129/750 Iteration: 1170 Train loss: 0.198353 Train acc: 0.925000\n",
      "Epoch: 129/750 Iteration: 1170 Validation loss: 0.189737 Validation acc: 0.928333\n",
      "Epoch: 130/750 Iteration: 1175 Train loss: 0.202793 Train acc: 0.938333\n",
      "Epoch: 131/750 Iteration: 1180 Train loss: 0.173331 Train acc: 0.938333\n",
      "Epoch: 131/750 Iteration: 1180 Validation loss: 0.188076 Validation acc: 0.927778\n",
      "Epoch: 131/750 Iteration: 1185 Train loss: 0.177351 Train acc: 0.926667\n",
      "Epoch: 132/750 Iteration: 1190 Train loss: 0.193837 Train acc: 0.943333\n",
      "Epoch: 132/750 Iteration: 1190 Validation loss: 0.186806 Validation acc: 0.927778\n",
      "Epoch: 132/750 Iteration: 1195 Train loss: 0.202007 Train acc: 0.936667\n",
      "Epoch: 133/750 Iteration: 1200 Train loss: 0.201916 Train acc: 0.926667\n",
      "Epoch: 133/750 Iteration: 1200 Validation loss: 0.184748 Validation acc: 0.930556\n",
      "Epoch: 133/750 Iteration: 1205 Train loss: 0.164266 Train acc: 0.948333\n",
      "Epoch: 134/750 Iteration: 1210 Train loss: 0.228461 Train acc: 0.901667\n",
      "Epoch: 134/750 Iteration: 1210 Validation loss: 0.183073 Validation acc: 0.929444\n",
      "Epoch: 134/750 Iteration: 1215 Train loss: 0.204142 Train acc: 0.930000\n",
      "Epoch: 135/750 Iteration: 1220 Train loss: 0.197666 Train acc: 0.923333\n",
      "Epoch: 135/750 Iteration: 1220 Validation loss: 0.181682 Validation acc: 0.930000\n",
      "Epoch: 136/750 Iteration: 1225 Train loss: 0.189795 Train acc: 0.926667\n",
      "Epoch: 136/750 Iteration: 1230 Train loss: 0.178563 Train acc: 0.930000\n",
      "Epoch: 136/750 Iteration: 1230 Validation loss: 0.180416 Validation acc: 0.930000\n",
      "Epoch: 137/750 Iteration: 1235 Train loss: 0.182588 Train acc: 0.943333\n",
      "Epoch: 137/750 Iteration: 1240 Train loss: 0.189629 Train acc: 0.936667\n",
      "Epoch: 137/750 Iteration: 1240 Validation loss: 0.178982 Validation acc: 0.931111\n",
      "Epoch: 138/750 Iteration: 1245 Train loss: 0.195826 Train acc: 0.921667\n",
      "Epoch: 138/750 Iteration: 1250 Train loss: 0.157032 Train acc: 0.953333\n",
      "Epoch: 138/750 Iteration: 1250 Validation loss: 0.177418 Validation acc: 0.931111\n",
      "Epoch: 139/750 Iteration: 1255 Train loss: 0.224298 Train acc: 0.910000\n",
      "Epoch: 139/750 Iteration: 1260 Train loss: 0.195836 Train acc: 0.931667\n",
      "Epoch: 139/750 Iteration: 1260 Validation loss: 0.175958 Validation acc: 0.932778\n",
      "Epoch: 140/750 Iteration: 1265 Train loss: 0.193769 Train acc: 0.936667\n",
      "Epoch: 141/750 Iteration: 1270 Train loss: 0.160297 Train acc: 0.933333\n",
      "Epoch: 141/750 Iteration: 1270 Validation loss: 0.174600 Validation acc: 0.932778\n",
      "Epoch: 141/750 Iteration: 1275 Train loss: 0.164444 Train acc: 0.945000\n",
      "Epoch: 142/750 Iteration: 1280 Train loss: 0.177968 Train acc: 0.948333\n",
      "Epoch: 142/750 Iteration: 1280 Validation loss: 0.173355 Validation acc: 0.933889\n",
      "Epoch: 142/750 Iteration: 1285 Train loss: 0.187580 Train acc: 0.931667\n",
      "Epoch: 143/750 Iteration: 1290 Train loss: 0.191594 Train acc: 0.920000\n",
      "Epoch: 143/750 Iteration: 1290 Validation loss: 0.172020 Validation acc: 0.933889\n",
      "Epoch: 143/750 Iteration: 1295 Train loss: 0.150840 Train acc: 0.946667\n",
      "Epoch: 144/750 Iteration: 1300 Train loss: 0.217899 Train acc: 0.918333\n",
      "Epoch: 144/750 Iteration: 1300 Validation loss: 0.171469 Validation acc: 0.933889\n",
      "Epoch: 144/750 Iteration: 1305 Train loss: 0.175205 Train acc: 0.938333\n",
      "Epoch: 145/750 Iteration: 1310 Train loss: 0.176708 Train acc: 0.940000\n",
      "Epoch: 145/750 Iteration: 1310 Validation loss: 0.169713 Validation acc: 0.936111\n",
      "Epoch: 146/750 Iteration: 1315 Train loss: 0.177857 Train acc: 0.930000\n",
      "Epoch: 146/750 Iteration: 1320 Train loss: 0.163210 Train acc: 0.935000\n",
      "Epoch: 146/750 Iteration: 1320 Validation loss: 0.169265 Validation acc: 0.933889\n",
      "Epoch: 147/750 Iteration: 1325 Train loss: 0.165436 Train acc: 0.943333\n",
      "Epoch: 147/750 Iteration: 1330 Train loss: 0.168660 Train acc: 0.948333\n",
      "Epoch: 147/750 Iteration: 1330 Validation loss: 0.167491 Validation acc: 0.937222\n",
      "Epoch: 148/750 Iteration: 1335 Train loss: 0.202633 Train acc: 0.931667\n",
      "Epoch: 148/750 Iteration: 1340 Train loss: 0.148808 Train acc: 0.946667\n",
      "Epoch: 148/750 Iteration: 1340 Validation loss: 0.166583 Validation acc: 0.937778\n",
      "Epoch: 149/750 Iteration: 1345 Train loss: 0.210027 Train acc: 0.918333\n",
      "Epoch: 149/750 Iteration: 1350 Train loss: 0.172548 Train acc: 0.941667\n",
      "Epoch: 149/750 Iteration: 1350 Validation loss: 0.165600 Validation acc: 0.937222\n",
      "Epoch: 150/750 Iteration: 1355 Train loss: 0.165853 Train acc: 0.946667\n",
      "Epoch: 151/750 Iteration: 1360 Train loss: 0.152043 Train acc: 0.936667\n",
      "Epoch: 151/750 Iteration: 1360 Validation loss: 0.164182 Validation acc: 0.937778\n",
      "Epoch: 151/750 Iteration: 1365 Train loss: 0.153201 Train acc: 0.936667\n",
      "Epoch: 152/750 Iteration: 1370 Train loss: 0.159566 Train acc: 0.950000\n",
      "Epoch: 152/750 Iteration: 1370 Validation loss: 0.163272 Validation acc: 0.939444\n",
      "Epoch: 152/750 Iteration: 1375 Train loss: 0.175360 Train acc: 0.945000\n",
      "Epoch: 153/750 Iteration: 1380 Train loss: 0.197819 Train acc: 0.915000\n",
      "Epoch: 153/750 Iteration: 1380 Validation loss: 0.162002 Validation acc: 0.938889\n",
      "Epoch: 153/750 Iteration: 1385 Train loss: 0.139888 Train acc: 0.948333\n",
      "Epoch: 154/750 Iteration: 1390 Train loss: 0.202579 Train acc: 0.923333\n",
      "Epoch: 154/750 Iteration: 1390 Validation loss: 0.161246 Validation acc: 0.938889\n",
      "Epoch: 154/750 Iteration: 1395 Train loss: 0.174076 Train acc: 0.933333\n",
      "Epoch: 155/750 Iteration: 1400 Train loss: 0.158176 Train acc: 0.948333\n",
      "Epoch: 155/750 Iteration: 1400 Validation loss: 0.160137 Validation acc: 0.940000\n",
      "Epoch: 156/750 Iteration: 1405 Train loss: 0.157504 Train acc: 0.945000\n",
      "Epoch: 156/750 Iteration: 1410 Train loss: 0.145294 Train acc: 0.950000\n",
      "Epoch: 156/750 Iteration: 1410 Validation loss: 0.159221 Validation acc: 0.941111\n",
      "Epoch: 157/750 Iteration: 1415 Train loss: 0.152221 Train acc: 0.953333\n",
      "Epoch: 157/750 Iteration: 1420 Train loss: 0.170758 Train acc: 0.938333\n",
      "Epoch: 157/750 Iteration: 1420 Validation loss: 0.158307 Validation acc: 0.939444\n",
      "Epoch: 158/750 Iteration: 1425 Train loss: 0.179096 Train acc: 0.920000\n",
      "Epoch: 158/750 Iteration: 1430 Train loss: 0.144562 Train acc: 0.945000\n",
      "Epoch: 158/750 Iteration: 1430 Validation loss: 0.157378 Validation acc: 0.940000\n",
      "Epoch: 159/750 Iteration: 1435 Train loss: 0.197393 Train acc: 0.925000\n",
      "Epoch: 159/750 Iteration: 1440 Train loss: 0.170814 Train acc: 0.941667\n",
      "Epoch: 159/750 Iteration: 1440 Validation loss: 0.156481 Validation acc: 0.939444\n",
      "Epoch: 160/750 Iteration: 1445 Train loss: 0.162701 Train acc: 0.945000\n",
      "Epoch: 161/750 Iteration: 1450 Train loss: 0.151228 Train acc: 0.938333\n",
      "Epoch: 161/750 Iteration: 1450 Validation loss: 0.155809 Validation acc: 0.939444\n",
      "Epoch: 161/750 Iteration: 1455 Train loss: 0.139827 Train acc: 0.946667\n",
      "Epoch: 162/750 Iteration: 1460 Train loss: 0.158961 Train acc: 0.941667\n",
      "Epoch: 162/750 Iteration: 1460 Validation loss: 0.155146 Validation acc: 0.940000\n",
      "Epoch: 162/750 Iteration: 1465 Train loss: 0.159168 Train acc: 0.941667\n",
      "Epoch: 163/750 Iteration: 1470 Train loss: 0.171084 Train acc: 0.925000\n",
      "Epoch: 163/750 Iteration: 1470 Validation loss: 0.153705 Validation acc: 0.940556\n",
      "Epoch: 163/750 Iteration: 1475 Train loss: 0.134817 Train acc: 0.951667\n",
      "Epoch: 164/750 Iteration: 1480 Train loss: 0.205854 Train acc: 0.923333\n",
      "Epoch: 164/750 Iteration: 1480 Validation loss: 0.152986 Validation acc: 0.941667\n",
      "Epoch: 164/750 Iteration: 1485 Train loss: 0.160040 Train acc: 0.950000\n",
      "Epoch: 165/750 Iteration: 1490 Train loss: 0.163399 Train acc: 0.940000\n",
      "Epoch: 165/750 Iteration: 1490 Validation loss: 0.152079 Validation acc: 0.943333\n",
      "Epoch: 166/750 Iteration: 1495 Train loss: 0.137407 Train acc: 0.953333\n",
      "Epoch: 166/750 Iteration: 1500 Train loss: 0.137115 Train acc: 0.945000\n",
      "Epoch: 166/750 Iteration: 1500 Validation loss: 0.151389 Validation acc: 0.941111\n",
      "Epoch: 167/750 Iteration: 1505 Train loss: 0.144155 Train acc: 0.948333\n",
      "Epoch: 167/750 Iteration: 1510 Train loss: 0.152978 Train acc: 0.940000\n",
      "Epoch: 167/750 Iteration: 1510 Validation loss: 0.150146 Validation acc: 0.941667\n",
      "Epoch: 168/750 Iteration: 1515 Train loss: 0.179173 Train acc: 0.928333\n",
      "Epoch: 168/750 Iteration: 1520 Train loss: 0.122816 Train acc: 0.958333\n",
      "Epoch: 168/750 Iteration: 1520 Validation loss: 0.149614 Validation acc: 0.941667\n",
      "Epoch: 169/750 Iteration: 1525 Train loss: 0.189488 Train acc: 0.928333\n",
      "Epoch: 169/750 Iteration: 1530 Train loss: 0.159506 Train acc: 0.941667\n",
      "Epoch: 169/750 Iteration: 1530 Validation loss: 0.149195 Validation acc: 0.940000\n",
      "Epoch: 170/750 Iteration: 1535 Train loss: 0.164243 Train acc: 0.940000\n",
      "Epoch: 171/750 Iteration: 1540 Train loss: 0.147039 Train acc: 0.948333\n",
      "Epoch: 171/750 Iteration: 1540 Validation loss: 0.148150 Validation acc: 0.941111\n",
      "Epoch: 171/750 Iteration: 1545 Train loss: 0.133773 Train acc: 0.948333\n",
      "Epoch: 172/750 Iteration: 1550 Train loss: 0.144164 Train acc: 0.950000\n",
      "Epoch: 172/750 Iteration: 1550 Validation loss: 0.147918 Validation acc: 0.940556\n",
      "Epoch: 172/750 Iteration: 1555 Train loss: 0.147694 Train acc: 0.945000\n",
      "Epoch: 173/750 Iteration: 1560 Train loss: 0.167211 Train acc: 0.926667\n",
      "Epoch: 173/750 Iteration: 1560 Validation loss: 0.146763 Validation acc: 0.941667\n",
      "Epoch: 173/750 Iteration: 1565 Train loss: 0.129235 Train acc: 0.956667\n",
      "Epoch: 174/750 Iteration: 1570 Train loss: 0.183182 Train acc: 0.931667\n",
      "Epoch: 174/750 Iteration: 1570 Validation loss: 0.146022 Validation acc: 0.945000\n",
      "Epoch: 174/750 Iteration: 1575 Train loss: 0.154303 Train acc: 0.945000\n",
      "Epoch: 175/750 Iteration: 1580 Train loss: 0.149300 Train acc: 0.951667\n",
      "Epoch: 175/750 Iteration: 1580 Validation loss: 0.145516 Validation acc: 0.942222\n",
      "Epoch: 176/750 Iteration: 1585 Train loss: 0.134939 Train acc: 0.941667\n",
      "Epoch: 176/750 Iteration: 1590 Train loss: 0.134762 Train acc: 0.951667\n",
      "Epoch: 176/750 Iteration: 1590 Validation loss: 0.145275 Validation acc: 0.943889\n",
      "Epoch: 177/750 Iteration: 1595 Train loss: 0.149596 Train acc: 0.945000\n",
      "Epoch: 177/750 Iteration: 1600 Train loss: 0.144747 Train acc: 0.951667\n",
      "Epoch: 177/750 Iteration: 1600 Validation loss: 0.144398 Validation acc: 0.943889\n",
      "Epoch: 178/750 Iteration: 1605 Train loss: 0.172536 Train acc: 0.925000\n",
      "Epoch: 178/750 Iteration: 1610 Train loss: 0.122515 Train acc: 0.960000\n",
      "Epoch: 178/750 Iteration: 1610 Validation loss: 0.143968 Validation acc: 0.943333\n",
      "Epoch: 179/750 Iteration: 1615 Train loss: 0.186376 Train acc: 0.923333\n",
      "Epoch: 179/750 Iteration: 1620 Train loss: 0.153889 Train acc: 0.946667\n",
      "Epoch: 179/750 Iteration: 1620 Validation loss: 0.143446 Validation acc: 0.945556\n",
      "Epoch: 180/750 Iteration: 1625 Train loss: 0.139553 Train acc: 0.955000\n",
      "Epoch: 181/750 Iteration: 1630 Train loss: 0.136408 Train acc: 0.956667\n",
      "Epoch: 181/750 Iteration: 1630 Validation loss: 0.142589 Validation acc: 0.943889\n",
      "Epoch: 181/750 Iteration: 1635 Train loss: 0.133587 Train acc: 0.946667\n",
      "Epoch: 182/750 Iteration: 1640 Train loss: 0.142916 Train acc: 0.951667\n",
      "Epoch: 182/750 Iteration: 1640 Validation loss: 0.142263 Validation acc: 0.943333\n",
      "Epoch: 182/750 Iteration: 1645 Train loss: 0.142548 Train acc: 0.945000\n",
      "Epoch: 183/750 Iteration: 1650 Train loss: 0.172313 Train acc: 0.925000\n",
      "Epoch: 183/750 Iteration: 1650 Validation loss: 0.141440 Validation acc: 0.946667\n",
      "Epoch: 183/750 Iteration: 1655 Train loss: 0.108983 Train acc: 0.963333\n",
      "Epoch: 184/750 Iteration: 1660 Train loss: 0.179832 Train acc: 0.918333\n",
      "Epoch: 184/750 Iteration: 1660 Validation loss: 0.140595 Validation acc: 0.946111\n",
      "Epoch: 184/750 Iteration: 1665 Train loss: 0.154356 Train acc: 0.945000\n",
      "Epoch: 185/750 Iteration: 1670 Train loss: 0.148462 Train acc: 0.950000\n",
      "Epoch: 185/750 Iteration: 1670 Validation loss: 0.140300 Validation acc: 0.947222\n",
      "Epoch: 186/750 Iteration: 1675 Train loss: 0.139284 Train acc: 0.943333\n",
      "Epoch: 186/750 Iteration: 1680 Train loss: 0.128159 Train acc: 0.946667\n",
      "Epoch: 186/750 Iteration: 1680 Validation loss: 0.139723 Validation acc: 0.947222\n",
      "Epoch: 187/750 Iteration: 1685 Train loss: 0.137084 Train acc: 0.953333\n",
      "Epoch: 187/750 Iteration: 1690 Train loss: 0.138189 Train acc: 0.950000\n",
      "Epoch: 187/750 Iteration: 1690 Validation loss: 0.139520 Validation acc: 0.947778\n",
      "Epoch: 188/750 Iteration: 1695 Train loss: 0.163370 Train acc: 0.926667\n",
      "Epoch: 188/750 Iteration: 1700 Train loss: 0.112565 Train acc: 0.961667\n",
      "Epoch: 188/750 Iteration: 1700 Validation loss: 0.138995 Validation acc: 0.946111\n",
      "Epoch: 189/750 Iteration: 1705 Train loss: 0.182412 Train acc: 0.928333\n",
      "Epoch: 189/750 Iteration: 1710 Train loss: 0.151624 Train acc: 0.948333\n",
      "Epoch: 189/750 Iteration: 1710 Validation loss: 0.138492 Validation acc: 0.946667\n",
      "Epoch: 190/750 Iteration: 1715 Train loss: 0.151121 Train acc: 0.941667\n",
      "Epoch: 191/750 Iteration: 1720 Train loss: 0.132535 Train acc: 0.943333\n",
      "Epoch: 191/750 Iteration: 1720 Validation loss: 0.138008 Validation acc: 0.946667\n",
      "Epoch: 191/750 Iteration: 1725 Train loss: 0.127833 Train acc: 0.953333\n",
      "Epoch: 192/750 Iteration: 1730 Train loss: 0.133963 Train acc: 0.950000\n",
      "Epoch: 192/750 Iteration: 1730 Validation loss: 0.137443 Validation acc: 0.944444\n",
      "Epoch: 192/750 Iteration: 1735 Train loss: 0.144708 Train acc: 0.946667\n",
      "Epoch: 193/750 Iteration: 1740 Train loss: 0.151165 Train acc: 0.935000\n",
      "Epoch: 193/750 Iteration: 1740 Validation loss: 0.137173 Validation acc: 0.947222\n",
      "Epoch: 193/750 Iteration: 1745 Train loss: 0.104833 Train acc: 0.960000\n",
      "Epoch: 194/750 Iteration: 1750 Train loss: 0.169965 Train acc: 0.933333\n",
      "Epoch: 194/750 Iteration: 1750 Validation loss: 0.137021 Validation acc: 0.947222\n",
      "Epoch: 194/750 Iteration: 1755 Train loss: 0.143226 Train acc: 0.948333\n",
      "Epoch: 195/750 Iteration: 1760 Train loss: 0.142386 Train acc: 0.955000\n",
      "Epoch: 195/750 Iteration: 1760 Validation loss: 0.136080 Validation acc: 0.947778\n",
      "Epoch: 196/750 Iteration: 1765 Train loss: 0.137731 Train acc: 0.935000\n",
      "Epoch: 196/750 Iteration: 1770 Train loss: 0.124939 Train acc: 0.956667\n",
      "Epoch: 196/750 Iteration: 1770 Validation loss: 0.135645 Validation acc: 0.948889\n",
      "Epoch: 197/750 Iteration: 1775 Train loss: 0.135300 Train acc: 0.953333\n",
      "Epoch: 197/750 Iteration: 1780 Train loss: 0.135330 Train acc: 0.948333\n",
      "Epoch: 197/750 Iteration: 1780 Validation loss: 0.135386 Validation acc: 0.948333\n",
      "Epoch: 198/750 Iteration: 1785 Train loss: 0.163723 Train acc: 0.930000\n",
      "Epoch: 198/750 Iteration: 1790 Train loss: 0.111078 Train acc: 0.960000\n",
      "Epoch: 198/750 Iteration: 1790 Validation loss: 0.134826 Validation acc: 0.948889\n",
      "Epoch: 199/750 Iteration: 1795 Train loss: 0.172681 Train acc: 0.928333\n",
      "Epoch: 199/750 Iteration: 1800 Train loss: 0.137366 Train acc: 0.948333\n",
      "Epoch: 199/750 Iteration: 1800 Validation loss: 0.134566 Validation acc: 0.948889\n",
      "Epoch: 200/750 Iteration: 1805 Train loss: 0.133351 Train acc: 0.958333\n",
      "Epoch: 201/750 Iteration: 1810 Train loss: 0.126230 Train acc: 0.950000\n",
      "Epoch: 201/750 Iteration: 1810 Validation loss: 0.133843 Validation acc: 0.948889\n",
      "Epoch: 201/750 Iteration: 1815 Train loss: 0.125465 Train acc: 0.955000\n",
      "Epoch: 202/750 Iteration: 1820 Train loss: 0.128994 Train acc: 0.950000\n",
      "Epoch: 202/750 Iteration: 1820 Validation loss: 0.133690 Validation acc: 0.947778\n",
      "Epoch: 202/750 Iteration: 1825 Train loss: 0.128957 Train acc: 0.958333\n",
      "Epoch: 203/750 Iteration: 1830 Train loss: 0.156163 Train acc: 0.930000\n",
      "Epoch: 203/750 Iteration: 1830 Validation loss: 0.132845 Validation acc: 0.951111\n",
      "Epoch: 203/750 Iteration: 1835 Train loss: 0.109154 Train acc: 0.958333\n",
      "Epoch: 204/750 Iteration: 1840 Train loss: 0.161361 Train acc: 0.936667\n",
      "Epoch: 204/750 Iteration: 1840 Validation loss: 0.133365 Validation acc: 0.947222\n",
      "Epoch: 204/750 Iteration: 1845 Train loss: 0.138685 Train acc: 0.948333\n",
      "Epoch: 205/750 Iteration: 1850 Train loss: 0.133493 Train acc: 0.950000\n",
      "Epoch: 205/750 Iteration: 1850 Validation loss: 0.132642 Validation acc: 0.947222\n",
      "Epoch: 206/750 Iteration: 1855 Train loss: 0.115653 Train acc: 0.958333\n",
      "Epoch: 206/750 Iteration: 1860 Train loss: 0.123601 Train acc: 0.946667\n",
      "Epoch: 206/750 Iteration: 1860 Validation loss: 0.131740 Validation acc: 0.950556\n",
      "Epoch: 207/750 Iteration: 1865 Train loss: 0.134593 Train acc: 0.953333\n",
      "Epoch: 207/750 Iteration: 1870 Train loss: 0.137958 Train acc: 0.951667\n",
      "Epoch: 207/750 Iteration: 1870 Validation loss: 0.131708 Validation acc: 0.947778\n",
      "Epoch: 208/750 Iteration: 1875 Train loss: 0.157539 Train acc: 0.926667\n",
      "Epoch: 208/750 Iteration: 1880 Train loss: 0.106755 Train acc: 0.965000\n",
      "Epoch: 208/750 Iteration: 1880 Validation loss: 0.131508 Validation acc: 0.948333\n",
      "Epoch: 209/750 Iteration: 1885 Train loss: 0.168158 Train acc: 0.926667\n",
      "Epoch: 209/750 Iteration: 1890 Train loss: 0.144843 Train acc: 0.946667\n",
      "Epoch: 209/750 Iteration: 1890 Validation loss: 0.131082 Validation acc: 0.951111\n",
      "Epoch: 210/750 Iteration: 1895 Train loss: 0.131451 Train acc: 0.950000\n",
      "Epoch: 211/750 Iteration: 1900 Train loss: 0.116710 Train acc: 0.955000\n",
      "Epoch: 211/750 Iteration: 1900 Validation loss: 0.130823 Validation acc: 0.948333\n",
      "Epoch: 211/750 Iteration: 1905 Train loss: 0.118133 Train acc: 0.955000\n",
      "Epoch: 212/750 Iteration: 1910 Train loss: 0.130912 Train acc: 0.951667\n",
      "Epoch: 212/750 Iteration: 1910 Validation loss: 0.130210 Validation acc: 0.947778\n",
      "Epoch: 212/750 Iteration: 1915 Train loss: 0.130383 Train acc: 0.960000\n",
      "Epoch: 213/750 Iteration: 1920 Train loss: 0.147383 Train acc: 0.931667\n",
      "Epoch: 213/750 Iteration: 1920 Validation loss: 0.130222 Validation acc: 0.948889\n",
      "Epoch: 213/750 Iteration: 1925 Train loss: 0.106795 Train acc: 0.956667\n",
      "Epoch: 214/750 Iteration: 1930 Train loss: 0.165488 Train acc: 0.926667\n",
      "Epoch: 214/750 Iteration: 1930 Validation loss: 0.129730 Validation acc: 0.948333\n",
      "Epoch: 214/750 Iteration: 1935 Train loss: 0.136302 Train acc: 0.950000\n",
      "Epoch: 215/750 Iteration: 1940 Train loss: 0.128726 Train acc: 0.950000\n",
      "Epoch: 215/750 Iteration: 1940 Validation loss: 0.129179 Validation acc: 0.949444\n",
      "Epoch: 216/750 Iteration: 1945 Train loss: 0.121897 Train acc: 0.950000\n",
      "Epoch: 216/750 Iteration: 1950 Train loss: 0.115395 Train acc: 0.955000\n",
      "Epoch: 216/750 Iteration: 1950 Validation loss: 0.128835 Validation acc: 0.948889\n",
      "Epoch: 217/750 Iteration: 1955 Train loss: 0.122026 Train acc: 0.951667\n",
      "Epoch: 217/750 Iteration: 1960 Train loss: 0.123322 Train acc: 0.953333\n",
      "Epoch: 217/750 Iteration: 1960 Validation loss: 0.128364 Validation acc: 0.948889\n",
      "Epoch: 218/750 Iteration: 1965 Train loss: 0.151296 Train acc: 0.935000\n",
      "Epoch: 218/750 Iteration: 1970 Train loss: 0.100712 Train acc: 0.958333\n",
      "Epoch: 218/750 Iteration: 1970 Validation loss: 0.128060 Validation acc: 0.950000\n",
      "Epoch: 219/750 Iteration: 1975 Train loss: 0.165637 Train acc: 0.931667\n",
      "Epoch: 219/750 Iteration: 1980 Train loss: 0.144420 Train acc: 0.946667\n",
      "Epoch: 219/750 Iteration: 1980 Validation loss: 0.127880 Validation acc: 0.948333\n",
      "Epoch: 220/750 Iteration: 1985 Train loss: 0.125464 Train acc: 0.953333\n",
      "Epoch: 221/750 Iteration: 1990 Train loss: 0.122752 Train acc: 0.955000\n",
      "Epoch: 221/750 Iteration: 1990 Validation loss: 0.127465 Validation acc: 0.948889\n",
      "Epoch: 221/750 Iteration: 1995 Train loss: 0.117179 Train acc: 0.951667\n",
      "Epoch: 222/750 Iteration: 2000 Train loss: 0.122858 Train acc: 0.955000\n",
      "Epoch: 222/750 Iteration: 2000 Validation loss: 0.126896 Validation acc: 0.947778\n",
      "Epoch: 222/750 Iteration: 2005 Train loss: 0.127401 Train acc: 0.953333\n",
      "Epoch: 223/750 Iteration: 2010 Train loss: 0.141648 Train acc: 0.936667\n",
      "Epoch: 223/750 Iteration: 2010 Validation loss: 0.126902 Validation acc: 0.950000\n",
      "Epoch: 223/750 Iteration: 2015 Train loss: 0.100288 Train acc: 0.955000\n",
      "Epoch: 224/750 Iteration: 2020 Train loss: 0.157299 Train acc: 0.935000\n",
      "Epoch: 224/750 Iteration: 2020 Validation loss: 0.126614 Validation acc: 0.949444\n",
      "Epoch: 224/750 Iteration: 2025 Train loss: 0.137134 Train acc: 0.945000\n",
      "Epoch: 225/750 Iteration: 2030 Train loss: 0.126655 Train acc: 0.958333\n",
      "Epoch: 225/750 Iteration: 2030 Validation loss: 0.126293 Validation acc: 0.950000\n",
      "Epoch: 226/750 Iteration: 2035 Train loss: 0.109796 Train acc: 0.955000\n",
      "Epoch: 226/750 Iteration: 2040 Train loss: 0.117683 Train acc: 0.956667\n",
      "Epoch: 226/750 Iteration: 2040 Validation loss: 0.126231 Validation acc: 0.950000\n",
      "Epoch: 227/750 Iteration: 2045 Train loss: 0.122748 Train acc: 0.953333\n",
      "Epoch: 227/750 Iteration: 2050 Train loss: 0.130900 Train acc: 0.951667\n",
      "Epoch: 227/750 Iteration: 2050 Validation loss: 0.126014 Validation acc: 0.948333\n",
      "Epoch: 228/750 Iteration: 2055 Train loss: 0.153925 Train acc: 0.926667\n",
      "Epoch: 228/750 Iteration: 2060 Train loss: 0.098805 Train acc: 0.968333\n",
      "Epoch: 228/750 Iteration: 2060 Validation loss: 0.125551 Validation acc: 0.949444\n",
      "Epoch: 229/750 Iteration: 2065 Train loss: 0.153332 Train acc: 0.933333\n",
      "Epoch: 229/750 Iteration: 2070 Train loss: 0.130781 Train acc: 0.956667\n",
      "Epoch: 229/750 Iteration: 2070 Validation loss: 0.125349 Validation acc: 0.948889\n",
      "Epoch: 230/750 Iteration: 2075 Train loss: 0.122129 Train acc: 0.953333\n",
      "Epoch: 231/750 Iteration: 2080 Train loss: 0.111564 Train acc: 0.948333\n",
      "Epoch: 231/750 Iteration: 2080 Validation loss: 0.125176 Validation acc: 0.948889\n",
      "Epoch: 231/750 Iteration: 2085 Train loss: 0.118117 Train acc: 0.951667\n",
      "Epoch: 232/750 Iteration: 2090 Train loss: 0.112098 Train acc: 0.961667\n",
      "Epoch: 232/750 Iteration: 2090 Validation loss: 0.124673 Validation acc: 0.949444\n",
      "Epoch: 232/750 Iteration: 2095 Train loss: 0.125889 Train acc: 0.953333\n",
      "Epoch: 233/750 Iteration: 2100 Train loss: 0.145314 Train acc: 0.935000\n",
      "Epoch: 233/750 Iteration: 2100 Validation loss: 0.124738 Validation acc: 0.950000\n",
      "Epoch: 233/750 Iteration: 2105 Train loss: 0.098305 Train acc: 0.961667\n",
      "Epoch: 234/750 Iteration: 2110 Train loss: 0.160953 Train acc: 0.933333\n",
      "Epoch: 234/750 Iteration: 2110 Validation loss: 0.124342 Validation acc: 0.948889\n",
      "Epoch: 234/750 Iteration: 2115 Train loss: 0.135631 Train acc: 0.946667\n",
      "Epoch: 235/750 Iteration: 2120 Train loss: 0.124174 Train acc: 0.955000\n",
      "Epoch: 235/750 Iteration: 2120 Validation loss: 0.123815 Validation acc: 0.950556\n",
      "Epoch: 236/750 Iteration: 2125 Train loss: 0.115181 Train acc: 0.958333\n",
      "Epoch: 236/750 Iteration: 2130 Train loss: 0.118581 Train acc: 0.951667\n",
      "Epoch: 236/750 Iteration: 2130 Validation loss: 0.124227 Validation acc: 0.950556\n",
      "Epoch: 237/750 Iteration: 2135 Train loss: 0.113495 Train acc: 0.958333\n",
      "Epoch: 237/750 Iteration: 2140 Train loss: 0.123418 Train acc: 0.956667\n",
      "Epoch: 237/750 Iteration: 2140 Validation loss: 0.124002 Validation acc: 0.947222\n",
      "Epoch: 238/750 Iteration: 2145 Train loss: 0.140259 Train acc: 0.941667\n",
      "Epoch: 238/750 Iteration: 2150 Train loss: 0.095387 Train acc: 0.965000\n",
      "Epoch: 238/750 Iteration: 2150 Validation loss: 0.123264 Validation acc: 0.950000\n",
      "Epoch: 239/750 Iteration: 2155 Train loss: 0.154715 Train acc: 0.930000\n",
      "Epoch: 239/750 Iteration: 2160 Train loss: 0.127330 Train acc: 0.950000\n",
      "Epoch: 239/750 Iteration: 2160 Validation loss: 0.122947 Validation acc: 0.950000\n",
      "Epoch: 240/750 Iteration: 2165 Train loss: 0.122082 Train acc: 0.950000\n",
      "Epoch: 241/750 Iteration: 2170 Train loss: 0.105886 Train acc: 0.961667\n",
      "Epoch: 241/750 Iteration: 2170 Validation loss: 0.122657 Validation acc: 0.949444\n",
      "Epoch: 241/750 Iteration: 2175 Train loss: 0.115603 Train acc: 0.948333\n",
      "Epoch: 242/750 Iteration: 2180 Train loss: 0.115470 Train acc: 0.958333\n",
      "Epoch: 242/750 Iteration: 2180 Validation loss: 0.122793 Validation acc: 0.950000\n",
      "Epoch: 242/750 Iteration: 2185 Train loss: 0.119591 Train acc: 0.948333\n",
      "Epoch: 243/750 Iteration: 2190 Train loss: 0.146168 Train acc: 0.931667\n",
      "Epoch: 243/750 Iteration: 2190 Validation loss: 0.122110 Validation acc: 0.950556\n",
      "Epoch: 243/750 Iteration: 2195 Train loss: 0.095269 Train acc: 0.966667\n",
      "Epoch: 244/750 Iteration: 2200 Train loss: 0.155817 Train acc: 0.928333\n",
      "Epoch: 244/750 Iteration: 2200 Validation loss: 0.121732 Validation acc: 0.950556\n",
      "Epoch: 244/750 Iteration: 2205 Train loss: 0.124315 Train acc: 0.955000\n",
      "Epoch: 245/750 Iteration: 2210 Train loss: 0.122047 Train acc: 0.953333\n",
      "Epoch: 245/750 Iteration: 2210 Validation loss: 0.121670 Validation acc: 0.950556\n",
      "Epoch: 246/750 Iteration: 2215 Train loss: 0.107499 Train acc: 0.961667\n",
      "Epoch: 246/750 Iteration: 2220 Train loss: 0.113223 Train acc: 0.955000\n",
      "Epoch: 246/750 Iteration: 2220 Validation loss: 0.121468 Validation acc: 0.949444\n",
      "Epoch: 247/750 Iteration: 2225 Train loss: 0.116636 Train acc: 0.955000\n",
      "Epoch: 247/750 Iteration: 2230 Train loss: 0.116346 Train acc: 0.961667\n",
      "Epoch: 247/750 Iteration: 2230 Validation loss: 0.121207 Validation acc: 0.950000\n",
      "Epoch: 248/750 Iteration: 2235 Train loss: 0.139747 Train acc: 0.933333\n",
      "Epoch: 248/750 Iteration: 2240 Train loss: 0.087534 Train acc: 0.966667\n",
      "Epoch: 248/750 Iteration: 2240 Validation loss: 0.121222 Validation acc: 0.949444\n",
      "Epoch: 249/750 Iteration: 2245 Train loss: 0.144181 Train acc: 0.938333\n",
      "Epoch: 249/750 Iteration: 2250 Train loss: 0.127538 Train acc: 0.953333\n",
      "Epoch: 249/750 Iteration: 2250 Validation loss: 0.120749 Validation acc: 0.950000\n",
      "Epoch: 250/750 Iteration: 2255 Train loss: 0.118908 Train acc: 0.958333\n",
      "Epoch: 251/750 Iteration: 2260 Train loss: 0.111487 Train acc: 0.951667\n",
      "Epoch: 251/750 Iteration: 2260 Validation loss: 0.120560 Validation acc: 0.950000\n",
      "Epoch: 251/750 Iteration: 2265 Train loss: 0.118519 Train acc: 0.953333\n",
      "Epoch: 252/750 Iteration: 2270 Train loss: 0.120312 Train acc: 0.956667\n",
      "Epoch: 252/750 Iteration: 2270 Validation loss: 0.120283 Validation acc: 0.950000\n",
      "Epoch: 252/750 Iteration: 2275 Train loss: 0.116360 Train acc: 0.963333\n",
      "Epoch: 253/750 Iteration: 2280 Train loss: 0.141981 Train acc: 0.928333\n",
      "Epoch: 253/750 Iteration: 2280 Validation loss: 0.120352 Validation acc: 0.950000\n",
      "Epoch: 253/750 Iteration: 2285 Train loss: 0.089609 Train acc: 0.968333\n",
      "Epoch: 254/750 Iteration: 2290 Train loss: 0.142173 Train acc: 0.938333\n",
      "Epoch: 254/750 Iteration: 2290 Validation loss: 0.120017 Validation acc: 0.951111\n",
      "Epoch: 254/750 Iteration: 2295 Train loss: 0.119041 Train acc: 0.958333\n",
      "Epoch: 255/750 Iteration: 2300 Train loss: 0.114786 Train acc: 0.955000\n",
      "Epoch: 255/750 Iteration: 2300 Validation loss: 0.119582 Validation acc: 0.951667\n",
      "Epoch: 256/750 Iteration: 2305 Train loss: 0.106353 Train acc: 0.961667\n",
      "Epoch: 256/750 Iteration: 2310 Train loss: 0.113939 Train acc: 0.950000\n",
      "Epoch: 256/750 Iteration: 2310 Validation loss: 0.119557 Validation acc: 0.950000\n",
      "Epoch: 257/750 Iteration: 2315 Train loss: 0.115658 Train acc: 0.951667\n",
      "Epoch: 257/750 Iteration: 2320 Train loss: 0.116199 Train acc: 0.961667\n",
      "Epoch: 257/750 Iteration: 2320 Validation loss: 0.119474 Validation acc: 0.951111\n",
      "Epoch: 258/750 Iteration: 2325 Train loss: 0.143264 Train acc: 0.925000\n",
      "Epoch: 258/750 Iteration: 2330 Train loss: 0.094999 Train acc: 0.956667\n",
      "Epoch: 258/750 Iteration: 2330 Validation loss: 0.119341 Validation acc: 0.950000\n",
      "Epoch: 259/750 Iteration: 2335 Train loss: 0.149511 Train acc: 0.936667\n",
      "Epoch: 259/750 Iteration: 2340 Train loss: 0.120583 Train acc: 0.956667\n",
      "Epoch: 259/750 Iteration: 2340 Validation loss: 0.118940 Validation acc: 0.950556\n",
      "Epoch: 260/750 Iteration: 2345 Train loss: 0.122103 Train acc: 0.945000\n",
      "Epoch: 261/750 Iteration: 2350 Train loss: 0.104718 Train acc: 0.956667\n",
      "Epoch: 261/750 Iteration: 2350 Validation loss: 0.119109 Validation acc: 0.950000\n",
      "Epoch: 261/750 Iteration: 2355 Train loss: 0.109255 Train acc: 0.965000\n",
      "Epoch: 262/750 Iteration: 2360 Train loss: 0.106990 Train acc: 0.958333\n",
      "Epoch: 262/750 Iteration: 2360 Validation loss: 0.118983 Validation acc: 0.950556\n",
      "Epoch: 262/750 Iteration: 2365 Train loss: 0.112871 Train acc: 0.956667\n",
      "Epoch: 263/750 Iteration: 2370 Train loss: 0.139050 Train acc: 0.933333\n",
      "Epoch: 263/750 Iteration: 2370 Validation loss: 0.118624 Validation acc: 0.952778\n",
      "Epoch: 263/750 Iteration: 2375 Train loss: 0.096220 Train acc: 0.961667\n",
      "Epoch: 264/750 Iteration: 2380 Train loss: 0.144413 Train acc: 0.928333\n",
      "Epoch: 264/750 Iteration: 2380 Validation loss: 0.118744 Validation acc: 0.951111\n",
      "Epoch: 264/750 Iteration: 2385 Train loss: 0.126423 Train acc: 0.955000\n",
      "Epoch: 265/750 Iteration: 2390 Train loss: 0.118963 Train acc: 0.950000\n",
      "Epoch: 265/750 Iteration: 2390 Validation loss: 0.118499 Validation acc: 0.952222\n",
      "Epoch: 266/750 Iteration: 2395 Train loss: 0.098591 Train acc: 0.958333\n",
      "Epoch: 266/750 Iteration: 2400 Train loss: 0.103278 Train acc: 0.956667\n",
      "Epoch: 266/750 Iteration: 2400 Validation loss: 0.118001 Validation acc: 0.950556\n",
      "Epoch: 267/750 Iteration: 2405 Train loss: 0.106162 Train acc: 0.961667\n",
      "Epoch: 267/750 Iteration: 2410 Train loss: 0.111769 Train acc: 0.956667\n",
      "Epoch: 267/750 Iteration: 2410 Validation loss: 0.117799 Validation acc: 0.950000\n",
      "Epoch: 268/750 Iteration: 2415 Train loss: 0.133355 Train acc: 0.933333\n",
      "Epoch: 268/750 Iteration: 2420 Train loss: 0.093737 Train acc: 0.965000\n",
      "Epoch: 268/750 Iteration: 2420 Validation loss: 0.117843 Validation acc: 0.952222\n",
      "Epoch: 269/750 Iteration: 2425 Train loss: 0.145833 Train acc: 0.938333\n",
      "Epoch: 269/750 Iteration: 2430 Train loss: 0.121667 Train acc: 0.953333\n",
      "Epoch: 269/750 Iteration: 2430 Validation loss: 0.117651 Validation acc: 0.950556\n",
      "Epoch: 270/750 Iteration: 2435 Train loss: 0.114414 Train acc: 0.953333\n",
      "Epoch: 271/750 Iteration: 2440 Train loss: 0.106288 Train acc: 0.956667\n",
      "Epoch: 271/750 Iteration: 2440 Validation loss: 0.117520 Validation acc: 0.951667\n",
      "Epoch: 271/750 Iteration: 2445 Train loss: 0.107882 Train acc: 0.951667\n",
      "Epoch: 272/750 Iteration: 2450 Train loss: 0.107834 Train acc: 0.960000\n",
      "Epoch: 272/750 Iteration: 2450 Validation loss: 0.117082 Validation acc: 0.950556\n",
      "Epoch: 272/750 Iteration: 2455 Train loss: 0.112068 Train acc: 0.948333\n",
      "Epoch: 273/750 Iteration: 2460 Train loss: 0.137321 Train acc: 0.930000\n",
      "Epoch: 273/750 Iteration: 2460 Validation loss: 0.116640 Validation acc: 0.951667\n",
      "Epoch: 273/750 Iteration: 2465 Train loss: 0.096466 Train acc: 0.960000\n",
      "Epoch: 274/750 Iteration: 2470 Train loss: 0.148012 Train acc: 0.930000\n",
      "Epoch: 274/750 Iteration: 2470 Validation loss: 0.117004 Validation acc: 0.952222\n",
      "Epoch: 274/750 Iteration: 2475 Train loss: 0.121693 Train acc: 0.953333\n",
      "Epoch: 275/750 Iteration: 2480 Train loss: 0.111671 Train acc: 0.955000\n",
      "Epoch: 275/750 Iteration: 2480 Validation loss: 0.116626 Validation acc: 0.953889\n",
      "Epoch: 276/750 Iteration: 2485 Train loss: 0.102580 Train acc: 0.960000\n",
      "Epoch: 276/750 Iteration: 2490 Train loss: 0.107179 Train acc: 0.950000\n",
      "Epoch: 276/750 Iteration: 2490 Validation loss: 0.116455 Validation acc: 0.950556\n",
      "Epoch: 277/750 Iteration: 2495 Train loss: 0.110793 Train acc: 0.955000\n",
      "Epoch: 277/750 Iteration: 2500 Train loss: 0.113441 Train acc: 0.958333\n",
      "Epoch: 277/750 Iteration: 2500 Validation loss: 0.116188 Validation acc: 0.951111\n",
      "Epoch: 278/750 Iteration: 2505 Train loss: 0.130060 Train acc: 0.936667\n",
      "Epoch: 278/750 Iteration: 2510 Train loss: 0.088621 Train acc: 0.956667\n",
      "Epoch: 278/750 Iteration: 2510 Validation loss: 0.115983 Validation acc: 0.951667\n",
      "Epoch: 279/750 Iteration: 2515 Train loss: 0.149345 Train acc: 0.931667\n",
      "Epoch: 279/750 Iteration: 2520 Train loss: 0.116313 Train acc: 0.955000\n",
      "Epoch: 279/750 Iteration: 2520 Validation loss: 0.116147 Validation acc: 0.951111\n",
      "Epoch: 280/750 Iteration: 2525 Train loss: 0.115739 Train acc: 0.950000\n",
      "Epoch: 281/750 Iteration: 2530 Train loss: 0.102258 Train acc: 0.961667\n",
      "Epoch: 281/750 Iteration: 2530 Validation loss: 0.115667 Validation acc: 0.950556\n",
      "Epoch: 281/750 Iteration: 2535 Train loss: 0.106710 Train acc: 0.955000\n",
      "Epoch: 282/750 Iteration: 2540 Train loss: 0.102079 Train acc: 0.963333\n",
      "Epoch: 282/750 Iteration: 2540 Validation loss: 0.115579 Validation acc: 0.951111\n",
      "Epoch: 282/750 Iteration: 2545 Train loss: 0.108492 Train acc: 0.965000\n",
      "Epoch: 283/750 Iteration: 2550 Train loss: 0.132290 Train acc: 0.938333\n",
      "Epoch: 283/750 Iteration: 2550 Validation loss: 0.115372 Validation acc: 0.951111\n",
      "Epoch: 283/750 Iteration: 2555 Train loss: 0.090283 Train acc: 0.961667\n",
      "Epoch: 284/750 Iteration: 2560 Train loss: 0.139171 Train acc: 0.943333\n",
      "Epoch: 284/750 Iteration: 2560 Validation loss: 0.115354 Validation acc: 0.952778\n",
      "Epoch: 284/750 Iteration: 2565 Train loss: 0.115713 Train acc: 0.958333\n",
      "Epoch: 285/750 Iteration: 2570 Train loss: 0.119471 Train acc: 0.953333\n",
      "Epoch: 285/750 Iteration: 2570 Validation loss: 0.115537 Validation acc: 0.951111\n",
      "Epoch: 286/750 Iteration: 2575 Train loss: 0.098864 Train acc: 0.958333\n",
      "Epoch: 286/750 Iteration: 2580 Train loss: 0.104127 Train acc: 0.958333\n",
      "Epoch: 286/750 Iteration: 2580 Validation loss: 0.114939 Validation acc: 0.952778\n",
      "Epoch: 287/750 Iteration: 2585 Train loss: 0.104400 Train acc: 0.958333\n",
      "Epoch: 287/750 Iteration: 2590 Train loss: 0.108704 Train acc: 0.963333\n",
      "Epoch: 287/750 Iteration: 2590 Validation loss: 0.114902 Validation acc: 0.953333\n",
      "Epoch: 288/750 Iteration: 2595 Train loss: 0.124717 Train acc: 0.948333\n",
      "Epoch: 288/750 Iteration: 2600 Train loss: 0.088679 Train acc: 0.968333\n",
      "Epoch: 288/750 Iteration: 2600 Validation loss: 0.114695 Validation acc: 0.950556\n",
      "Epoch: 289/750 Iteration: 2605 Train loss: 0.141333 Train acc: 0.936667\n",
      "Epoch: 289/750 Iteration: 2610 Train loss: 0.116347 Train acc: 0.955000\n",
      "Epoch: 289/750 Iteration: 2610 Validation loss: 0.114441 Validation acc: 0.951667\n",
      "Epoch: 290/750 Iteration: 2615 Train loss: 0.111950 Train acc: 0.953333\n",
      "Epoch: 291/750 Iteration: 2620 Train loss: 0.100418 Train acc: 0.961667\n",
      "Epoch: 291/750 Iteration: 2620 Validation loss: 0.113987 Validation acc: 0.951667\n",
      "Epoch: 291/750 Iteration: 2625 Train loss: 0.110987 Train acc: 0.955000\n",
      "Epoch: 292/750 Iteration: 2630 Train loss: 0.105064 Train acc: 0.956667\n",
      "Epoch: 292/750 Iteration: 2630 Validation loss: 0.114281 Validation acc: 0.951667\n",
      "Epoch: 292/750 Iteration: 2635 Train loss: 0.113514 Train acc: 0.951667\n",
      "Epoch: 293/750 Iteration: 2640 Train loss: 0.125078 Train acc: 0.943333\n",
      "Epoch: 293/750 Iteration: 2640 Validation loss: 0.113915 Validation acc: 0.952778\n",
      "Epoch: 293/750 Iteration: 2645 Train loss: 0.088535 Train acc: 0.965000\n",
      "Epoch: 294/750 Iteration: 2650 Train loss: 0.145165 Train acc: 0.926667\n",
      "Epoch: 294/750 Iteration: 2650 Validation loss: 0.113868 Validation acc: 0.952778\n",
      "Epoch: 294/750 Iteration: 2655 Train loss: 0.111082 Train acc: 0.958333\n",
      "Epoch: 295/750 Iteration: 2660 Train loss: 0.112427 Train acc: 0.955000\n",
      "Epoch: 295/750 Iteration: 2660 Validation loss: 0.113740 Validation acc: 0.952778\n",
      "Epoch: 296/750 Iteration: 2665 Train loss: 0.100675 Train acc: 0.953333\n",
      "Epoch: 296/750 Iteration: 2670 Train loss: 0.106850 Train acc: 0.953333\n",
      "Epoch: 296/750 Iteration: 2670 Validation loss: 0.113606 Validation acc: 0.953333\n",
      "Epoch: 297/750 Iteration: 2675 Train loss: 0.100429 Train acc: 0.955000\n",
      "Epoch: 297/750 Iteration: 2680 Train loss: 0.102790 Train acc: 0.960000\n",
      "Epoch: 297/750 Iteration: 2680 Validation loss: 0.113792 Validation acc: 0.953333\n",
      "Epoch: 298/750 Iteration: 2685 Train loss: 0.132112 Train acc: 0.938333\n",
      "Epoch: 298/750 Iteration: 2690 Train loss: 0.091705 Train acc: 0.965000\n",
      "Epoch: 298/750 Iteration: 2690 Validation loss: 0.113309 Validation acc: 0.953333\n",
      "Epoch: 299/750 Iteration: 2695 Train loss: 0.141836 Train acc: 0.928333\n",
      "Epoch: 299/750 Iteration: 2700 Train loss: 0.120775 Train acc: 0.950000\n",
      "Epoch: 299/750 Iteration: 2700 Validation loss: 0.113192 Validation acc: 0.953333\n",
      "Epoch: 300/750 Iteration: 2705 Train loss: 0.119419 Train acc: 0.958333\n",
      "Epoch: 301/750 Iteration: 2710 Train loss: 0.098057 Train acc: 0.958333\n",
      "Epoch: 301/750 Iteration: 2710 Validation loss: 0.113054 Validation acc: 0.953333\n",
      "Epoch: 301/750 Iteration: 2715 Train loss: 0.102462 Train acc: 0.951667\n",
      "Epoch: 302/750 Iteration: 2720 Train loss: 0.111188 Train acc: 0.955000\n",
      "Epoch: 302/750 Iteration: 2720 Validation loss: 0.112932 Validation acc: 0.952778\n",
      "Epoch: 302/750 Iteration: 2725 Train loss: 0.110071 Train acc: 0.961667\n",
      "Epoch: 303/750 Iteration: 2730 Train loss: 0.131607 Train acc: 0.940000\n",
      "Epoch: 303/750 Iteration: 2730 Validation loss: 0.113013 Validation acc: 0.954444\n",
      "Epoch: 303/750 Iteration: 2735 Train loss: 0.086558 Train acc: 0.968333\n",
      "Epoch: 304/750 Iteration: 2740 Train loss: 0.134165 Train acc: 0.933333\n",
      "Epoch: 304/750 Iteration: 2740 Validation loss: 0.112733 Validation acc: 0.952778\n",
      "Epoch: 304/750 Iteration: 2745 Train loss: 0.118099 Train acc: 0.950000\n",
      "Epoch: 305/750 Iteration: 2750 Train loss: 0.112230 Train acc: 0.951667\n",
      "Epoch: 305/750 Iteration: 2750 Validation loss: 0.112463 Validation acc: 0.952778\n",
      "Epoch: 306/750 Iteration: 2755 Train loss: 0.100949 Train acc: 0.953333\n",
      "Epoch: 306/750 Iteration: 2760 Train loss: 0.102565 Train acc: 0.956667\n",
      "Epoch: 306/750 Iteration: 2760 Validation loss: 0.112386 Validation acc: 0.953333\n",
      "Epoch: 307/750 Iteration: 2765 Train loss: 0.102395 Train acc: 0.956667\n",
      "Epoch: 307/750 Iteration: 2770 Train loss: 0.110639 Train acc: 0.955000\n",
      "Epoch: 307/750 Iteration: 2770 Validation loss: 0.112323 Validation acc: 0.954444\n",
      "Epoch: 308/750 Iteration: 2775 Train loss: 0.126076 Train acc: 0.935000\n",
      "Epoch: 308/750 Iteration: 2780 Train loss: 0.087130 Train acc: 0.965000\n",
      "Epoch: 308/750 Iteration: 2780 Validation loss: 0.112037 Validation acc: 0.953333\n",
      "Epoch: 309/750 Iteration: 2785 Train loss: 0.133197 Train acc: 0.938333\n",
      "Epoch: 309/750 Iteration: 2790 Train loss: 0.117968 Train acc: 0.950000\n",
      "Epoch: 309/750 Iteration: 2790 Validation loss: 0.111666 Validation acc: 0.953333\n",
      "Epoch: 310/750 Iteration: 2795 Train loss: 0.109879 Train acc: 0.960000\n",
      "Epoch: 311/750 Iteration: 2800 Train loss: 0.097131 Train acc: 0.956667\n",
      "Epoch: 311/750 Iteration: 2800 Validation loss: 0.111860 Validation acc: 0.953333\n",
      "Epoch: 311/750 Iteration: 2805 Train loss: 0.101791 Train acc: 0.951667\n",
      "Epoch: 312/750 Iteration: 2810 Train loss: 0.098463 Train acc: 0.956667\n",
      "Epoch: 312/750 Iteration: 2810 Validation loss: 0.111519 Validation acc: 0.953333\n",
      "Epoch: 312/750 Iteration: 2815 Train loss: 0.103556 Train acc: 0.961667\n",
      "Epoch: 313/750 Iteration: 2820 Train loss: 0.136004 Train acc: 0.931667\n",
      "Epoch: 313/750 Iteration: 2820 Validation loss: 0.111369 Validation acc: 0.954444\n",
      "Epoch: 313/750 Iteration: 2825 Train loss: 0.084557 Train acc: 0.968333\n",
      "Epoch: 314/750 Iteration: 2830 Train loss: 0.134823 Train acc: 0.931667\n",
      "Epoch: 314/750 Iteration: 2830 Validation loss: 0.111467 Validation acc: 0.953333\n",
      "Epoch: 314/750 Iteration: 2835 Train loss: 0.112349 Train acc: 0.951667\n",
      "Epoch: 315/750 Iteration: 2840 Train loss: 0.108340 Train acc: 0.960000\n",
      "Epoch: 315/750 Iteration: 2840 Validation loss: 0.110930 Validation acc: 0.953333\n",
      "Epoch: 316/750 Iteration: 2845 Train loss: 0.098987 Train acc: 0.955000\n",
      "Epoch: 316/750 Iteration: 2850 Train loss: 0.105786 Train acc: 0.956667\n",
      "Epoch: 316/750 Iteration: 2850 Validation loss: 0.110949 Validation acc: 0.953889\n",
      "Epoch: 317/750 Iteration: 2855 Train loss: 0.097519 Train acc: 0.963333\n",
      "Epoch: 317/750 Iteration: 2860 Train loss: 0.106979 Train acc: 0.963333\n",
      "Epoch: 317/750 Iteration: 2860 Validation loss: 0.111220 Validation acc: 0.954444\n",
      "Epoch: 318/750 Iteration: 2865 Train loss: 0.121288 Train acc: 0.940000\n",
      "Epoch: 318/750 Iteration: 2870 Train loss: 0.081238 Train acc: 0.966667\n",
      "Epoch: 318/750 Iteration: 2870 Validation loss: 0.110744 Validation acc: 0.953889\n",
      "Epoch: 319/750 Iteration: 2875 Train loss: 0.137544 Train acc: 0.938333\n",
      "Epoch: 319/750 Iteration: 2880 Train loss: 0.117053 Train acc: 0.950000\n",
      "Epoch: 319/750 Iteration: 2880 Validation loss: 0.110758 Validation acc: 0.953889\n",
      "Epoch: 320/750 Iteration: 2885 Train loss: 0.109434 Train acc: 0.958333\n",
      "Epoch: 321/750 Iteration: 2890 Train loss: 0.101824 Train acc: 0.953333\n",
      "Epoch: 321/750 Iteration: 2890 Validation loss: 0.110818 Validation acc: 0.953889\n",
      "Epoch: 321/750 Iteration: 2895 Train loss: 0.103564 Train acc: 0.955000\n",
      "Epoch: 322/750 Iteration: 2900 Train loss: 0.098343 Train acc: 0.961667\n",
      "Epoch: 322/750 Iteration: 2900 Validation loss: 0.110667 Validation acc: 0.953333\n",
      "Epoch: 322/750 Iteration: 2905 Train loss: 0.102143 Train acc: 0.961667\n",
      "Epoch: 323/750 Iteration: 2910 Train loss: 0.126411 Train acc: 0.931667\n",
      "Epoch: 323/750 Iteration: 2910 Validation loss: 0.110518 Validation acc: 0.953333\n",
      "Epoch: 323/750 Iteration: 2915 Train loss: 0.079420 Train acc: 0.968333\n",
      "Epoch: 324/750 Iteration: 2920 Train loss: 0.141256 Train acc: 0.933333\n",
      "Epoch: 324/750 Iteration: 2920 Validation loss: 0.110313 Validation acc: 0.953333\n",
      "Epoch: 324/750 Iteration: 2925 Train loss: 0.107249 Train acc: 0.960000\n",
      "Epoch: 325/750 Iteration: 2930 Train loss: 0.110923 Train acc: 0.951667\n",
      "Epoch: 325/750 Iteration: 2930 Validation loss: 0.109955 Validation acc: 0.954444\n",
      "Epoch: 326/750 Iteration: 2935 Train loss: 0.095967 Train acc: 0.955000\n",
      "Epoch: 326/750 Iteration: 2940 Train loss: 0.104930 Train acc: 0.956667\n",
      "Epoch: 326/750 Iteration: 2940 Validation loss: 0.109755 Validation acc: 0.953889\n",
      "Epoch: 327/750 Iteration: 2945 Train loss: 0.101278 Train acc: 0.960000\n",
      "Epoch: 327/750 Iteration: 2950 Train loss: 0.108846 Train acc: 0.958333\n",
      "Epoch: 327/750 Iteration: 2950 Validation loss: 0.110362 Validation acc: 0.953889\n",
      "Epoch: 328/750 Iteration: 2955 Train loss: 0.123242 Train acc: 0.941667\n",
      "Epoch: 328/750 Iteration: 2960 Train loss: 0.081178 Train acc: 0.963333\n",
      "Epoch: 328/750 Iteration: 2960 Validation loss: 0.109788 Validation acc: 0.954444\n",
      "Epoch: 329/750 Iteration: 2965 Train loss: 0.128378 Train acc: 0.940000\n",
      "Epoch: 329/750 Iteration: 2970 Train loss: 0.111406 Train acc: 0.955000\n",
      "Epoch: 329/750 Iteration: 2970 Validation loss: 0.109434 Validation acc: 0.954444\n",
      "Epoch: 330/750 Iteration: 2975 Train loss: 0.103295 Train acc: 0.956667\n",
      "Epoch: 331/750 Iteration: 2980 Train loss: 0.099621 Train acc: 0.956667\n",
      "Epoch: 331/750 Iteration: 2980 Validation loss: 0.109373 Validation acc: 0.954444\n",
      "Epoch: 331/750 Iteration: 2985 Train loss: 0.103882 Train acc: 0.958333\n",
      "Epoch: 332/750 Iteration: 2990 Train loss: 0.098274 Train acc: 0.965000\n",
      "Epoch: 332/750 Iteration: 2990 Validation loss: 0.109253 Validation acc: 0.954444\n",
      "Epoch: 332/750 Iteration: 2995 Train loss: 0.104747 Train acc: 0.956667\n",
      "Epoch: 333/750 Iteration: 3000 Train loss: 0.120341 Train acc: 0.940000\n",
      "Epoch: 333/750 Iteration: 3000 Validation loss: 0.108993 Validation acc: 0.953889\n",
      "Epoch: 333/750 Iteration: 3005 Train loss: 0.082141 Train acc: 0.971667\n",
      "Epoch: 334/750 Iteration: 3010 Train loss: 0.129662 Train acc: 0.936667\n",
      "Epoch: 334/750 Iteration: 3010 Validation loss: 0.108859 Validation acc: 0.953889\n",
      "Epoch: 334/750 Iteration: 3015 Train loss: 0.102961 Train acc: 0.961667\n",
      "Epoch: 335/750 Iteration: 3020 Train loss: 0.106362 Train acc: 0.960000\n",
      "Epoch: 335/750 Iteration: 3020 Validation loss: 0.108789 Validation acc: 0.954444\n",
      "Epoch: 336/750 Iteration: 3025 Train loss: 0.096697 Train acc: 0.953333\n",
      "Epoch: 336/750 Iteration: 3030 Train loss: 0.099523 Train acc: 0.955000\n",
      "Epoch: 336/750 Iteration: 3030 Validation loss: 0.108956 Validation acc: 0.953889\n",
      "Epoch: 337/750 Iteration: 3035 Train loss: 0.092794 Train acc: 0.963333\n",
      "Epoch: 337/750 Iteration: 3040 Train loss: 0.103207 Train acc: 0.956667\n",
      "Epoch: 337/750 Iteration: 3040 Validation loss: 0.108657 Validation acc: 0.954444\n",
      "Epoch: 338/750 Iteration: 3045 Train loss: 0.130010 Train acc: 0.940000\n",
      "Epoch: 338/750 Iteration: 3050 Train loss: 0.081203 Train acc: 0.968333\n",
      "Epoch: 338/750 Iteration: 3050 Validation loss: 0.108491 Validation acc: 0.954444\n",
      "Epoch: 339/750 Iteration: 3055 Train loss: 0.133641 Train acc: 0.935000\n",
      "Epoch: 339/750 Iteration: 3060 Train loss: 0.111506 Train acc: 0.958333\n",
      "Epoch: 339/750 Iteration: 3060 Validation loss: 0.108459 Validation acc: 0.953889\n",
      "Epoch: 340/750 Iteration: 3065 Train loss: 0.103423 Train acc: 0.961667\n",
      "Epoch: 341/750 Iteration: 3070 Train loss: 0.096339 Train acc: 0.963333\n",
      "Epoch: 341/750 Iteration: 3070 Validation loss: 0.108590 Validation acc: 0.954444\n",
      "Epoch: 341/750 Iteration: 3075 Train loss: 0.095299 Train acc: 0.960000\n",
      "Epoch: 342/750 Iteration: 3080 Train loss: 0.095384 Train acc: 0.960000\n",
      "Epoch: 342/750 Iteration: 3080 Validation loss: 0.108077 Validation acc: 0.954444\n",
      "Epoch: 342/750 Iteration: 3085 Train loss: 0.097806 Train acc: 0.963333\n",
      "Epoch: 343/750 Iteration: 3090 Train loss: 0.114811 Train acc: 0.950000\n",
      "Epoch: 343/750 Iteration: 3090 Validation loss: 0.107946 Validation acc: 0.954444\n",
      "Epoch: 343/750 Iteration: 3095 Train loss: 0.078610 Train acc: 0.970000\n",
      "Epoch: 344/750 Iteration: 3100 Train loss: 0.132432 Train acc: 0.941667\n",
      "Epoch: 344/750 Iteration: 3100 Validation loss: 0.108346 Validation acc: 0.955000\n",
      "Epoch: 344/750 Iteration: 3105 Train loss: 0.108739 Train acc: 0.958333\n",
      "Epoch: 345/750 Iteration: 3110 Train loss: 0.108052 Train acc: 0.955000\n",
      "Epoch: 345/750 Iteration: 3110 Validation loss: 0.107889 Validation acc: 0.953889\n",
      "Epoch: 346/750 Iteration: 3115 Train loss: 0.096979 Train acc: 0.960000\n",
      "Epoch: 346/750 Iteration: 3120 Train loss: 0.103891 Train acc: 0.955000\n",
      "Epoch: 346/750 Iteration: 3120 Validation loss: 0.107794 Validation acc: 0.953889\n",
      "Epoch: 347/750 Iteration: 3125 Train loss: 0.088243 Train acc: 0.968333\n",
      "Epoch: 347/750 Iteration: 3130 Train loss: 0.102658 Train acc: 0.965000\n",
      "Epoch: 347/750 Iteration: 3130 Validation loss: 0.107833 Validation acc: 0.955000\n",
      "Epoch: 348/750 Iteration: 3135 Train loss: 0.120898 Train acc: 0.938333\n",
      "Epoch: 348/750 Iteration: 3140 Train loss: 0.079358 Train acc: 0.963333\n",
      "Epoch: 348/750 Iteration: 3140 Validation loss: 0.107260 Validation acc: 0.955000\n",
      "Epoch: 349/750 Iteration: 3145 Train loss: 0.133718 Train acc: 0.935000\n",
      "Epoch: 349/750 Iteration: 3150 Train loss: 0.108034 Train acc: 0.953333\n",
      "Epoch: 349/750 Iteration: 3150 Validation loss: 0.107165 Validation acc: 0.954444\n",
      "Epoch: 350/750 Iteration: 3155 Train loss: 0.105078 Train acc: 0.955000\n",
      "Epoch: 351/750 Iteration: 3160 Train loss: 0.090326 Train acc: 0.958333\n",
      "Epoch: 351/750 Iteration: 3160 Validation loss: 0.107205 Validation acc: 0.954444\n",
      "Epoch: 351/750 Iteration: 3165 Train loss: 0.095798 Train acc: 0.958333\n",
      "Epoch: 352/750 Iteration: 3170 Train loss: 0.093414 Train acc: 0.961667\n",
      "Epoch: 352/750 Iteration: 3170 Validation loss: 0.106931 Validation acc: 0.953889\n",
      "Epoch: 352/750 Iteration: 3175 Train loss: 0.104342 Train acc: 0.961667\n",
      "Epoch: 353/750 Iteration: 3180 Train loss: 0.124633 Train acc: 0.943333\n",
      "Epoch: 353/750 Iteration: 3180 Validation loss: 0.106798 Validation acc: 0.955555\n",
      "Epoch: 353/750 Iteration: 3185 Train loss: 0.076104 Train acc: 0.970000\n",
      "Epoch: 354/750 Iteration: 3190 Train loss: 0.125531 Train acc: 0.940000\n",
      "Epoch: 354/750 Iteration: 3190 Validation loss: 0.106724 Validation acc: 0.954444\n",
      "Epoch: 354/750 Iteration: 3195 Train loss: 0.107173 Train acc: 0.951667\n",
      "Epoch: 355/750 Iteration: 3200 Train loss: 0.102879 Train acc: 0.958333\n",
      "Epoch: 355/750 Iteration: 3200 Validation loss: 0.106635 Validation acc: 0.955000\n",
      "Epoch: 356/750 Iteration: 3205 Train loss: 0.098140 Train acc: 0.956667\n",
      "Epoch: 356/750 Iteration: 3210 Train loss: 0.092521 Train acc: 0.953333\n",
      "Epoch: 356/750 Iteration: 3210 Validation loss: 0.106383 Validation acc: 0.953889\n",
      "Epoch: 357/750 Iteration: 3215 Train loss: 0.094168 Train acc: 0.961667\n",
      "Epoch: 357/750 Iteration: 3220 Train loss: 0.102648 Train acc: 0.958333\n",
      "Epoch: 357/750 Iteration: 3220 Validation loss: 0.106208 Validation acc: 0.954444\n",
      "Epoch: 358/750 Iteration: 3225 Train loss: 0.119219 Train acc: 0.938333\n",
      "Epoch: 358/750 Iteration: 3230 Train loss: 0.082262 Train acc: 0.966667\n",
      "Epoch: 358/750 Iteration: 3230 Validation loss: 0.106040 Validation acc: 0.954444\n",
      "Epoch: 359/750 Iteration: 3235 Train loss: 0.131163 Train acc: 0.938333\n",
      "Epoch: 359/750 Iteration: 3240 Train loss: 0.102813 Train acc: 0.958333\n",
      "Epoch: 359/750 Iteration: 3240 Validation loss: 0.105860 Validation acc: 0.955000\n",
      "Epoch: 360/750 Iteration: 3245 Train loss: 0.106157 Train acc: 0.956667\n",
      "Epoch: 361/750 Iteration: 3250 Train loss: 0.094311 Train acc: 0.956667\n",
      "Epoch: 361/750 Iteration: 3250 Validation loss: 0.106831 Validation acc: 0.955000\n",
      "Epoch: 361/750 Iteration: 3255 Train loss: 0.095686 Train acc: 0.963333\n",
      "Epoch: 362/750 Iteration: 3260 Train loss: 0.093970 Train acc: 0.960000\n",
      "Epoch: 362/750 Iteration: 3260 Validation loss: 0.105851 Validation acc: 0.955555\n",
      "Epoch: 362/750 Iteration: 3265 Train loss: 0.096736 Train acc: 0.966667\n",
      "Epoch: 363/750 Iteration: 3270 Train loss: 0.123054 Train acc: 0.936667\n",
      "Epoch: 363/750 Iteration: 3270 Validation loss: 0.105396 Validation acc: 0.955555\n",
      "Epoch: 363/750 Iteration: 3275 Train loss: 0.075322 Train acc: 0.970000\n",
      "Epoch: 364/750 Iteration: 3280 Train loss: 0.132047 Train acc: 0.936667\n",
      "Epoch: 364/750 Iteration: 3280 Validation loss: 0.105681 Validation acc: 0.956111\n",
      "Epoch: 364/750 Iteration: 3285 Train loss: 0.101606 Train acc: 0.961667\n",
      "Epoch: 365/750 Iteration: 3290 Train loss: 0.105385 Train acc: 0.956667\n",
      "Epoch: 365/750 Iteration: 3290 Validation loss: 0.105399 Validation acc: 0.956111\n",
      "Epoch: 366/750 Iteration: 3295 Train loss: 0.094262 Train acc: 0.958333\n",
      "Epoch: 366/750 Iteration: 3300 Train loss: 0.096796 Train acc: 0.958333\n",
      "Epoch: 366/750 Iteration: 3300 Validation loss: 0.105121 Validation acc: 0.954444\n",
      "Epoch: 367/750 Iteration: 3305 Train loss: 0.091268 Train acc: 0.961667\n",
      "Epoch: 367/750 Iteration: 3310 Train loss: 0.094579 Train acc: 0.963333\n",
      "Epoch: 367/750 Iteration: 3310 Validation loss: 0.105324 Validation acc: 0.955000\n",
      "Epoch: 368/750 Iteration: 3315 Train loss: 0.117468 Train acc: 0.943333\n",
      "Epoch: 368/750 Iteration: 3320 Train loss: 0.071498 Train acc: 0.966667\n",
      "Epoch: 368/750 Iteration: 3320 Validation loss: 0.105136 Validation acc: 0.955000\n",
      "Epoch: 369/750 Iteration: 3325 Train loss: 0.128929 Train acc: 0.938333\n",
      "Epoch: 369/750 Iteration: 3330 Train loss: 0.104105 Train acc: 0.955000\n",
      "Epoch: 369/750 Iteration: 3330 Validation loss: 0.104806 Validation acc: 0.955555\n",
      "Epoch: 370/750 Iteration: 3335 Train loss: 0.106494 Train acc: 0.950000\n",
      "Epoch: 371/750 Iteration: 3340 Train loss: 0.094855 Train acc: 0.953333\n",
      "Epoch: 371/750 Iteration: 3340 Validation loss: 0.104855 Validation acc: 0.955556\n",
      "Epoch: 371/750 Iteration: 3345 Train loss: 0.092420 Train acc: 0.958333\n",
      "Epoch: 372/750 Iteration: 3350 Train loss: 0.093947 Train acc: 0.961667\n",
      "Epoch: 372/750 Iteration: 3350 Validation loss: 0.105057 Validation acc: 0.955555\n",
      "Epoch: 372/750 Iteration: 3355 Train loss: 0.094284 Train acc: 0.966667\n",
      "Epoch: 373/750 Iteration: 3360 Train loss: 0.110350 Train acc: 0.945000\n",
      "Epoch: 373/750 Iteration: 3360 Validation loss: 0.104372 Validation acc: 0.955555\n",
      "Epoch: 373/750 Iteration: 3365 Train loss: 0.072303 Train acc: 0.970000\n",
      "Epoch: 374/750 Iteration: 3370 Train loss: 0.125423 Train acc: 0.943333\n",
      "Epoch: 374/750 Iteration: 3370 Validation loss: 0.104649 Validation acc: 0.955556\n",
      "Epoch: 374/750 Iteration: 3375 Train loss: 0.101399 Train acc: 0.960000\n",
      "Epoch: 375/750 Iteration: 3380 Train loss: 0.096683 Train acc: 0.958333\n",
      "Epoch: 375/750 Iteration: 3380 Validation loss: 0.104446 Validation acc: 0.955000\n",
      "Epoch: 376/750 Iteration: 3385 Train loss: 0.091653 Train acc: 0.961667\n",
      "Epoch: 376/750 Iteration: 3390 Train loss: 0.098970 Train acc: 0.958333\n",
      "Epoch: 376/750 Iteration: 3390 Validation loss: 0.104251 Validation acc: 0.955555\n",
      "Epoch: 377/750 Iteration: 3395 Train loss: 0.089114 Train acc: 0.966667\n",
      "Epoch: 377/750 Iteration: 3400 Train loss: 0.098550 Train acc: 0.961667\n",
      "Epoch: 377/750 Iteration: 3400 Validation loss: 0.104480 Validation acc: 0.955000\n",
      "Epoch: 378/750 Iteration: 3405 Train loss: 0.115490 Train acc: 0.943333\n",
      "Epoch: 378/750 Iteration: 3410 Train loss: 0.067341 Train acc: 0.973333\n",
      "Epoch: 378/750 Iteration: 3410 Validation loss: 0.104443 Validation acc: 0.955000\n",
      "Epoch: 379/750 Iteration: 3415 Train loss: 0.122224 Train acc: 0.936667\n",
      "Epoch: 379/750 Iteration: 3420 Train loss: 0.096709 Train acc: 0.958333\n",
      "Epoch: 379/750 Iteration: 3420 Validation loss: 0.104094 Validation acc: 0.955555\n",
      "Epoch: 380/750 Iteration: 3425 Train loss: 0.099331 Train acc: 0.960000\n",
      "Epoch: 381/750 Iteration: 3430 Train loss: 0.094669 Train acc: 0.956667\n",
      "Epoch: 381/750 Iteration: 3430 Validation loss: 0.104133 Validation acc: 0.955000\n",
      "Epoch: 381/750 Iteration: 3435 Train loss: 0.091035 Train acc: 0.961667\n",
      "Epoch: 382/750 Iteration: 3440 Train loss: 0.089268 Train acc: 0.963333\n",
      "Epoch: 382/750 Iteration: 3440 Validation loss: 0.103847 Validation acc: 0.956111\n",
      "Epoch: 382/750 Iteration: 3445 Train loss: 0.095605 Train acc: 0.966667\n",
      "Epoch: 383/750 Iteration: 3450 Train loss: 0.110558 Train acc: 0.945000\n",
      "Epoch: 383/750 Iteration: 3450 Validation loss: 0.103894 Validation acc: 0.956111\n",
      "Epoch: 383/750 Iteration: 3455 Train loss: 0.077488 Train acc: 0.961667\n",
      "Epoch: 384/750 Iteration: 3460 Train loss: 0.117544 Train acc: 0.938333\n",
      "Epoch: 384/750 Iteration: 3460 Validation loss: 0.103628 Validation acc: 0.956111\n",
      "Epoch: 384/750 Iteration: 3465 Train loss: 0.098907 Train acc: 0.955000\n",
      "Epoch: 385/750 Iteration: 3470 Train loss: 0.097439 Train acc: 0.963333\n",
      "Epoch: 385/750 Iteration: 3470 Validation loss: 0.103349 Validation acc: 0.955000\n",
      "Epoch: 386/750 Iteration: 3475 Train loss: 0.087453 Train acc: 0.958333\n",
      "Epoch: 386/750 Iteration: 3480 Train loss: 0.090770 Train acc: 0.956667\n",
      "Epoch: 386/750 Iteration: 3480 Validation loss: 0.103642 Validation acc: 0.955556\n",
      "Epoch: 387/750 Iteration: 3485 Train loss: 0.091448 Train acc: 0.961667\n",
      "Epoch: 387/750 Iteration: 3490 Train loss: 0.097524 Train acc: 0.958333\n",
      "Epoch: 387/750 Iteration: 3490 Validation loss: 0.103419 Validation acc: 0.956111\n",
      "Epoch: 388/750 Iteration: 3495 Train loss: 0.120272 Train acc: 0.938333\n",
      "Epoch: 388/750 Iteration: 3500 Train loss: 0.073490 Train acc: 0.970000\n",
      "Epoch: 388/750 Iteration: 3500 Validation loss: 0.103471 Validation acc: 0.956111\n",
      "Epoch: 389/750 Iteration: 3505 Train loss: 0.123818 Train acc: 0.940000\n",
      "Epoch: 389/750 Iteration: 3510 Train loss: 0.095767 Train acc: 0.960000\n",
      "Epoch: 389/750 Iteration: 3510 Validation loss: 0.102832 Validation acc: 0.956667\n",
      "Epoch: 390/750 Iteration: 3515 Train loss: 0.099433 Train acc: 0.960000\n",
      "Epoch: 391/750 Iteration: 3520 Train loss: 0.089079 Train acc: 0.963333\n",
      "Epoch: 391/750 Iteration: 3520 Validation loss: 0.102792 Validation acc: 0.955555\n",
      "Epoch: 391/750 Iteration: 3525 Train loss: 0.097296 Train acc: 0.955000\n",
      "Epoch: 392/750 Iteration: 3530 Train loss: 0.085872 Train acc: 0.963333\n",
      "Epoch: 392/750 Iteration: 3530 Validation loss: 0.102975 Validation acc: 0.956111\n",
      "Epoch: 392/750 Iteration: 3535 Train loss: 0.091090 Train acc: 0.966667\n",
      "Epoch: 393/750 Iteration: 3540 Train loss: 0.117457 Train acc: 0.940000\n",
      "Epoch: 393/750 Iteration: 3540 Validation loss: 0.102828 Validation acc: 0.956111\n",
      "Epoch: 393/750 Iteration: 3545 Train loss: 0.076314 Train acc: 0.970000\n",
      "Epoch: 394/750 Iteration: 3550 Train loss: 0.126318 Train acc: 0.941667\n",
      "Epoch: 394/750 Iteration: 3550 Validation loss: 0.102832 Validation acc: 0.956667\n",
      "Epoch: 394/750 Iteration: 3555 Train loss: 0.096363 Train acc: 0.960000\n",
      "Epoch: 395/750 Iteration: 3560 Train loss: 0.103770 Train acc: 0.953333\n",
      "Epoch: 395/750 Iteration: 3560 Validation loss: 0.102729 Validation acc: 0.955555\n",
      "Epoch: 396/750 Iteration: 3565 Train loss: 0.091231 Train acc: 0.963333\n",
      "Epoch: 396/750 Iteration: 3570 Train loss: 0.093237 Train acc: 0.961667\n",
      "Epoch: 396/750 Iteration: 3570 Validation loss: 0.102273 Validation acc: 0.956667\n",
      "Epoch: 397/750 Iteration: 3575 Train loss: 0.087921 Train acc: 0.963333\n",
      "Epoch: 397/750 Iteration: 3580 Train loss: 0.090642 Train acc: 0.965000\n",
      "Epoch: 397/750 Iteration: 3580 Validation loss: 0.102192 Validation acc: 0.956667\n",
      "Epoch: 398/750 Iteration: 3585 Train loss: 0.105979 Train acc: 0.950000\n",
      "Epoch: 398/750 Iteration: 3590 Train loss: 0.071723 Train acc: 0.970000\n",
      "Epoch: 398/750 Iteration: 3590 Validation loss: 0.102115 Validation acc: 0.956667\n",
      "Epoch: 399/750 Iteration: 3595 Train loss: 0.125886 Train acc: 0.936667\n",
      "Epoch: 399/750 Iteration: 3600 Train loss: 0.095190 Train acc: 0.961667\n",
      "Epoch: 399/750 Iteration: 3600 Validation loss: 0.101975 Validation acc: 0.956111\n",
      "Epoch: 400/750 Iteration: 3605 Train loss: 0.096900 Train acc: 0.961667\n",
      "Epoch: 401/750 Iteration: 3610 Train loss: 0.089876 Train acc: 0.961667\n",
      "Epoch: 401/750 Iteration: 3610 Validation loss: 0.102207 Validation acc: 0.957222\n",
      "Epoch: 401/750 Iteration: 3615 Train loss: 0.092038 Train acc: 0.956667\n",
      "Epoch: 402/750 Iteration: 3620 Train loss: 0.091474 Train acc: 0.961667\n",
      "Epoch: 402/750 Iteration: 3620 Validation loss: 0.101741 Validation acc: 0.956667\n",
      "Epoch: 402/750 Iteration: 3625 Train loss: 0.093649 Train acc: 0.961667\n",
      "Epoch: 403/750 Iteration: 3630 Train loss: 0.111527 Train acc: 0.941667\n",
      "Epoch: 403/750 Iteration: 3630 Validation loss: 0.101674 Validation acc: 0.957222\n",
      "Epoch: 403/750 Iteration: 3635 Train loss: 0.075523 Train acc: 0.968333\n",
      "Epoch: 404/750 Iteration: 3640 Train loss: 0.118721 Train acc: 0.940000\n",
      "Epoch: 404/750 Iteration: 3640 Validation loss: 0.101243 Validation acc: 0.956667\n",
      "Epoch: 404/750 Iteration: 3645 Train loss: 0.095843 Train acc: 0.953333\n",
      "Epoch: 405/750 Iteration: 3650 Train loss: 0.097869 Train acc: 0.953333\n",
      "Epoch: 405/750 Iteration: 3650 Validation loss: 0.101097 Validation acc: 0.956667\n",
      "Epoch: 406/750 Iteration: 3655 Train loss: 0.085732 Train acc: 0.965000\n",
      "Epoch: 406/750 Iteration: 3660 Train loss: 0.091687 Train acc: 0.958333\n",
      "Epoch: 406/750 Iteration: 3660 Validation loss: 0.100954 Validation acc: 0.956111\n",
      "Epoch: 407/750 Iteration: 3665 Train loss: 0.086283 Train acc: 0.963333\n",
      "Epoch: 407/750 Iteration: 3670 Train loss: 0.094433 Train acc: 0.963333\n",
      "Epoch: 407/750 Iteration: 3670 Validation loss: 0.101120 Validation acc: 0.957222\n",
      "Epoch: 408/750 Iteration: 3675 Train loss: 0.113934 Train acc: 0.941667\n",
      "Epoch: 408/750 Iteration: 3680 Train loss: 0.069589 Train acc: 0.970000\n",
      "Epoch: 408/750 Iteration: 3680 Validation loss: 0.101282 Validation acc: 0.957222\n",
      "Epoch: 409/750 Iteration: 3685 Train loss: 0.123385 Train acc: 0.936667\n",
      "Epoch: 409/750 Iteration: 3690 Train loss: 0.092484 Train acc: 0.960000\n",
      "Epoch: 409/750 Iteration: 3690 Validation loss: 0.100979 Validation acc: 0.957222\n",
      "Epoch: 410/750 Iteration: 3695 Train loss: 0.090920 Train acc: 0.966667\n",
      "Epoch: 411/750 Iteration: 3700 Train loss: 0.088473 Train acc: 0.958333\n",
      "Epoch: 411/750 Iteration: 3700 Validation loss: 0.100831 Validation acc: 0.957222\n",
      "Epoch: 411/750 Iteration: 3705 Train loss: 0.095277 Train acc: 0.958333\n",
      "Epoch: 412/750 Iteration: 3710 Train loss: 0.086438 Train acc: 0.965000\n",
      "Epoch: 412/750 Iteration: 3710 Validation loss: 0.100807 Validation acc: 0.957222\n",
      "Epoch: 412/750 Iteration: 3715 Train loss: 0.090725 Train acc: 0.963333\n",
      "Epoch: 413/750 Iteration: 3720 Train loss: 0.111005 Train acc: 0.945000\n",
      "Epoch: 413/750 Iteration: 3720 Validation loss: 0.100510 Validation acc: 0.956667\n",
      "Epoch: 413/750 Iteration: 3725 Train loss: 0.073090 Train acc: 0.966667\n",
      "Epoch: 414/750 Iteration: 3730 Train loss: 0.123076 Train acc: 0.943333\n",
      "Epoch: 414/750 Iteration: 3730 Validation loss: 0.100382 Validation acc: 0.956667\n",
      "Epoch: 414/750 Iteration: 3735 Train loss: 0.095044 Train acc: 0.961667\n",
      "Epoch: 415/750 Iteration: 3740 Train loss: 0.095804 Train acc: 0.963333\n",
      "Epoch: 415/750 Iteration: 3740 Validation loss: 0.100775 Validation acc: 0.956111\n",
      "Epoch: 416/750 Iteration: 3745 Train loss: 0.081860 Train acc: 0.965000\n",
      "Epoch: 416/750 Iteration: 3750 Train loss: 0.095138 Train acc: 0.956667\n",
      "Epoch: 416/750 Iteration: 3750 Validation loss: 0.100329 Validation acc: 0.957778\n",
      "Epoch: 417/750 Iteration: 3755 Train loss: 0.080203 Train acc: 0.963333\n",
      "Epoch: 417/750 Iteration: 3760 Train loss: 0.086779 Train acc: 0.968333\n",
      "Epoch: 417/750 Iteration: 3760 Validation loss: 0.100097 Validation acc: 0.957222\n",
      "Epoch: 418/750 Iteration: 3765 Train loss: 0.107469 Train acc: 0.951667\n",
      "Epoch: 418/750 Iteration: 3770 Train loss: 0.071336 Train acc: 0.968333\n",
      "Epoch: 418/750 Iteration: 3770 Validation loss: 0.100642 Validation acc: 0.956111\n",
      "Epoch: 419/750 Iteration: 3775 Train loss: 0.119689 Train acc: 0.943333\n",
      "Epoch: 419/750 Iteration: 3780 Train loss: 0.098999 Train acc: 0.956667\n",
      "Epoch: 419/750 Iteration: 3780 Validation loss: 0.100389 Validation acc: 0.957222\n",
      "Epoch: 420/750 Iteration: 3785 Train loss: 0.098166 Train acc: 0.956667\n",
      "Epoch: 421/750 Iteration: 3790 Train loss: 0.087572 Train acc: 0.961667\n",
      "Epoch: 421/750 Iteration: 3790 Validation loss: 0.100063 Validation acc: 0.957222\n",
      "Epoch: 421/750 Iteration: 3795 Train loss: 0.092246 Train acc: 0.960000\n",
      "Epoch: 422/750 Iteration: 3800 Train loss: 0.082934 Train acc: 0.965000\n",
      "Epoch: 422/750 Iteration: 3800 Validation loss: 0.099934 Validation acc: 0.956111\n",
      "Epoch: 422/750 Iteration: 3805 Train loss: 0.085267 Train acc: 0.965000\n",
      "Epoch: 423/750 Iteration: 3810 Train loss: 0.111040 Train acc: 0.941667\n",
      "Epoch: 423/750 Iteration: 3810 Validation loss: 0.099635 Validation acc: 0.957222\n",
      "Epoch: 423/750 Iteration: 3815 Train loss: 0.069941 Train acc: 0.973333\n",
      "Epoch: 424/750 Iteration: 3820 Train loss: 0.118930 Train acc: 0.941667\n",
      "Epoch: 424/750 Iteration: 3820 Validation loss: 0.099568 Validation acc: 0.956667\n",
      "Epoch: 424/750 Iteration: 3825 Train loss: 0.092751 Train acc: 0.958333\n",
      "Epoch: 425/750 Iteration: 3830 Train loss: 0.099188 Train acc: 0.955000\n",
      "Epoch: 425/750 Iteration: 3830 Validation loss: 0.099398 Validation acc: 0.956667\n",
      "Epoch: 426/750 Iteration: 3835 Train loss: 0.084823 Train acc: 0.966667\n",
      "Epoch: 426/750 Iteration: 3840 Train loss: 0.092723 Train acc: 0.956667\n",
      "Epoch: 426/750 Iteration: 3840 Validation loss: 0.099472 Validation acc: 0.956667\n",
      "Epoch: 427/750 Iteration: 3845 Train loss: 0.084164 Train acc: 0.961667\n",
      "Epoch: 427/750 Iteration: 3850 Train loss: 0.094733 Train acc: 0.966667\n",
      "Epoch: 427/750 Iteration: 3850 Validation loss: 0.099262 Validation acc: 0.957222\n",
      "Epoch: 428/750 Iteration: 3855 Train loss: 0.108590 Train acc: 0.945000\n",
      "Epoch: 428/750 Iteration: 3860 Train loss: 0.069091 Train acc: 0.963333\n",
      "Epoch: 428/750 Iteration: 3860 Validation loss: 0.098977 Validation acc: 0.956667\n",
      "Epoch: 429/750 Iteration: 3865 Train loss: 0.117272 Train acc: 0.940000\n",
      "Epoch: 429/750 Iteration: 3870 Train loss: 0.094323 Train acc: 0.958333\n",
      "Epoch: 429/750 Iteration: 3870 Validation loss: 0.099265 Validation acc: 0.956667\n",
      "Epoch: 430/750 Iteration: 3875 Train loss: 0.093139 Train acc: 0.958333\n",
      "Epoch: 431/750 Iteration: 3880 Train loss: 0.087991 Train acc: 0.965000\n",
      "Epoch: 431/750 Iteration: 3880 Validation loss: 0.098833 Validation acc: 0.956111\n",
      "Epoch: 431/750 Iteration: 3885 Train loss: 0.088812 Train acc: 0.960000\n",
      "Epoch: 432/750 Iteration: 3890 Train loss: 0.080231 Train acc: 0.965000\n",
      "Epoch: 432/750 Iteration: 3890 Validation loss: 0.098875 Validation acc: 0.956667\n",
      "Epoch: 432/750 Iteration: 3895 Train loss: 0.094836 Train acc: 0.963333\n",
      "Epoch: 433/750 Iteration: 3900 Train loss: 0.106133 Train acc: 0.945000\n",
      "Epoch: 433/750 Iteration: 3900 Validation loss: 0.098908 Validation acc: 0.957222\n",
      "Epoch: 433/750 Iteration: 3905 Train loss: 0.064972 Train acc: 0.968333\n",
      "Epoch: 434/750 Iteration: 3910 Train loss: 0.119349 Train acc: 0.940000\n",
      "Epoch: 434/750 Iteration: 3910 Validation loss: 0.098854 Validation acc: 0.956667\n",
      "Epoch: 434/750 Iteration: 3915 Train loss: 0.088743 Train acc: 0.965000\n",
      "Epoch: 435/750 Iteration: 3920 Train loss: 0.093070 Train acc: 0.965000\n",
      "Epoch: 435/750 Iteration: 3920 Validation loss: 0.098772 Validation acc: 0.957778\n",
      "Epoch: 436/750 Iteration: 3925 Train loss: 0.087519 Train acc: 0.960000\n",
      "Epoch: 436/750 Iteration: 3930 Train loss: 0.088043 Train acc: 0.958333\n",
      "Epoch: 436/750 Iteration: 3930 Validation loss: 0.098505 Validation acc: 0.957222\n",
      "Epoch: 437/750 Iteration: 3935 Train loss: 0.080128 Train acc: 0.965000\n",
      "Epoch: 437/750 Iteration: 3940 Train loss: 0.094597 Train acc: 0.966667\n",
      "Epoch: 437/750 Iteration: 3940 Validation loss: 0.098299 Validation acc: 0.956667\n",
      "Epoch: 438/750 Iteration: 3945 Train loss: 0.112429 Train acc: 0.950000\n",
      "Epoch: 438/750 Iteration: 3950 Train loss: 0.072470 Train acc: 0.968333\n",
      "Epoch: 438/750 Iteration: 3950 Validation loss: 0.098529 Validation acc: 0.956667\n",
      "Epoch: 439/750 Iteration: 3955 Train loss: 0.115486 Train acc: 0.943333\n",
      "Epoch: 439/750 Iteration: 3960 Train loss: 0.089690 Train acc: 0.961667\n",
      "Epoch: 439/750 Iteration: 3960 Validation loss: 0.098473 Validation acc: 0.957222\n",
      "Epoch: 440/750 Iteration: 3965 Train loss: 0.091388 Train acc: 0.963333\n",
      "Epoch: 441/750 Iteration: 3970 Train loss: 0.088583 Train acc: 0.965000\n",
      "Epoch: 441/750 Iteration: 3970 Validation loss: 0.098150 Validation acc: 0.957222\n",
      "Epoch: 441/750 Iteration: 3975 Train loss: 0.084537 Train acc: 0.958333\n",
      "Epoch: 442/750 Iteration: 3980 Train loss: 0.082139 Train acc: 0.965000\n",
      "Epoch: 442/750 Iteration: 3980 Validation loss: 0.098047 Validation acc: 0.957222\n",
      "Epoch: 442/750 Iteration: 3985 Train loss: 0.090264 Train acc: 0.970000\n",
      "Epoch: 443/750 Iteration: 3990 Train loss: 0.110810 Train acc: 0.945000\n",
      "Epoch: 443/750 Iteration: 3990 Validation loss: 0.097808 Validation acc: 0.956667\n",
      "Epoch: 443/750 Iteration: 3995 Train loss: 0.070877 Train acc: 0.970000\n",
      "Epoch: 444/750 Iteration: 4000 Train loss: 0.118148 Train acc: 0.935000\n",
      "Epoch: 444/750 Iteration: 4000 Validation loss: 0.097939 Validation acc: 0.956667\n",
      "Epoch: 444/750 Iteration: 4005 Train loss: 0.086606 Train acc: 0.965000\n",
      "Epoch: 445/750 Iteration: 4010 Train loss: 0.090481 Train acc: 0.963333\n",
      "Epoch: 445/750 Iteration: 4010 Validation loss: 0.097914 Validation acc: 0.957222\n",
      "Epoch: 446/750 Iteration: 4015 Train loss: 0.086104 Train acc: 0.956667\n",
      "Epoch: 446/750 Iteration: 4020 Train loss: 0.090108 Train acc: 0.960000\n",
      "Epoch: 446/750 Iteration: 4020 Validation loss: 0.097973 Validation acc: 0.957222\n",
      "Epoch: 447/750 Iteration: 4025 Train loss: 0.083442 Train acc: 0.958333\n",
      "Epoch: 447/750 Iteration: 4030 Train loss: 0.087161 Train acc: 0.965000\n",
      "Epoch: 447/750 Iteration: 4030 Validation loss: 0.097740 Validation acc: 0.957222\n",
      "Epoch: 448/750 Iteration: 4035 Train loss: 0.107977 Train acc: 0.948333\n",
      "Epoch: 448/750 Iteration: 4040 Train loss: 0.069825 Train acc: 0.975000\n",
      "Epoch: 448/750 Iteration: 4040 Validation loss: 0.098009 Validation acc: 0.957222\n",
      "Epoch: 449/750 Iteration: 4045 Train loss: 0.118018 Train acc: 0.938333\n",
      "Epoch: 449/750 Iteration: 4050 Train loss: 0.088567 Train acc: 0.960000\n",
      "Epoch: 449/750 Iteration: 4050 Validation loss: 0.097605 Validation acc: 0.957222\n",
      "Epoch: 450/750 Iteration: 4055 Train loss: 0.089844 Train acc: 0.960000\n",
      "Epoch: 451/750 Iteration: 4060 Train loss: 0.080477 Train acc: 0.966667\n",
      "Epoch: 451/750 Iteration: 4060 Validation loss: 0.097382 Validation acc: 0.956667\n",
      "Epoch: 451/750 Iteration: 4065 Train loss: 0.088324 Train acc: 0.958333\n",
      "Epoch: 452/750 Iteration: 4070 Train loss: 0.079406 Train acc: 0.965000\n",
      "Epoch: 452/750 Iteration: 4070 Validation loss: 0.097476 Validation acc: 0.956111\n",
      "Epoch: 452/750 Iteration: 4075 Train loss: 0.084244 Train acc: 0.966667\n",
      "Epoch: 453/750 Iteration: 4080 Train loss: 0.102711 Train acc: 0.950000\n",
      "Epoch: 453/750 Iteration: 4080 Validation loss: 0.097153 Validation acc: 0.956667\n",
      "Epoch: 453/750 Iteration: 4085 Train loss: 0.066504 Train acc: 0.973333\n",
      "Epoch: 454/750 Iteration: 4090 Train loss: 0.118139 Train acc: 0.945000\n",
      "Epoch: 454/750 Iteration: 4090 Validation loss: 0.096814 Validation acc: 0.956111\n",
      "Epoch: 454/750 Iteration: 4095 Train loss: 0.084888 Train acc: 0.971667\n",
      "Epoch: 455/750 Iteration: 4100 Train loss: 0.087521 Train acc: 0.963333\n",
      "Epoch: 455/750 Iteration: 4100 Validation loss: 0.096689 Validation acc: 0.956667\n",
      "Epoch: 456/750 Iteration: 4105 Train loss: 0.079647 Train acc: 0.971667\n",
      "Epoch: 456/750 Iteration: 4110 Train loss: 0.086484 Train acc: 0.965000\n",
      "Epoch: 456/750 Iteration: 4110 Validation loss: 0.097232 Validation acc: 0.957222\n",
      "Epoch: 457/750 Iteration: 4115 Train loss: 0.085352 Train acc: 0.966667\n",
      "Epoch: 457/750 Iteration: 4120 Train loss: 0.084886 Train acc: 0.971667\n",
      "Epoch: 457/750 Iteration: 4120 Validation loss: 0.097118 Validation acc: 0.956667\n",
      "Epoch: 458/750 Iteration: 4125 Train loss: 0.106630 Train acc: 0.945000\n",
      "Epoch: 458/750 Iteration: 4130 Train loss: 0.061888 Train acc: 0.973333\n",
      "Epoch: 458/750 Iteration: 4130 Validation loss: 0.096898 Validation acc: 0.957222\n",
      "Epoch: 459/750 Iteration: 4135 Train loss: 0.117468 Train acc: 0.938333\n",
      "Epoch: 459/750 Iteration: 4140 Train loss: 0.084899 Train acc: 0.968333\n",
      "Epoch: 459/750 Iteration: 4140 Validation loss: 0.096782 Validation acc: 0.956111\n",
      "Epoch: 460/750 Iteration: 4145 Train loss: 0.093435 Train acc: 0.963333\n",
      "Epoch: 461/750 Iteration: 4150 Train loss: 0.083979 Train acc: 0.965000\n",
      "Epoch: 461/750 Iteration: 4150 Validation loss: 0.096784 Validation acc: 0.956667\n",
      "Epoch: 461/750 Iteration: 4155 Train loss: 0.087927 Train acc: 0.958333\n",
      "Epoch: 462/750 Iteration: 4160 Train loss: 0.078233 Train acc: 0.963333\n",
      "Epoch: 462/750 Iteration: 4160 Validation loss: 0.096747 Validation acc: 0.957778\n",
      "Epoch: 462/750 Iteration: 4165 Train loss: 0.084481 Train acc: 0.968333\n",
      "Epoch: 463/750 Iteration: 4170 Train loss: 0.102161 Train acc: 0.953333\n",
      "Epoch: 463/750 Iteration: 4170 Validation loss: 0.096307 Validation acc: 0.957222\n",
      "Epoch: 463/750 Iteration: 4175 Train loss: 0.065354 Train acc: 0.973333\n",
      "Epoch: 464/750 Iteration: 4180 Train loss: 0.112294 Train acc: 0.945000\n",
      "Epoch: 464/750 Iteration: 4180 Validation loss: 0.096209 Validation acc: 0.957222\n",
      "Epoch: 464/750 Iteration: 4185 Train loss: 0.083982 Train acc: 0.963333\n",
      "Epoch: 465/750 Iteration: 4190 Train loss: 0.095515 Train acc: 0.956667\n",
      "Epoch: 465/750 Iteration: 4190 Validation loss: 0.096044 Validation acc: 0.957222\n",
      "Epoch: 466/750 Iteration: 4195 Train loss: 0.083846 Train acc: 0.965000\n",
      "Epoch: 466/750 Iteration: 4200 Train loss: 0.091265 Train acc: 0.961667\n",
      "Epoch: 466/750 Iteration: 4200 Validation loss: 0.096179 Validation acc: 0.957222\n",
      "Epoch: 467/750 Iteration: 4205 Train loss: 0.076545 Train acc: 0.961667\n",
      "Epoch: 467/750 Iteration: 4210 Train loss: 0.085454 Train acc: 0.970000\n",
      "Epoch: 467/750 Iteration: 4210 Validation loss: 0.095840 Validation acc: 0.957222\n",
      "Epoch: 468/750 Iteration: 4215 Train loss: 0.108395 Train acc: 0.953333\n",
      "Epoch: 468/750 Iteration: 4220 Train loss: 0.066055 Train acc: 0.973333\n",
      "Epoch: 468/750 Iteration: 4220 Validation loss: 0.095772 Validation acc: 0.957222\n",
      "Epoch: 469/750 Iteration: 4225 Train loss: 0.116221 Train acc: 0.940000\n",
      "Epoch: 469/750 Iteration: 4230 Train loss: 0.084750 Train acc: 0.956667\n",
      "Epoch: 469/750 Iteration: 4230 Validation loss: 0.095641 Validation acc: 0.957778\n",
      "Epoch: 470/750 Iteration: 4235 Train loss: 0.089984 Train acc: 0.955000\n",
      "Epoch: 471/750 Iteration: 4240 Train loss: 0.077899 Train acc: 0.966667\n",
      "Epoch: 471/750 Iteration: 4240 Validation loss: 0.096413 Validation acc: 0.957222\n",
      "Epoch: 471/750 Iteration: 4245 Train loss: 0.087701 Train acc: 0.961667\n",
      "Epoch: 472/750 Iteration: 4250 Train loss: 0.079935 Train acc: 0.965000\n",
      "Epoch: 472/750 Iteration: 4250 Validation loss: 0.095778 Validation acc: 0.958333\n",
      "Epoch: 472/750 Iteration: 4255 Train loss: 0.082279 Train acc: 0.968333\n",
      "Epoch: 473/750 Iteration: 4260 Train loss: 0.110166 Train acc: 0.946667\n",
      "Epoch: 473/750 Iteration: 4260 Validation loss: 0.095560 Validation acc: 0.957222\n",
      "Epoch: 473/750 Iteration: 4265 Train loss: 0.067017 Train acc: 0.970000\n",
      "Epoch: 474/750 Iteration: 4270 Train loss: 0.113442 Train acc: 0.943333\n",
      "Epoch: 474/750 Iteration: 4270 Validation loss: 0.095278 Validation acc: 0.957778\n",
      "Epoch: 474/750 Iteration: 4275 Train loss: 0.093274 Train acc: 0.960000\n",
      "Epoch: 475/750 Iteration: 4280 Train loss: 0.090195 Train acc: 0.961667\n",
      "Epoch: 475/750 Iteration: 4280 Validation loss: 0.095232 Validation acc: 0.957778\n",
      "Epoch: 476/750 Iteration: 4285 Train loss: 0.086176 Train acc: 0.961667\n",
      "Epoch: 476/750 Iteration: 4290 Train loss: 0.086955 Train acc: 0.968333\n",
      "Epoch: 476/750 Iteration: 4290 Validation loss: 0.095951 Validation acc: 0.957778\n",
      "Epoch: 477/750 Iteration: 4295 Train loss: 0.079079 Train acc: 0.966667\n",
      "Epoch: 477/750 Iteration: 4300 Train loss: 0.078096 Train acc: 0.970000\n",
      "Epoch: 477/750 Iteration: 4300 Validation loss: 0.095706 Validation acc: 0.957778\n",
      "Epoch: 478/750 Iteration: 4305 Train loss: 0.105608 Train acc: 0.945000\n",
      "Epoch: 478/750 Iteration: 4310 Train loss: 0.060478 Train acc: 0.976667\n",
      "Epoch: 478/750 Iteration: 4310 Validation loss: 0.095316 Validation acc: 0.958333\n",
      "Epoch: 479/750 Iteration: 4315 Train loss: 0.110436 Train acc: 0.940000\n",
      "Epoch: 479/750 Iteration: 4320 Train loss: 0.082380 Train acc: 0.961667\n",
      "Epoch: 479/750 Iteration: 4320 Validation loss: 0.095295 Validation acc: 0.957778\n",
      "Epoch: 480/750 Iteration: 4325 Train loss: 0.092532 Train acc: 0.960000\n",
      "Epoch: 481/750 Iteration: 4330 Train loss: 0.078973 Train acc: 0.963333\n",
      "Epoch: 481/750 Iteration: 4330 Validation loss: 0.095091 Validation acc: 0.958889\n",
      "Epoch: 481/750 Iteration: 4335 Train loss: 0.089827 Train acc: 0.963333\n",
      "Epoch: 482/750 Iteration: 4340 Train loss: 0.074108 Train acc: 0.965000\n",
      "Epoch: 482/750 Iteration: 4340 Validation loss: 0.095067 Validation acc: 0.957222\n",
      "Epoch: 482/750 Iteration: 4345 Train loss: 0.081947 Train acc: 0.965000\n",
      "Epoch: 483/750 Iteration: 4350 Train loss: 0.100745 Train acc: 0.950000\n",
      "Epoch: 483/750 Iteration: 4350 Validation loss: 0.094780 Validation acc: 0.958333\n",
      "Epoch: 483/750 Iteration: 4355 Train loss: 0.064873 Train acc: 0.970000\n",
      "Epoch: 484/750 Iteration: 4360 Train loss: 0.118701 Train acc: 0.941667\n",
      "Epoch: 484/750 Iteration: 4360 Validation loss: 0.094740 Validation acc: 0.958889\n",
      "Epoch: 484/750 Iteration: 4365 Train loss: 0.085765 Train acc: 0.958333\n",
      "Epoch: 485/750 Iteration: 4370 Train loss: 0.087634 Train acc: 0.966667\n",
      "Epoch: 485/750 Iteration: 4370 Validation loss: 0.094651 Validation acc: 0.957778\n",
      "Epoch: 486/750 Iteration: 4375 Train loss: 0.082123 Train acc: 0.965000\n",
      "Epoch: 486/750 Iteration: 4380 Train loss: 0.081715 Train acc: 0.960000\n",
      "Epoch: 486/750 Iteration: 4380 Validation loss: 0.094585 Validation acc: 0.957778\n",
      "Epoch: 487/750 Iteration: 4385 Train loss: 0.071768 Train acc: 0.968333\n",
      "Epoch: 487/750 Iteration: 4390 Train loss: 0.079506 Train acc: 0.971667\n",
      "Epoch: 487/750 Iteration: 4390 Validation loss: 0.094803 Validation acc: 0.957778\n",
      "Epoch: 488/750 Iteration: 4395 Train loss: 0.107264 Train acc: 0.950000\n",
      "Epoch: 488/750 Iteration: 4400 Train loss: 0.063859 Train acc: 0.971667\n",
      "Epoch: 488/750 Iteration: 4400 Validation loss: 0.094588 Validation acc: 0.958333\n",
      "Epoch: 489/750 Iteration: 4405 Train loss: 0.111379 Train acc: 0.941667\n",
      "Epoch: 489/750 Iteration: 4410 Train loss: 0.083868 Train acc: 0.963333\n",
      "Epoch: 489/750 Iteration: 4410 Validation loss: 0.094534 Validation acc: 0.958333\n",
      "Epoch: 490/750 Iteration: 4415 Train loss: 0.093831 Train acc: 0.961667\n",
      "Epoch: 491/750 Iteration: 4420 Train loss: 0.079158 Train acc: 0.966667\n",
      "Epoch: 491/750 Iteration: 4420 Validation loss: 0.094323 Validation acc: 0.958333\n",
      "Epoch: 491/750 Iteration: 4425 Train loss: 0.086241 Train acc: 0.963333\n",
      "Epoch: 492/750 Iteration: 4430 Train loss: 0.075542 Train acc: 0.966667\n",
      "Epoch: 492/750 Iteration: 4430 Validation loss: 0.094380 Validation acc: 0.957222\n",
      "Epoch: 492/750 Iteration: 4435 Train loss: 0.075820 Train acc: 0.968333\n",
      "Epoch: 493/750 Iteration: 4440 Train loss: 0.105270 Train acc: 0.943333\n",
      "Epoch: 493/750 Iteration: 4440 Validation loss: 0.094373 Validation acc: 0.958889\n",
      "Epoch: 493/750 Iteration: 4445 Train loss: 0.066268 Train acc: 0.970000\n",
      "Epoch: 494/750 Iteration: 4450 Train loss: 0.115164 Train acc: 0.938333\n",
      "Epoch: 494/750 Iteration: 4450 Validation loss: 0.094249 Validation acc: 0.959444\n",
      "Epoch: 494/750 Iteration: 4455 Train loss: 0.081182 Train acc: 0.968333\n",
      "Epoch: 495/750 Iteration: 4460 Train loss: 0.090154 Train acc: 0.961667\n",
      "Epoch: 495/750 Iteration: 4460 Validation loss: 0.094377 Validation acc: 0.958889\n",
      "Epoch: 496/750 Iteration: 4465 Train loss: 0.082344 Train acc: 0.965000\n",
      "Epoch: 496/750 Iteration: 4470 Train loss: 0.083215 Train acc: 0.970000\n",
      "Epoch: 496/750 Iteration: 4470 Validation loss: 0.093954 Validation acc: 0.958333\n",
      "Epoch: 497/750 Iteration: 4475 Train loss: 0.073603 Train acc: 0.966667\n",
      "Epoch: 497/750 Iteration: 4480 Train loss: 0.077918 Train acc: 0.970000\n",
      "Epoch: 497/750 Iteration: 4480 Validation loss: 0.094001 Validation acc: 0.958333\n",
      "Epoch: 498/750 Iteration: 4485 Train loss: 0.100648 Train acc: 0.951667\n",
      "Epoch: 498/750 Iteration: 4490 Train loss: 0.062419 Train acc: 0.973333\n",
      "Epoch: 498/750 Iteration: 4490 Validation loss: 0.093861 Validation acc: 0.959444\n",
      "Epoch: 499/750 Iteration: 4495 Train loss: 0.106927 Train acc: 0.945000\n",
      "Epoch: 499/750 Iteration: 4500 Train loss: 0.079980 Train acc: 0.965000\n",
      "Epoch: 499/750 Iteration: 4500 Validation loss: 0.094169 Validation acc: 0.959444\n",
      "Epoch: 500/750 Iteration: 4505 Train loss: 0.088810 Train acc: 0.968333\n",
      "Epoch: 501/750 Iteration: 4510 Train loss: 0.083993 Train acc: 0.960000\n",
      "Epoch: 501/750 Iteration: 4510 Validation loss: 0.093591 Validation acc: 0.958333\n",
      "Epoch: 501/750 Iteration: 4515 Train loss: 0.078492 Train acc: 0.968333\n",
      "Epoch: 502/750 Iteration: 4520 Train loss: 0.072348 Train acc: 0.965000\n",
      "Epoch: 502/750 Iteration: 4520 Validation loss: 0.093302 Validation acc: 0.959444\n",
      "Epoch: 502/750 Iteration: 4525 Train loss: 0.078448 Train acc: 0.971667\n",
      "Epoch: 503/750 Iteration: 4530 Train loss: 0.102475 Train acc: 0.955000\n",
      "Epoch: 503/750 Iteration: 4530 Validation loss: 0.093441 Validation acc: 0.959444\n",
      "Epoch: 503/750 Iteration: 4535 Train loss: 0.062162 Train acc: 0.971667\n",
      "Epoch: 504/750 Iteration: 4540 Train loss: 0.111939 Train acc: 0.941667\n",
      "Epoch: 504/750 Iteration: 4540 Validation loss: 0.093298 Validation acc: 0.958889\n",
      "Epoch: 504/750 Iteration: 4545 Train loss: 0.083844 Train acc: 0.961667\n",
      "Epoch: 505/750 Iteration: 4550 Train loss: 0.091304 Train acc: 0.963333\n",
      "Epoch: 505/750 Iteration: 4550 Validation loss: 0.093341 Validation acc: 0.959444\n",
      "Epoch: 506/750 Iteration: 4555 Train loss: 0.083241 Train acc: 0.965000\n",
      "Epoch: 506/750 Iteration: 4560 Train loss: 0.086463 Train acc: 0.958333\n",
      "Epoch: 506/750 Iteration: 4560 Validation loss: 0.093132 Validation acc: 0.958333\n",
      "Epoch: 507/750 Iteration: 4565 Train loss: 0.075882 Train acc: 0.966667\n",
      "Epoch: 507/750 Iteration: 4570 Train loss: 0.076886 Train acc: 0.970000\n",
      "Epoch: 507/750 Iteration: 4570 Validation loss: 0.093150 Validation acc: 0.958889\n",
      "Epoch: 508/750 Iteration: 4575 Train loss: 0.105659 Train acc: 0.946667\n",
      "Epoch: 508/750 Iteration: 4580 Train loss: 0.059354 Train acc: 0.975000\n",
      "Epoch: 508/750 Iteration: 4580 Validation loss: 0.092851 Validation acc: 0.960000\n",
      "Epoch: 509/750 Iteration: 4585 Train loss: 0.113873 Train acc: 0.940000\n",
      "Epoch: 509/750 Iteration: 4590 Train loss: 0.081994 Train acc: 0.960000\n",
      "Epoch: 509/750 Iteration: 4590 Validation loss: 0.092846 Validation acc: 0.960000\n",
      "Epoch: 510/750 Iteration: 4595 Train loss: 0.082570 Train acc: 0.966667\n",
      "Epoch: 511/750 Iteration: 4600 Train loss: 0.081907 Train acc: 0.966667\n",
      "Epoch: 511/750 Iteration: 4600 Validation loss: 0.092752 Validation acc: 0.959444\n",
      "Epoch: 511/750 Iteration: 4605 Train loss: 0.083112 Train acc: 0.958333\n",
      "Epoch: 512/750 Iteration: 4610 Train loss: 0.073786 Train acc: 0.966667\n",
      "Epoch: 512/750 Iteration: 4610 Validation loss: 0.092680 Validation acc: 0.957778\n",
      "Epoch: 512/750 Iteration: 4615 Train loss: 0.083495 Train acc: 0.970000\n",
      "Epoch: 513/750 Iteration: 4620 Train loss: 0.105401 Train acc: 0.948333\n",
      "Epoch: 513/750 Iteration: 4620 Validation loss: 0.092799 Validation acc: 0.959444\n",
      "Epoch: 513/750 Iteration: 4625 Train loss: 0.059566 Train acc: 0.976667\n",
      "Epoch: 514/750 Iteration: 4630 Train loss: 0.110811 Train acc: 0.941667\n",
      "Epoch: 514/750 Iteration: 4630 Validation loss: 0.092495 Validation acc: 0.959444\n",
      "Epoch: 514/750 Iteration: 4635 Train loss: 0.082215 Train acc: 0.966667\n",
      "Epoch: 515/750 Iteration: 4640 Train loss: 0.091834 Train acc: 0.956667\n",
      "Epoch: 515/750 Iteration: 4640 Validation loss: 0.092230 Validation acc: 0.958333\n",
      "Epoch: 516/750 Iteration: 4645 Train loss: 0.079430 Train acc: 0.961667\n",
      "Epoch: 516/750 Iteration: 4650 Train loss: 0.083399 Train acc: 0.960000\n",
      "Epoch: 516/750 Iteration: 4650 Validation loss: 0.092193 Validation acc: 0.958333\n",
      "Epoch: 517/750 Iteration: 4655 Train loss: 0.080074 Train acc: 0.966667\n",
      "Epoch: 517/750 Iteration: 4660 Train loss: 0.076628 Train acc: 0.971667\n",
      "Epoch: 517/750 Iteration: 4660 Validation loss: 0.092490 Validation acc: 0.960000\n",
      "Epoch: 518/750 Iteration: 4665 Train loss: 0.099433 Train acc: 0.948333\n",
      "Epoch: 518/750 Iteration: 4670 Train loss: 0.060284 Train acc: 0.971667\n",
      "Epoch: 518/750 Iteration: 4670 Validation loss: 0.092566 Validation acc: 0.957778\n",
      "Epoch: 519/750 Iteration: 4675 Train loss: 0.113170 Train acc: 0.943333\n",
      "Epoch: 519/750 Iteration: 4680 Train loss: 0.082318 Train acc: 0.966667\n",
      "Epoch: 519/750 Iteration: 4680 Validation loss: 0.092414 Validation acc: 0.960000\n",
      "Epoch: 520/750 Iteration: 4685 Train loss: 0.089686 Train acc: 0.961667\n",
      "Epoch: 521/750 Iteration: 4690 Train loss: 0.080199 Train acc: 0.966667\n",
      "Epoch: 521/750 Iteration: 4690 Validation loss: 0.092315 Validation acc: 0.960000\n",
      "Epoch: 521/750 Iteration: 4695 Train loss: 0.078950 Train acc: 0.965000\n",
      "Epoch: 522/750 Iteration: 4700 Train loss: 0.076256 Train acc: 0.965000\n",
      "Epoch: 522/750 Iteration: 4700 Validation loss: 0.091824 Validation acc: 0.958333\n",
      "Epoch: 522/750 Iteration: 4705 Train loss: 0.080181 Train acc: 0.970000\n",
      "Epoch: 523/750 Iteration: 4710 Train loss: 0.100870 Train acc: 0.946667\n",
      "Epoch: 523/750 Iteration: 4710 Validation loss: 0.091764 Validation acc: 0.960000\n",
      "Epoch: 523/750 Iteration: 4715 Train loss: 0.059450 Train acc: 0.973333\n",
      "Epoch: 524/750 Iteration: 4720 Train loss: 0.112705 Train acc: 0.936667\n",
      "Epoch: 524/750 Iteration: 4720 Validation loss: 0.091809 Validation acc: 0.958333\n",
      "Epoch: 524/750 Iteration: 4725 Train loss: 0.077551 Train acc: 0.965000\n",
      "Epoch: 525/750 Iteration: 4730 Train loss: 0.086064 Train acc: 0.970000\n",
      "Epoch: 525/750 Iteration: 4730 Validation loss: 0.091600 Validation acc: 0.958333\n",
      "Epoch: 526/750 Iteration: 4735 Train loss: 0.076702 Train acc: 0.970000\n",
      "Epoch: 526/750 Iteration: 4740 Train loss: 0.075619 Train acc: 0.963333\n",
      "Epoch: 526/750 Iteration: 4740 Validation loss: 0.091398 Validation acc: 0.959444\n",
      "Epoch: 527/750 Iteration: 4745 Train loss: 0.073874 Train acc: 0.965000\n",
      "Epoch: 527/750 Iteration: 4750 Train loss: 0.076371 Train acc: 0.971667\n",
      "Epoch: 527/750 Iteration: 4750 Validation loss: 0.091631 Validation acc: 0.960000\n",
      "Epoch: 528/750 Iteration: 4755 Train loss: 0.101566 Train acc: 0.948333\n",
      "Epoch: 528/750 Iteration: 4760 Train loss: 0.060640 Train acc: 0.975000\n",
      "Epoch: 528/750 Iteration: 4760 Validation loss: 0.091963 Validation acc: 0.958889\n",
      "Epoch: 529/750 Iteration: 4765 Train loss: 0.111654 Train acc: 0.938333\n",
      "Epoch: 529/750 Iteration: 4770 Train loss: 0.082240 Train acc: 0.961667\n",
      "Epoch: 529/750 Iteration: 4770 Validation loss: 0.092110 Validation acc: 0.958889\n",
      "Epoch: 530/750 Iteration: 4775 Train loss: 0.081343 Train acc: 0.970000\n",
      "Epoch: 531/750 Iteration: 4780 Train loss: 0.078372 Train acc: 0.966667\n",
      "Epoch: 531/750 Iteration: 4780 Validation loss: 0.091368 Validation acc: 0.957778\n",
      "Epoch: 531/750 Iteration: 4785 Train loss: 0.081839 Train acc: 0.965000\n",
      "Epoch: 532/750 Iteration: 4790 Train loss: 0.071728 Train acc: 0.965000\n",
      "Epoch: 532/750 Iteration: 4790 Validation loss: 0.091196 Validation acc: 0.960000\n",
      "Epoch: 532/750 Iteration: 4795 Train loss: 0.077292 Train acc: 0.965000\n",
      "Epoch: 533/750 Iteration: 4800 Train loss: 0.105427 Train acc: 0.948333\n",
      "Epoch: 533/750 Iteration: 4800 Validation loss: 0.091198 Validation acc: 0.957778\n",
      "Epoch: 533/750 Iteration: 4805 Train loss: 0.056486 Train acc: 0.980000\n",
      "Epoch: 534/750 Iteration: 4810 Train loss: 0.105652 Train acc: 0.946667\n",
      "Epoch: 534/750 Iteration: 4810 Validation loss: 0.091117 Validation acc: 0.958889\n",
      "Epoch: 534/750 Iteration: 4815 Train loss: 0.075374 Train acc: 0.968333\n",
      "Epoch: 535/750 Iteration: 4820 Train loss: 0.082561 Train acc: 0.961667\n",
      "Epoch: 535/750 Iteration: 4820 Validation loss: 0.090805 Validation acc: 0.959444\n",
      "Epoch: 536/750 Iteration: 4825 Train loss: 0.075040 Train acc: 0.968333\n",
      "Epoch: 536/750 Iteration: 4830 Train loss: 0.082311 Train acc: 0.965000\n",
      "Epoch: 536/750 Iteration: 4830 Validation loss: 0.090750 Validation acc: 0.958889\n",
      "Epoch: 537/750 Iteration: 4835 Train loss: 0.070040 Train acc: 0.970000\n",
      "Epoch: 537/750 Iteration: 4840 Train loss: 0.078057 Train acc: 0.966667\n",
      "Epoch: 537/750 Iteration: 4840 Validation loss: 0.090736 Validation acc: 0.958889\n",
      "Epoch: 538/750 Iteration: 4845 Train loss: 0.097299 Train acc: 0.955000\n",
      "Epoch: 538/750 Iteration: 4850 Train loss: 0.057907 Train acc: 0.978333\n",
      "Epoch: 538/750 Iteration: 4850 Validation loss: 0.090695 Validation acc: 0.959444\n",
      "Epoch: 539/750 Iteration: 4855 Train loss: 0.110335 Train acc: 0.943333\n",
      "Epoch: 539/750 Iteration: 4860 Train loss: 0.077479 Train acc: 0.965000\n",
      "Epoch: 539/750 Iteration: 4860 Validation loss: 0.090788 Validation acc: 0.960000\n",
      "Epoch: 540/750 Iteration: 4865 Train loss: 0.080868 Train acc: 0.963333\n",
      "Epoch: 541/750 Iteration: 4870 Train loss: 0.079417 Train acc: 0.965000\n",
      "Epoch: 541/750 Iteration: 4870 Validation loss: 0.090642 Validation acc: 0.958333\n",
      "Epoch: 541/750 Iteration: 4875 Train loss: 0.080320 Train acc: 0.965000\n",
      "Epoch: 542/750 Iteration: 4880 Train loss: 0.069737 Train acc: 0.965000\n",
      "Epoch: 542/750 Iteration: 4880 Validation loss: 0.090480 Validation acc: 0.958889\n",
      "Epoch: 542/750 Iteration: 4885 Train loss: 0.077447 Train acc: 0.966667\n",
      "Epoch: 543/750 Iteration: 4890 Train loss: 0.098488 Train acc: 0.945000\n",
      "Epoch: 543/750 Iteration: 4890 Validation loss: 0.090447 Validation acc: 0.958889\n",
      "Epoch: 543/750 Iteration: 4895 Train loss: 0.061645 Train acc: 0.975000\n",
      "Epoch: 544/750 Iteration: 4900 Train loss: 0.104662 Train acc: 0.941667\n",
      "Epoch: 544/750 Iteration: 4900 Validation loss: 0.090431 Validation acc: 0.958889\n",
      "Epoch: 544/750 Iteration: 4905 Train loss: 0.075872 Train acc: 0.968333\n",
      "Epoch: 545/750 Iteration: 4910 Train loss: 0.086453 Train acc: 0.963333\n",
      "Epoch: 545/750 Iteration: 4910 Validation loss: 0.090335 Validation acc: 0.960000\n",
      "Epoch: 546/750 Iteration: 4915 Train loss: 0.076924 Train acc: 0.966667\n",
      "Epoch: 546/750 Iteration: 4920 Train loss: 0.079368 Train acc: 0.970000\n",
      "Epoch: 546/750 Iteration: 4920 Validation loss: 0.090077 Validation acc: 0.959444\n",
      "Epoch: 547/750 Iteration: 4925 Train loss: 0.073664 Train acc: 0.965000\n",
      "Epoch: 547/750 Iteration: 4930 Train loss: 0.078256 Train acc: 0.968333\n",
      "Epoch: 547/750 Iteration: 4930 Validation loss: 0.090240 Validation acc: 0.958889\n",
      "Epoch: 548/750 Iteration: 4935 Train loss: 0.098796 Train acc: 0.950000\n",
      "Epoch: 548/750 Iteration: 4940 Train loss: 0.058581 Train acc: 0.978333\n",
      "Epoch: 548/750 Iteration: 4940 Validation loss: 0.089862 Validation acc: 0.959444\n",
      "Epoch: 549/750 Iteration: 4945 Train loss: 0.111234 Train acc: 0.936667\n",
      "Epoch: 549/750 Iteration: 4950 Train loss: 0.077132 Train acc: 0.970000\n",
      "Epoch: 549/750 Iteration: 4950 Validation loss: 0.090077 Validation acc: 0.958889\n",
      "Epoch: 550/750 Iteration: 4955 Train loss: 0.082123 Train acc: 0.963333\n",
      "Epoch: 551/750 Iteration: 4960 Train loss: 0.076061 Train acc: 0.963333\n",
      "Epoch: 551/750 Iteration: 4960 Validation loss: 0.089868 Validation acc: 0.959444\n",
      "Epoch: 551/750 Iteration: 4965 Train loss: 0.075990 Train acc: 0.968333\n",
      "Epoch: 552/750 Iteration: 4970 Train loss: 0.070747 Train acc: 0.966667\n",
      "Epoch: 552/750 Iteration: 4970 Validation loss: 0.089293 Validation acc: 0.959444\n",
      "Epoch: 552/750 Iteration: 4975 Train loss: 0.076758 Train acc: 0.966667\n",
      "Epoch: 553/750 Iteration: 4980 Train loss: 0.095524 Train acc: 0.953333\n",
      "Epoch: 553/750 Iteration: 4980 Validation loss: 0.089312 Validation acc: 0.958889\n",
      "Epoch: 553/750 Iteration: 4985 Train loss: 0.057498 Train acc: 0.975000\n",
      "Epoch: 554/750 Iteration: 4990 Train loss: 0.109122 Train acc: 0.943333\n",
      "Epoch: 554/750 Iteration: 4990 Validation loss: 0.089488 Validation acc: 0.959444\n",
      "Epoch: 554/750 Iteration: 4995 Train loss: 0.068825 Train acc: 0.971667\n",
      "Epoch: 555/750 Iteration: 5000 Train loss: 0.082345 Train acc: 0.965000\n",
      "Epoch: 555/750 Iteration: 5000 Validation loss: 0.089883 Validation acc: 0.958889\n",
      "Epoch: 556/750 Iteration: 5005 Train loss: 0.079110 Train acc: 0.966667\n",
      "Epoch: 556/750 Iteration: 5010 Train loss: 0.079625 Train acc: 0.963333\n",
      "Epoch: 556/750 Iteration: 5010 Validation loss: 0.089126 Validation acc: 0.959444\n",
      "Epoch: 557/750 Iteration: 5015 Train loss: 0.068285 Train acc: 0.968333\n",
      "Epoch: 557/750 Iteration: 5020 Train loss: 0.077682 Train acc: 0.965000\n",
      "Epoch: 557/750 Iteration: 5020 Validation loss: 0.088861 Validation acc: 0.959444\n",
      "Epoch: 558/750 Iteration: 5025 Train loss: 0.094822 Train acc: 0.950000\n",
      "Epoch: 558/750 Iteration: 5030 Train loss: 0.056429 Train acc: 0.975000\n",
      "Epoch: 558/750 Iteration: 5030 Validation loss: 0.089393 Validation acc: 0.960556\n",
      "Epoch: 559/750 Iteration: 5035 Train loss: 0.116379 Train acc: 0.938333\n",
      "Epoch: 559/750 Iteration: 5040 Train loss: 0.073698 Train acc: 0.970000\n",
      "Epoch: 559/750 Iteration: 5040 Validation loss: 0.089084 Validation acc: 0.959444\n",
      "Epoch: 560/750 Iteration: 5045 Train loss: 0.081390 Train acc: 0.968333\n",
      "Epoch: 561/750 Iteration: 5050 Train loss: 0.075128 Train acc: 0.968333\n",
      "Epoch: 561/750 Iteration: 5050 Validation loss: 0.088643 Validation acc: 0.959444\n",
      "Epoch: 561/750 Iteration: 5055 Train loss: 0.076953 Train acc: 0.968333\n",
      "Epoch: 562/750 Iteration: 5060 Train loss: 0.068343 Train acc: 0.966667\n",
      "Epoch: 562/750 Iteration: 5060 Validation loss: 0.088376 Validation acc: 0.959444\n",
      "Epoch: 562/750 Iteration: 5065 Train loss: 0.074945 Train acc: 0.970000\n",
      "Epoch: 563/750 Iteration: 5070 Train loss: 0.098208 Train acc: 0.955000\n",
      "Epoch: 563/750 Iteration: 5070 Validation loss: 0.088614 Validation acc: 0.959444\n",
      "Epoch: 563/750 Iteration: 5075 Train loss: 0.059601 Train acc: 0.976667\n",
      "Epoch: 564/750 Iteration: 5080 Train loss: 0.105739 Train acc: 0.946667\n",
      "Epoch: 564/750 Iteration: 5080 Validation loss: 0.088979 Validation acc: 0.959444\n",
      "Epoch: 564/750 Iteration: 5085 Train loss: 0.072461 Train acc: 0.971667\n",
      "Epoch: 565/750 Iteration: 5090 Train loss: 0.079575 Train acc: 0.966667\n",
      "Epoch: 565/750 Iteration: 5090 Validation loss: 0.088533 Validation acc: 0.959444\n",
      "Epoch: 566/750 Iteration: 5095 Train loss: 0.073820 Train acc: 0.973333\n",
      "Epoch: 566/750 Iteration: 5100 Train loss: 0.081664 Train acc: 0.960000\n",
      "Epoch: 566/750 Iteration: 5100 Validation loss: 0.088266 Validation acc: 0.959444\n",
      "Epoch: 567/750 Iteration: 5105 Train loss: 0.067734 Train acc: 0.966667\n",
      "Epoch: 567/750 Iteration: 5110 Train loss: 0.076561 Train acc: 0.971667\n",
      "Epoch: 567/750 Iteration: 5110 Validation loss: 0.088371 Validation acc: 0.960000\n",
      "Epoch: 568/750 Iteration: 5115 Train loss: 0.101124 Train acc: 0.948333\n",
      "Epoch: 568/750 Iteration: 5120 Train loss: 0.055522 Train acc: 0.975000\n",
      "Epoch: 568/750 Iteration: 5120 Validation loss: 0.088332 Validation acc: 0.958889\n",
      "Epoch: 569/750 Iteration: 5125 Train loss: 0.105936 Train acc: 0.950000\n",
      "Epoch: 569/750 Iteration: 5130 Train loss: 0.072162 Train acc: 0.965000\n",
      "Epoch: 569/750 Iteration: 5130 Validation loss: 0.088126 Validation acc: 0.959444\n",
      "Epoch: 570/750 Iteration: 5135 Train loss: 0.089203 Train acc: 0.963333\n",
      "Epoch: 571/750 Iteration: 5140 Train loss: 0.075677 Train acc: 0.970000\n",
      "Epoch: 571/750 Iteration: 5140 Validation loss: 0.088045 Validation acc: 0.959444\n",
      "Epoch: 571/750 Iteration: 5145 Train loss: 0.074965 Train acc: 0.970000\n",
      "Epoch: 572/750 Iteration: 5150 Train loss: 0.066094 Train acc: 0.966667\n",
      "Epoch: 572/750 Iteration: 5150 Validation loss: 0.087906 Validation acc: 0.959444\n",
      "Epoch: 572/750 Iteration: 5155 Train loss: 0.075103 Train acc: 0.968333\n",
      "Epoch: 573/750 Iteration: 5160 Train loss: 0.094768 Train acc: 0.950000\n",
      "Epoch: 573/750 Iteration: 5160 Validation loss: 0.088001 Validation acc: 0.960555\n",
      "Epoch: 573/750 Iteration: 5165 Train loss: 0.059755 Train acc: 0.976667\n",
      "Epoch: 574/750 Iteration: 5170 Train loss: 0.106051 Train acc: 0.950000\n",
      "Epoch: 574/750 Iteration: 5170 Validation loss: 0.088084 Validation acc: 0.958889\n",
      "Epoch: 574/750 Iteration: 5175 Train loss: 0.075100 Train acc: 0.966667\n",
      "Epoch: 575/750 Iteration: 5180 Train loss: 0.080171 Train acc: 0.963333\n",
      "Epoch: 575/750 Iteration: 5180 Validation loss: 0.088082 Validation acc: 0.960556\n",
      "Epoch: 576/750 Iteration: 5185 Train loss: 0.077922 Train acc: 0.958333\n",
      "Epoch: 576/750 Iteration: 5190 Train loss: 0.078246 Train acc: 0.965000\n",
      "Epoch: 576/750 Iteration: 5190 Validation loss: 0.087741 Validation acc: 0.958889\n",
      "Epoch: 577/750 Iteration: 5195 Train loss: 0.062364 Train acc: 0.971667\n",
      "Epoch: 577/750 Iteration: 5200 Train loss: 0.074397 Train acc: 0.968333\n",
      "Epoch: 577/750 Iteration: 5200 Validation loss: 0.087532 Validation acc: 0.960000\n",
      "Epoch: 578/750 Iteration: 5205 Train loss: 0.101095 Train acc: 0.948333\n",
      "Epoch: 578/750 Iteration: 5210 Train loss: 0.056352 Train acc: 0.978333\n",
      "Epoch: 578/750 Iteration: 5210 Validation loss: 0.087171 Validation acc: 0.959444\n",
      "Epoch: 579/750 Iteration: 5215 Train loss: 0.104358 Train acc: 0.946667\n",
      "Epoch: 579/750 Iteration: 5220 Train loss: 0.074163 Train acc: 0.970000\n",
      "Epoch: 579/750 Iteration: 5220 Validation loss: 0.087628 Validation acc: 0.960556\n",
      "Epoch: 580/750 Iteration: 5225 Train loss: 0.078945 Train acc: 0.963333\n",
      "Epoch: 581/750 Iteration: 5230 Train loss: 0.077681 Train acc: 0.968333\n",
      "Epoch: 581/750 Iteration: 5230 Validation loss: 0.087487 Validation acc: 0.959444\n",
      "Epoch: 581/750 Iteration: 5235 Train loss: 0.074178 Train acc: 0.966667\n",
      "Epoch: 582/750 Iteration: 5240 Train loss: 0.064161 Train acc: 0.970000\n",
      "Epoch: 582/750 Iteration: 5240 Validation loss: 0.087572 Validation acc: 0.960000\n",
      "Epoch: 582/750 Iteration: 5245 Train loss: 0.067416 Train acc: 0.971667\n",
      "Epoch: 583/750 Iteration: 5250 Train loss: 0.091832 Train acc: 0.956667\n",
      "Epoch: 583/750 Iteration: 5250 Validation loss: 0.087274 Validation acc: 0.959444\n",
      "Epoch: 583/750 Iteration: 5255 Train loss: 0.055058 Train acc: 0.973333\n",
      "Epoch: 584/750 Iteration: 5260 Train loss: 0.109700 Train acc: 0.945000\n",
      "Epoch: 584/750 Iteration: 5260 Validation loss: 0.087159 Validation acc: 0.959444\n",
      "Epoch: 584/750 Iteration: 5265 Train loss: 0.069683 Train acc: 0.968333\n",
      "Epoch: 585/750 Iteration: 5270 Train loss: 0.084405 Train acc: 0.965000\n",
      "Epoch: 585/750 Iteration: 5270 Validation loss: 0.087080 Validation acc: 0.959444\n",
      "Epoch: 586/750 Iteration: 5275 Train loss: 0.072154 Train acc: 0.968333\n",
      "Epoch: 586/750 Iteration: 5280 Train loss: 0.074280 Train acc: 0.966667\n",
      "Epoch: 586/750 Iteration: 5280 Validation loss: 0.087481 Validation acc: 0.958889\n",
      "Epoch: 587/750 Iteration: 5285 Train loss: 0.063018 Train acc: 0.968333\n",
      "Epoch: 587/750 Iteration: 5290 Train loss: 0.074154 Train acc: 0.965000\n",
      "Epoch: 587/750 Iteration: 5290 Validation loss: 0.087197 Validation acc: 0.959444\n",
      "Epoch: 588/750 Iteration: 5295 Train loss: 0.101900 Train acc: 0.946667\n",
      "Epoch: 588/750 Iteration: 5300 Train loss: 0.056426 Train acc: 0.973333\n",
      "Epoch: 588/750 Iteration: 5300 Validation loss: 0.087009 Validation acc: 0.959444\n",
      "Epoch: 589/750 Iteration: 5305 Train loss: 0.100628 Train acc: 0.945000\n",
      "Epoch: 589/750 Iteration: 5310 Train loss: 0.071811 Train acc: 0.970000\n",
      "Epoch: 589/750 Iteration: 5310 Validation loss: 0.086765 Validation acc: 0.960000\n",
      "Epoch: 590/750 Iteration: 5315 Train loss: 0.081450 Train acc: 0.966667\n",
      "Epoch: 591/750 Iteration: 5320 Train loss: 0.076973 Train acc: 0.963333\n",
      "Epoch: 591/750 Iteration: 5320 Validation loss: 0.086677 Validation acc: 0.959444\n",
      "Epoch: 591/750 Iteration: 5325 Train loss: 0.074391 Train acc: 0.968333\n",
      "Epoch: 592/750 Iteration: 5330 Train loss: 0.061951 Train acc: 0.968333\n",
      "Epoch: 592/750 Iteration: 5330 Validation loss: 0.086755 Validation acc: 0.959444\n",
      "Epoch: 592/750 Iteration: 5335 Train loss: 0.072686 Train acc: 0.970000\n",
      "Epoch: 593/750 Iteration: 5340 Train loss: 0.098298 Train acc: 0.953333\n",
      "Epoch: 593/750 Iteration: 5340 Validation loss: 0.086555 Validation acc: 0.959444\n",
      "Epoch: 593/750 Iteration: 5345 Train loss: 0.058187 Train acc: 0.976667\n",
      "Epoch: 594/750 Iteration: 5350 Train loss: 0.107416 Train acc: 0.941667\n",
      "Epoch: 594/750 Iteration: 5350 Validation loss: 0.086735 Validation acc: 0.959444\n",
      "Epoch: 594/750 Iteration: 5355 Train loss: 0.071443 Train acc: 0.971667\n",
      "Epoch: 595/750 Iteration: 5360 Train loss: 0.077516 Train acc: 0.966667\n",
      "Epoch: 595/750 Iteration: 5360 Validation loss: 0.086400 Validation acc: 0.959444\n",
      "Epoch: 596/750 Iteration: 5365 Train loss: 0.081387 Train acc: 0.963333\n",
      "Epoch: 596/750 Iteration: 5370 Train loss: 0.076891 Train acc: 0.971667\n",
      "Epoch: 596/750 Iteration: 5370 Validation loss: 0.086430 Validation acc: 0.959444\n",
      "Epoch: 597/750 Iteration: 5375 Train loss: 0.064411 Train acc: 0.971667\n",
      "Epoch: 597/750 Iteration: 5380 Train loss: 0.068786 Train acc: 0.968333\n",
      "Epoch: 597/750 Iteration: 5380 Validation loss: 0.086712 Validation acc: 0.959444\n",
      "Epoch: 598/750 Iteration: 5385 Train loss: 0.095797 Train acc: 0.948333\n",
      "Epoch: 598/750 Iteration: 5390 Train loss: 0.050536 Train acc: 0.981667\n",
      "Epoch: 598/750 Iteration: 5390 Validation loss: 0.086337 Validation acc: 0.959444\n",
      "Epoch: 599/750 Iteration: 5395 Train loss: 0.103580 Train acc: 0.950000\n",
      "Epoch: 599/750 Iteration: 5400 Train loss: 0.069352 Train acc: 0.970000\n",
      "Epoch: 599/750 Iteration: 5400 Validation loss: 0.086549 Validation acc: 0.960555\n",
      "Epoch: 600/750 Iteration: 5405 Train loss: 0.081212 Train acc: 0.960000\n",
      "Epoch: 601/750 Iteration: 5410 Train loss: 0.075725 Train acc: 0.968333\n",
      "Epoch: 601/750 Iteration: 5410 Validation loss: 0.085975 Validation acc: 0.959444\n",
      "Epoch: 601/750 Iteration: 5415 Train loss: 0.069190 Train acc: 0.971667\n",
      "Epoch: 602/750 Iteration: 5420 Train loss: 0.068696 Train acc: 0.968333\n",
      "Epoch: 602/750 Iteration: 5420 Validation loss: 0.086081 Validation acc: 0.959444\n",
      "Epoch: 602/750 Iteration: 5425 Train loss: 0.073659 Train acc: 0.971667\n",
      "Epoch: 603/750 Iteration: 5430 Train loss: 0.093573 Train acc: 0.953333\n",
      "Epoch: 603/750 Iteration: 5430 Validation loss: 0.086011 Validation acc: 0.959444\n",
      "Epoch: 603/750 Iteration: 5435 Train loss: 0.053559 Train acc: 0.978333\n",
      "Epoch: 604/750 Iteration: 5440 Train loss: 0.107990 Train acc: 0.945000\n",
      "Epoch: 604/750 Iteration: 5440 Validation loss: 0.086155 Validation acc: 0.959444\n",
      "Epoch: 604/750 Iteration: 5445 Train loss: 0.072997 Train acc: 0.973333\n",
      "Epoch: 605/750 Iteration: 5450 Train loss: 0.078085 Train acc: 0.966667\n",
      "Epoch: 605/750 Iteration: 5450 Validation loss: 0.085546 Validation acc: 0.959444\n",
      "Epoch: 606/750 Iteration: 5455 Train loss: 0.073743 Train acc: 0.961667\n",
      "Epoch: 606/750 Iteration: 5460 Train loss: 0.077015 Train acc: 0.965000\n",
      "Epoch: 606/750 Iteration: 5460 Validation loss: 0.085792 Validation acc: 0.961111\n",
      "Epoch: 607/750 Iteration: 5465 Train loss: 0.065268 Train acc: 0.971667\n",
      "Epoch: 607/750 Iteration: 5470 Train loss: 0.068131 Train acc: 0.965000\n",
      "Epoch: 607/750 Iteration: 5470 Validation loss: 0.086057 Validation acc: 0.960000\n",
      "Epoch: 608/750 Iteration: 5475 Train loss: 0.099230 Train acc: 0.946667\n",
      "Epoch: 608/750 Iteration: 5480 Train loss: 0.056271 Train acc: 0.978333\n",
      "Epoch: 608/750 Iteration: 5480 Validation loss: 0.086093 Validation acc: 0.961111\n",
      "Epoch: 609/750 Iteration: 5485 Train loss: 0.109034 Train acc: 0.943333\n",
      "Epoch: 609/750 Iteration: 5490 Train loss: 0.072539 Train acc: 0.966667\n",
      "Epoch: 609/750 Iteration: 5490 Validation loss: 0.085613 Validation acc: 0.960000\n",
      "Epoch: 610/750 Iteration: 5495 Train loss: 0.077176 Train acc: 0.965000\n",
      "Epoch: 611/750 Iteration: 5500 Train loss: 0.075998 Train acc: 0.963333\n",
      "Epoch: 611/750 Iteration: 5500 Validation loss: 0.085565 Validation acc: 0.959444\n",
      "Epoch: 611/750 Iteration: 5505 Train loss: 0.073878 Train acc: 0.968333\n",
      "Epoch: 612/750 Iteration: 5510 Train loss: 0.063738 Train acc: 0.970000\n",
      "Epoch: 612/750 Iteration: 5510 Validation loss: 0.085728 Validation acc: 0.960555\n",
      "Epoch: 612/750 Iteration: 5515 Train loss: 0.071405 Train acc: 0.966667\n",
      "Epoch: 613/750 Iteration: 5520 Train loss: 0.095521 Train acc: 0.946667\n",
      "Epoch: 613/750 Iteration: 5520 Validation loss: 0.085285 Validation acc: 0.960000\n",
      "Epoch: 613/750 Iteration: 5525 Train loss: 0.055085 Train acc: 0.975000\n",
      "Epoch: 614/750 Iteration: 5530 Train loss: 0.104196 Train acc: 0.943333\n",
      "Epoch: 614/750 Iteration: 5530 Validation loss: 0.085431 Validation acc: 0.960000\n",
      "Epoch: 614/750 Iteration: 5535 Train loss: 0.068268 Train acc: 0.971667\n",
      "Epoch: 615/750 Iteration: 5540 Train loss: 0.076748 Train acc: 0.968333\n",
      "Epoch: 615/750 Iteration: 5540 Validation loss: 0.085509 Validation acc: 0.960000\n",
      "Epoch: 616/750 Iteration: 5545 Train loss: 0.067261 Train acc: 0.973333\n",
      "Epoch: 616/750 Iteration: 5550 Train loss: 0.076298 Train acc: 0.965000\n",
      "Epoch: 616/750 Iteration: 5550 Validation loss: 0.085184 Validation acc: 0.960000\n",
      "Epoch: 617/750 Iteration: 5555 Train loss: 0.063245 Train acc: 0.973333\n",
      "Epoch: 617/750 Iteration: 5560 Train loss: 0.067267 Train acc: 0.971667\n",
      "Epoch: 617/750 Iteration: 5560 Validation loss: 0.085421 Validation acc: 0.961111\n",
      "Epoch: 618/750 Iteration: 5565 Train loss: 0.090642 Train acc: 0.955000\n",
      "Epoch: 618/750 Iteration: 5570 Train loss: 0.057837 Train acc: 0.976667\n",
      "Epoch: 618/750 Iteration: 5570 Validation loss: 0.085195 Validation acc: 0.960000\n",
      "Epoch: 619/750 Iteration: 5575 Train loss: 0.108099 Train acc: 0.940000\n",
      "Epoch: 619/750 Iteration: 5580 Train loss: 0.072258 Train acc: 0.963333\n",
      "Epoch: 619/750 Iteration: 5580 Validation loss: 0.085343 Validation acc: 0.961111\n",
      "Epoch: 620/750 Iteration: 5585 Train loss: 0.078743 Train acc: 0.966667\n",
      "Epoch: 621/750 Iteration: 5590 Train loss: 0.069167 Train acc: 0.968333\n",
      "Epoch: 621/750 Iteration: 5590 Validation loss: 0.085028 Validation acc: 0.960000\n",
      "Epoch: 621/750 Iteration: 5595 Train loss: 0.070207 Train acc: 0.965000\n",
      "Epoch: 622/750 Iteration: 5600 Train loss: 0.062852 Train acc: 0.970000\n",
      "Epoch: 622/750 Iteration: 5600 Validation loss: 0.085022 Validation acc: 0.961667\n",
      "Epoch: 622/750 Iteration: 5605 Train loss: 0.071527 Train acc: 0.968333\n",
      "Epoch: 623/750 Iteration: 5610 Train loss: 0.096500 Train acc: 0.953333\n",
      "Epoch: 623/750 Iteration: 5610 Validation loss: 0.085062 Validation acc: 0.960000\n",
      "Epoch: 623/750 Iteration: 5615 Train loss: 0.054135 Train acc: 0.980000\n",
      "Epoch: 624/750 Iteration: 5620 Train loss: 0.107341 Train acc: 0.945000\n",
      "Epoch: 624/750 Iteration: 5620 Validation loss: 0.085060 Validation acc: 0.960000\n",
      "Epoch: 624/750 Iteration: 5625 Train loss: 0.070874 Train acc: 0.968333\n",
      "Epoch: 625/750 Iteration: 5630 Train loss: 0.080855 Train acc: 0.965000\n",
      "Epoch: 625/750 Iteration: 5630 Validation loss: 0.084526 Validation acc: 0.960000\n",
      "Epoch: 626/750 Iteration: 5635 Train loss: 0.077425 Train acc: 0.963333\n",
      "Epoch: 626/750 Iteration: 5640 Train loss: 0.072148 Train acc: 0.966667\n",
      "Epoch: 626/750 Iteration: 5640 Validation loss: 0.085225 Validation acc: 0.960556\n",
      "Epoch: 627/750 Iteration: 5645 Train loss: 0.061773 Train acc: 0.971667\n",
      "Epoch: 627/750 Iteration: 5650 Train loss: 0.072704 Train acc: 0.970000\n",
      "Epoch: 627/750 Iteration: 5650 Validation loss: 0.085297 Validation acc: 0.961111\n",
      "Epoch: 628/750 Iteration: 5655 Train loss: 0.088187 Train acc: 0.953333\n",
      "Epoch: 628/750 Iteration: 5660 Train loss: 0.055230 Train acc: 0.975000\n",
      "Epoch: 628/750 Iteration: 5660 Validation loss: 0.084778 Validation acc: 0.961111\n",
      "Epoch: 629/750 Iteration: 5665 Train loss: 0.107339 Train acc: 0.943333\n",
      "Epoch: 629/750 Iteration: 5670 Train loss: 0.068199 Train acc: 0.970000\n",
      "Epoch: 629/750 Iteration: 5670 Validation loss: 0.084166 Validation acc: 0.960000\n",
      "Epoch: 630/750 Iteration: 5675 Train loss: 0.077559 Train acc: 0.966667\n",
      "Epoch: 631/750 Iteration: 5680 Train loss: 0.070555 Train acc: 0.968333\n",
      "Epoch: 631/750 Iteration: 5680 Validation loss: 0.084334 Validation acc: 0.960000\n",
      "Epoch: 631/750 Iteration: 5685 Train loss: 0.068301 Train acc: 0.970000\n",
      "Epoch: 632/750 Iteration: 5690 Train loss: 0.062587 Train acc: 0.970000\n",
      "Epoch: 632/750 Iteration: 5690 Validation loss: 0.083973 Validation acc: 0.960000\n",
      "Epoch: 632/750 Iteration: 5695 Train loss: 0.066779 Train acc: 0.968333\n",
      "Epoch: 633/750 Iteration: 5700 Train loss: 0.089550 Train acc: 0.950000\n",
      "Epoch: 633/750 Iteration: 5700 Validation loss: 0.084487 Validation acc: 0.961111\n",
      "Epoch: 633/750 Iteration: 5705 Train loss: 0.053729 Train acc: 0.978333\n",
      "Epoch: 634/750 Iteration: 5710 Train loss: 0.104505 Train acc: 0.940000\n",
      "Epoch: 634/750 Iteration: 5710 Validation loss: 0.084525 Validation acc: 0.960000\n",
      "Epoch: 634/750 Iteration: 5715 Train loss: 0.067264 Train acc: 0.973333\n",
      "Epoch: 635/750 Iteration: 5720 Train loss: 0.080277 Train acc: 0.963333\n",
      "Epoch: 635/750 Iteration: 5720 Validation loss: 0.084328 Validation acc: 0.960000\n",
      "Epoch: 636/750 Iteration: 5725 Train loss: 0.075821 Train acc: 0.961667\n",
      "Epoch: 636/750 Iteration: 5730 Train loss: 0.068956 Train acc: 0.970000\n",
      "Epoch: 636/750 Iteration: 5730 Validation loss: 0.083903 Validation acc: 0.960000\n",
      "Epoch: 637/750 Iteration: 5735 Train loss: 0.063514 Train acc: 0.971667\n",
      "Epoch: 637/750 Iteration: 5740 Train loss: 0.069039 Train acc: 0.971667\n",
      "Epoch: 637/750 Iteration: 5740 Validation loss: 0.083952 Validation acc: 0.960556\n",
      "Epoch: 638/750 Iteration: 5745 Train loss: 0.093169 Train acc: 0.948333\n",
      "Epoch: 638/750 Iteration: 5750 Train loss: 0.050746 Train acc: 0.980000\n",
      "Epoch: 638/750 Iteration: 5750 Validation loss: 0.084042 Validation acc: 0.960556\n",
      "Epoch: 639/750 Iteration: 5755 Train loss: 0.106304 Train acc: 0.946667\n",
      "Epoch: 639/750 Iteration: 5760 Train loss: 0.065654 Train acc: 0.975000\n",
      "Epoch: 639/750 Iteration: 5760 Validation loss: 0.084133 Validation acc: 0.961111\n",
      "Epoch: 640/750 Iteration: 5765 Train loss: 0.080641 Train acc: 0.965000\n",
      "Epoch: 641/750 Iteration: 5770 Train loss: 0.066674 Train acc: 0.973333\n",
      "Epoch: 641/750 Iteration: 5770 Validation loss: 0.083930 Validation acc: 0.960556\n",
      "Epoch: 641/750 Iteration: 5775 Train loss: 0.067874 Train acc: 0.970000\n",
      "Epoch: 642/750 Iteration: 5780 Train loss: 0.061782 Train acc: 0.971667\n",
      "Epoch: 642/750 Iteration: 5780 Validation loss: 0.084087 Validation acc: 0.960000\n",
      "Epoch: 642/750 Iteration: 5785 Train loss: 0.071781 Train acc: 0.970000\n",
      "Epoch: 643/750 Iteration: 5790 Train loss: 0.095744 Train acc: 0.950000\n",
      "Epoch: 643/750 Iteration: 5790 Validation loss: 0.084089 Validation acc: 0.960000\n",
      "Epoch: 643/750 Iteration: 5795 Train loss: 0.053652 Train acc: 0.973333\n",
      "Epoch: 644/750 Iteration: 5800 Train loss: 0.103025 Train acc: 0.945000\n",
      "Epoch: 644/750 Iteration: 5800 Validation loss: 0.083781 Validation acc: 0.960556\n",
      "Epoch: 644/750 Iteration: 5805 Train loss: 0.066527 Train acc: 0.971667\n",
      "Epoch: 645/750 Iteration: 5810 Train loss: 0.072495 Train acc: 0.971667\n",
      "Epoch: 645/750 Iteration: 5810 Validation loss: 0.083591 Validation acc: 0.960556\n",
      "Epoch: 646/750 Iteration: 5815 Train loss: 0.068482 Train acc: 0.971667\n",
      "Epoch: 646/750 Iteration: 5820 Train loss: 0.073377 Train acc: 0.970000\n",
      "Epoch: 646/750 Iteration: 5820 Validation loss: 0.083508 Validation acc: 0.960555\n",
      "Epoch: 647/750 Iteration: 5825 Train loss: 0.060033 Train acc: 0.970000\n",
      "Epoch: 647/750 Iteration: 5830 Train loss: 0.070886 Train acc: 0.970000\n",
      "Epoch: 647/750 Iteration: 5830 Validation loss: 0.083376 Validation acc: 0.961111\n",
      "Epoch: 648/750 Iteration: 5835 Train loss: 0.095169 Train acc: 0.948333\n",
      "Epoch: 648/750 Iteration: 5840 Train loss: 0.057076 Train acc: 0.976667\n",
      "Epoch: 648/750 Iteration: 5840 Validation loss: 0.083213 Validation acc: 0.960556\n",
      "Epoch: 649/750 Iteration: 5845 Train loss: 0.106043 Train acc: 0.945000\n",
      "Epoch: 649/750 Iteration: 5850 Train loss: 0.065365 Train acc: 0.975000\n",
      "Epoch: 649/750 Iteration: 5850 Validation loss: 0.083590 Validation acc: 0.961667\n",
      "Epoch: 650/750 Iteration: 5855 Train loss: 0.072533 Train acc: 0.970000\n",
      "Epoch: 651/750 Iteration: 5860 Train loss: 0.068773 Train acc: 0.970000\n",
      "Epoch: 651/750 Iteration: 5860 Validation loss: 0.083553 Validation acc: 0.961667\n",
      "Epoch: 651/750 Iteration: 5865 Train loss: 0.072753 Train acc: 0.970000\n",
      "Epoch: 652/750 Iteration: 5870 Train loss: 0.057591 Train acc: 0.970000\n",
      "Epoch: 652/750 Iteration: 5870 Validation loss: 0.082937 Validation acc: 0.960555\n",
      "Epoch: 652/750 Iteration: 5875 Train loss: 0.067852 Train acc: 0.971667\n",
      "Epoch: 653/750 Iteration: 5880 Train loss: 0.084894 Train acc: 0.958333\n",
      "Epoch: 653/750 Iteration: 5880 Validation loss: 0.083323 Validation acc: 0.961667\n",
      "Epoch: 653/750 Iteration: 5885 Train loss: 0.053374 Train acc: 0.975000\n",
      "Epoch: 654/750 Iteration: 5890 Train loss: 0.107973 Train acc: 0.938333\n",
      "Epoch: 654/750 Iteration: 5890 Validation loss: 0.083322 Validation acc: 0.960000\n",
      "Epoch: 654/750 Iteration: 5895 Train loss: 0.065923 Train acc: 0.973333\n",
      "Epoch: 655/750 Iteration: 5900 Train loss: 0.071982 Train acc: 0.975000\n",
      "Epoch: 655/750 Iteration: 5900 Validation loss: 0.083026 Validation acc: 0.960556\n",
      "Epoch: 656/750 Iteration: 5905 Train loss: 0.069740 Train acc: 0.971667\n",
      "Epoch: 656/750 Iteration: 5910 Train loss: 0.074177 Train acc: 0.965000\n",
      "Epoch: 656/750 Iteration: 5910 Validation loss: 0.083542 Validation acc: 0.961667\n",
      "Epoch: 657/750 Iteration: 5915 Train loss: 0.058815 Train acc: 0.973333\n",
      "Epoch: 657/750 Iteration: 5920 Train loss: 0.072343 Train acc: 0.970000\n",
      "Epoch: 657/750 Iteration: 5920 Validation loss: 0.083147 Validation acc: 0.961667\n",
      "Epoch: 658/750 Iteration: 5925 Train loss: 0.092996 Train acc: 0.955000\n",
      "Epoch: 658/750 Iteration: 5930 Train loss: 0.053594 Train acc: 0.980000\n",
      "Epoch: 658/750 Iteration: 5930 Validation loss: 0.082592 Validation acc: 0.962222\n",
      "Epoch: 659/750 Iteration: 5935 Train loss: 0.105529 Train acc: 0.943333\n",
      "Epoch: 659/750 Iteration: 5940 Train loss: 0.064024 Train acc: 0.976667\n",
      "Epoch: 659/750 Iteration: 5940 Validation loss: 0.083171 Validation acc: 0.960556\n",
      "Epoch: 660/750 Iteration: 5945 Train loss: 0.078006 Train acc: 0.966667\n",
      "Epoch: 661/750 Iteration: 5950 Train loss: 0.072284 Train acc: 0.970000\n",
      "Epoch: 661/750 Iteration: 5950 Validation loss: 0.083984 Validation acc: 0.961111\n",
      "Epoch: 661/750 Iteration: 5955 Train loss: 0.067287 Train acc: 0.968333\n",
      "Epoch: 662/750 Iteration: 5960 Train loss: 0.059625 Train acc: 0.970000\n",
      "Epoch: 662/750 Iteration: 5960 Validation loss: 0.083623 Validation acc: 0.960000\n",
      "Epoch: 662/750 Iteration: 5965 Train loss: 0.066903 Train acc: 0.971667\n",
      "Epoch: 663/750 Iteration: 5970 Train loss: 0.092726 Train acc: 0.953333\n",
      "Epoch: 663/750 Iteration: 5970 Validation loss: 0.082765 Validation acc: 0.960000\n",
      "Epoch: 663/750 Iteration: 5975 Train loss: 0.051971 Train acc: 0.978333\n",
      "Epoch: 664/750 Iteration: 5980 Train loss: 0.100390 Train acc: 0.945000\n",
      "Epoch: 664/750 Iteration: 5980 Validation loss: 0.082383 Validation acc: 0.961111\n",
      "Epoch: 664/750 Iteration: 5985 Train loss: 0.062230 Train acc: 0.971667\n",
      "Epoch: 665/750 Iteration: 5990 Train loss: 0.077592 Train acc: 0.963333\n",
      "Epoch: 665/750 Iteration: 5990 Validation loss: 0.082643 Validation acc: 0.960556\n",
      "Epoch: 666/750 Iteration: 5995 Train loss: 0.068928 Train acc: 0.970000\n",
      "Epoch: 666/750 Iteration: 6000 Train loss: 0.075220 Train acc: 0.968333\n",
      "Epoch: 666/750 Iteration: 6000 Validation loss: 0.083007 Validation acc: 0.960556\n",
      "Epoch: 667/750 Iteration: 6005 Train loss: 0.061093 Train acc: 0.973333\n",
      "Epoch: 667/750 Iteration: 6010 Train loss: 0.066881 Train acc: 0.966667\n",
      "Epoch: 667/750 Iteration: 6010 Validation loss: 0.082246 Validation acc: 0.960556\n",
      "Epoch: 668/750 Iteration: 6015 Train loss: 0.090029 Train acc: 0.955000\n",
      "Epoch: 668/750 Iteration: 6020 Train loss: 0.050627 Train acc: 0.978333\n",
      "Epoch: 668/750 Iteration: 6020 Validation loss: 0.082602 Validation acc: 0.961111\n",
      "Epoch: 669/750 Iteration: 6025 Train loss: 0.105526 Train acc: 0.941667\n",
      "Epoch: 669/750 Iteration: 6030 Train loss: 0.063711 Train acc: 0.970000\n",
      "Epoch: 669/750 Iteration: 6030 Validation loss: 0.082233 Validation acc: 0.960556\n",
      "Epoch: 670/750 Iteration: 6035 Train loss: 0.071116 Train acc: 0.966667\n",
      "Epoch: 671/750 Iteration: 6040 Train loss: 0.072957 Train acc: 0.968333\n",
      "Epoch: 671/750 Iteration: 6040 Validation loss: 0.082268 Validation acc: 0.960000\n",
      "Epoch: 671/750 Iteration: 6045 Train loss: 0.068298 Train acc: 0.968333\n",
      "Epoch: 672/750 Iteration: 6050 Train loss: 0.062258 Train acc: 0.971667\n",
      "Epoch: 672/750 Iteration: 6050 Validation loss: 0.082664 Validation acc: 0.960000\n",
      "Epoch: 672/750 Iteration: 6055 Train loss: 0.066075 Train acc: 0.975000\n",
      "Epoch: 673/750 Iteration: 6060 Train loss: 0.081274 Train acc: 0.956667\n",
      "Epoch: 673/750 Iteration: 6060 Validation loss: 0.082638 Validation acc: 0.961667\n",
      "Epoch: 673/750 Iteration: 6065 Train loss: 0.055125 Train acc: 0.975000\n",
      "Epoch: 674/750 Iteration: 6070 Train loss: 0.099125 Train acc: 0.946667\n",
      "Epoch: 674/750 Iteration: 6070 Validation loss: 0.081750 Validation acc: 0.960556\n",
      "Epoch: 674/750 Iteration: 6075 Train loss: 0.064285 Train acc: 0.970000\n",
      "Epoch: 675/750 Iteration: 6080 Train loss: 0.074102 Train acc: 0.966667\n",
      "Epoch: 675/750 Iteration: 6080 Validation loss: 0.081646 Validation acc: 0.960556\n",
      "Epoch: 676/750 Iteration: 6085 Train loss: 0.065872 Train acc: 0.971667\n",
      "Epoch: 676/750 Iteration: 6090 Train loss: 0.072340 Train acc: 0.971667\n",
      "Epoch: 676/750 Iteration: 6090 Validation loss: 0.082156 Validation acc: 0.960556\n",
      "Epoch: 677/750 Iteration: 6095 Train loss: 0.064715 Train acc: 0.970000\n",
      "Epoch: 677/750 Iteration: 6100 Train loss: 0.064911 Train acc: 0.971667\n",
      "Epoch: 677/750 Iteration: 6100 Validation loss: 0.081991 Validation acc: 0.962222\n",
      "Epoch: 678/750 Iteration: 6105 Train loss: 0.089273 Train acc: 0.950000\n",
      "Epoch: 678/750 Iteration: 6110 Train loss: 0.050334 Train acc: 0.980000\n",
      "Epoch: 678/750 Iteration: 6110 Validation loss: 0.081618 Validation acc: 0.961111\n",
      "Epoch: 679/750 Iteration: 6115 Train loss: 0.106387 Train acc: 0.945000\n",
      "Epoch: 679/750 Iteration: 6120 Train loss: 0.065634 Train acc: 0.973333\n",
      "Epoch: 679/750 Iteration: 6120 Validation loss: 0.082000 Validation acc: 0.961111\n",
      "Epoch: 680/750 Iteration: 6125 Train loss: 0.072392 Train acc: 0.966667\n",
      "Epoch: 681/750 Iteration: 6130 Train loss: 0.069857 Train acc: 0.965000\n",
      "Epoch: 681/750 Iteration: 6130 Validation loss: 0.082081 Validation acc: 0.961667\n",
      "Epoch: 681/750 Iteration: 6135 Train loss: 0.067967 Train acc: 0.966667\n",
      "Epoch: 682/750 Iteration: 6140 Train loss: 0.062317 Train acc: 0.970000\n",
      "Epoch: 682/750 Iteration: 6140 Validation loss: 0.081910 Validation acc: 0.962222\n",
      "Epoch: 682/750 Iteration: 6145 Train loss: 0.068555 Train acc: 0.968333\n",
      "Epoch: 683/750 Iteration: 6150 Train loss: 0.087808 Train acc: 0.956667\n",
      "Epoch: 683/750 Iteration: 6150 Validation loss: 0.081334 Validation acc: 0.961111\n",
      "Epoch: 683/750 Iteration: 6155 Train loss: 0.052692 Train acc: 0.976667\n",
      "Epoch: 684/750 Iteration: 6160 Train loss: 0.102326 Train acc: 0.943333\n",
      "Epoch: 684/750 Iteration: 6160 Validation loss: 0.081450 Validation acc: 0.961111\n",
      "Epoch: 684/750 Iteration: 6165 Train loss: 0.063024 Train acc: 0.975000\n",
      "Epoch: 685/750 Iteration: 6170 Train loss: 0.075388 Train acc: 0.961667\n",
      "Epoch: 685/750 Iteration: 6170 Validation loss: 0.081369 Validation acc: 0.961111\n",
      "Epoch: 686/750 Iteration: 6175 Train loss: 0.065651 Train acc: 0.973333\n",
      "Epoch: 686/750 Iteration: 6180 Train loss: 0.068541 Train acc: 0.968333\n",
      "Epoch: 686/750 Iteration: 6180 Validation loss: 0.081381 Validation acc: 0.961111\n",
      "Epoch: 687/750 Iteration: 6185 Train loss: 0.061829 Train acc: 0.970000\n",
      "Epoch: 687/750 Iteration: 6190 Train loss: 0.067776 Train acc: 0.971667\n",
      "Epoch: 687/750 Iteration: 6190 Validation loss: 0.081723 Validation acc: 0.962222\n",
      "Epoch: 688/750 Iteration: 6195 Train loss: 0.087836 Train acc: 0.955000\n",
      "Epoch: 688/750 Iteration: 6200 Train loss: 0.050365 Train acc: 0.978333\n",
      "Epoch: 688/750 Iteration: 6200 Validation loss: 0.081649 Validation acc: 0.960556\n",
      "Epoch: 689/750 Iteration: 6205 Train loss: 0.101099 Train acc: 0.945000\n",
      "Epoch: 689/750 Iteration: 6210 Train loss: 0.062967 Train acc: 0.975000\n",
      "Epoch: 689/750 Iteration: 6210 Validation loss: 0.081604 Validation acc: 0.961667\n",
      "Epoch: 690/750 Iteration: 6215 Train loss: 0.073545 Train acc: 0.968333\n",
      "Epoch: 691/750 Iteration: 6220 Train loss: 0.067485 Train acc: 0.966667\n",
      "Epoch: 691/750 Iteration: 6220 Validation loss: 0.080815 Validation acc: 0.961111\n",
      "Epoch: 691/750 Iteration: 6225 Train loss: 0.071195 Train acc: 0.965000\n",
      "Epoch: 692/750 Iteration: 6230 Train loss: 0.058688 Train acc: 0.971667\n",
      "Epoch: 692/750 Iteration: 6230 Validation loss: 0.080839 Validation acc: 0.962778\n",
      "Epoch: 692/750 Iteration: 6235 Train loss: 0.067617 Train acc: 0.971667\n",
      "Epoch: 693/750 Iteration: 6240 Train loss: 0.089721 Train acc: 0.953333\n",
      "Epoch: 693/750 Iteration: 6240 Validation loss: 0.080712 Validation acc: 0.961111\n",
      "Epoch: 693/750 Iteration: 6245 Train loss: 0.047887 Train acc: 0.985000\n",
      "Epoch: 694/750 Iteration: 6250 Train loss: 0.094513 Train acc: 0.950000\n",
      "Epoch: 694/750 Iteration: 6250 Validation loss: 0.080750 Validation acc: 0.961111\n",
      "Epoch: 694/750 Iteration: 6255 Train loss: 0.061727 Train acc: 0.973333\n",
      "Epoch: 695/750 Iteration: 6260 Train loss: 0.073490 Train acc: 0.971667\n",
      "Epoch: 695/750 Iteration: 6260 Validation loss: 0.081078 Validation acc: 0.961111\n",
      "Epoch: 696/750 Iteration: 6265 Train loss: 0.070277 Train acc: 0.968333\n",
      "Epoch: 696/750 Iteration: 6270 Train loss: 0.068736 Train acc: 0.970000\n",
      "Epoch: 696/750 Iteration: 6270 Validation loss: 0.080918 Validation acc: 0.961667\n",
      "Epoch: 697/750 Iteration: 6275 Train loss: 0.059007 Train acc: 0.970000\n",
      "Epoch: 697/750 Iteration: 6280 Train loss: 0.064341 Train acc: 0.971667\n",
      "Epoch: 697/750 Iteration: 6280 Validation loss: 0.081047 Validation acc: 0.962222\n",
      "Epoch: 698/750 Iteration: 6285 Train loss: 0.088892 Train acc: 0.950000\n",
      "Epoch: 698/750 Iteration: 6290 Train loss: 0.050549 Train acc: 0.983333\n",
      "Epoch: 698/750 Iteration: 6290 Validation loss: 0.080751 Validation acc: 0.960555\n",
      "Epoch: 699/750 Iteration: 6295 Train loss: 0.097372 Train acc: 0.946667\n",
      "Epoch: 699/750 Iteration: 6300 Train loss: 0.058695 Train acc: 0.975000\n",
      "Epoch: 699/750 Iteration: 6300 Validation loss: 0.080734 Validation acc: 0.963333\n",
      "Epoch: 700/750 Iteration: 6305 Train loss: 0.074753 Train acc: 0.970000\n",
      "Epoch: 701/750 Iteration: 6310 Train loss: 0.064866 Train acc: 0.970000\n",
      "Epoch: 701/750 Iteration: 6310 Validation loss: 0.080499 Validation acc: 0.961111\n",
      "Epoch: 701/750 Iteration: 6315 Train loss: 0.065886 Train acc: 0.970000\n",
      "Epoch: 702/750 Iteration: 6320 Train loss: 0.060640 Train acc: 0.971667\n",
      "Epoch: 702/750 Iteration: 6320 Validation loss: 0.080414 Validation acc: 0.961111\n",
      "Epoch: 702/750 Iteration: 6325 Train loss: 0.059660 Train acc: 0.976667\n",
      "Epoch: 703/750 Iteration: 6330 Train loss: 0.087679 Train acc: 0.951667\n",
      "Epoch: 703/750 Iteration: 6330 Validation loss: 0.080420 Validation acc: 0.961111\n",
      "Epoch: 703/750 Iteration: 6335 Train loss: 0.049030 Train acc: 0.980000\n",
      "Epoch: 704/750 Iteration: 6340 Train loss: 0.099409 Train acc: 0.946667\n",
      "Epoch: 704/750 Iteration: 6340 Validation loss: 0.080295 Validation acc: 0.961667\n",
      "Epoch: 704/750 Iteration: 6345 Train loss: 0.062023 Train acc: 0.978333\n",
      "Epoch: 705/750 Iteration: 6350 Train loss: 0.075353 Train acc: 0.963333\n",
      "Epoch: 705/750 Iteration: 6350 Validation loss: 0.080212 Validation acc: 0.961667\n",
      "Epoch: 706/750 Iteration: 6355 Train loss: 0.066530 Train acc: 0.970000\n",
      "Epoch: 706/750 Iteration: 6360 Train loss: 0.068806 Train acc: 0.973333\n",
      "Epoch: 706/750 Iteration: 6360 Validation loss: 0.080762 Validation acc: 0.962222\n",
      "Epoch: 707/750 Iteration: 6365 Train loss: 0.055460 Train acc: 0.975000\n",
      "Epoch: 707/750 Iteration: 6370 Train loss: 0.060613 Train acc: 0.978333\n",
      "Epoch: 707/750 Iteration: 6370 Validation loss: 0.080625 Validation acc: 0.961111\n",
      "Epoch: 708/750 Iteration: 6375 Train loss: 0.084935 Train acc: 0.948333\n",
      "Epoch: 708/750 Iteration: 6380 Train loss: 0.050750 Train acc: 0.978333\n",
      "Epoch: 708/750 Iteration: 6380 Validation loss: 0.080130 Validation acc: 0.961111\n",
      "Epoch: 709/750 Iteration: 6385 Train loss: 0.106766 Train acc: 0.943333\n",
      "Epoch: 709/750 Iteration: 6390 Train loss: 0.060512 Train acc: 0.971667\n",
      "Epoch: 709/750 Iteration: 6390 Validation loss: 0.079956 Validation acc: 0.963333\n",
      "Epoch: 710/750 Iteration: 6395 Train loss: 0.071663 Train acc: 0.966667\n",
      "Epoch: 711/750 Iteration: 6400 Train loss: 0.066798 Train acc: 0.966667\n",
      "Epoch: 711/750 Iteration: 6400 Validation loss: 0.080196 Validation acc: 0.963333\n",
      "Epoch: 711/750 Iteration: 6405 Train loss: 0.066004 Train acc: 0.971667\n",
      "Epoch: 712/750 Iteration: 6410 Train loss: 0.059115 Train acc: 0.970000\n",
      "Epoch: 712/750 Iteration: 6410 Validation loss: 0.080001 Validation acc: 0.961667\n",
      "Epoch: 712/750 Iteration: 6415 Train loss: 0.062713 Train acc: 0.973333\n",
      "Epoch: 713/750 Iteration: 6420 Train loss: 0.087579 Train acc: 0.951667\n",
      "Epoch: 713/750 Iteration: 6420 Validation loss: 0.079934 Validation acc: 0.961667\n",
      "Epoch: 713/750 Iteration: 6425 Train loss: 0.045828 Train acc: 0.981667\n",
      "Epoch: 714/750 Iteration: 6430 Train loss: 0.100036 Train acc: 0.945000\n",
      "Epoch: 714/750 Iteration: 6430 Validation loss: 0.079805 Validation acc: 0.962778\n",
      "Epoch: 714/750 Iteration: 6435 Train loss: 0.061599 Train acc: 0.973333\n",
      "Epoch: 715/750 Iteration: 6440 Train loss: 0.071246 Train acc: 0.970000\n",
      "Epoch: 715/750 Iteration: 6440 Validation loss: 0.079679 Validation acc: 0.962778\n",
      "Epoch: 716/750 Iteration: 6445 Train loss: 0.065676 Train acc: 0.970000\n",
      "Epoch: 716/750 Iteration: 6450 Train loss: 0.066404 Train acc: 0.973333\n",
      "Epoch: 716/750 Iteration: 6450 Validation loss: 0.079754 Validation acc: 0.963333\n",
      "Epoch: 717/750 Iteration: 6455 Train loss: 0.055409 Train acc: 0.970000\n",
      "Epoch: 717/750 Iteration: 6460 Train loss: 0.064385 Train acc: 0.970000\n",
      "Epoch: 717/750 Iteration: 6460 Validation loss: 0.079780 Validation acc: 0.962778\n",
      "Epoch: 718/750 Iteration: 6465 Train loss: 0.082365 Train acc: 0.958333\n",
      "Epoch: 718/750 Iteration: 6470 Train loss: 0.050760 Train acc: 0.978333\n",
      "Epoch: 718/750 Iteration: 6470 Validation loss: 0.079695 Validation acc: 0.961111\n",
      "Epoch: 719/750 Iteration: 6475 Train loss: 0.107300 Train acc: 0.946667\n",
      "Epoch: 719/750 Iteration: 6480 Train loss: 0.061958 Train acc: 0.975000\n",
      "Epoch: 719/750 Iteration: 6480 Validation loss: 0.079743 Validation acc: 0.962778\n",
      "Epoch: 720/750 Iteration: 6485 Train loss: 0.074552 Train acc: 0.966667\n",
      "Epoch: 721/750 Iteration: 6490 Train loss: 0.065869 Train acc: 0.971667\n",
      "Epoch: 721/750 Iteration: 6490 Validation loss: 0.079485 Validation acc: 0.962778\n",
      "Epoch: 721/750 Iteration: 6495 Train loss: 0.072141 Train acc: 0.966667\n",
      "Epoch: 722/750 Iteration: 6500 Train loss: 0.055263 Train acc: 0.971667\n",
      "Epoch: 722/750 Iteration: 6500 Validation loss: 0.078949 Validation acc: 0.961667\n",
      "Epoch: 722/750 Iteration: 6505 Train loss: 0.063484 Train acc: 0.971667\n",
      "Epoch: 723/750 Iteration: 6510 Train loss: 0.081896 Train acc: 0.956667\n",
      "Epoch: 723/750 Iteration: 6510 Validation loss: 0.078711 Validation acc: 0.961667\n",
      "Epoch: 723/750 Iteration: 6515 Train loss: 0.049379 Train acc: 0.980000\n",
      "Epoch: 724/750 Iteration: 6520 Train loss: 0.097889 Train acc: 0.941667\n",
      "Epoch: 724/750 Iteration: 6520 Validation loss: 0.079153 Validation acc: 0.962222\n",
      "Epoch: 724/750 Iteration: 6525 Train loss: 0.063655 Train acc: 0.973333\n",
      "Epoch: 725/750 Iteration: 6530 Train loss: 0.074271 Train acc: 0.965000\n",
      "Epoch: 725/750 Iteration: 6530 Validation loss: 0.079069 Validation acc: 0.962222\n",
      "Epoch: 726/750 Iteration: 6535 Train loss: 0.065852 Train acc: 0.970000\n",
      "Epoch: 726/750 Iteration: 6540 Train loss: 0.062633 Train acc: 0.971667\n",
      "Epoch: 726/750 Iteration: 6540 Validation loss: 0.079002 Validation acc: 0.963333\n",
      "Epoch: 727/750 Iteration: 6545 Train loss: 0.056172 Train acc: 0.975000\n",
      "Epoch: 727/750 Iteration: 6550 Train loss: 0.066459 Train acc: 0.973333\n",
      "Epoch: 727/750 Iteration: 6550 Validation loss: 0.078845 Validation acc: 0.963333\n",
      "Epoch: 728/750 Iteration: 6555 Train loss: 0.080525 Train acc: 0.958333\n",
      "Epoch: 728/750 Iteration: 6560 Train loss: 0.046490 Train acc: 0.980000\n",
      "Epoch: 728/750 Iteration: 6560 Validation loss: 0.078912 Validation acc: 0.962778\n",
      "Epoch: 729/750 Iteration: 6565 Train loss: 0.098023 Train acc: 0.945000\n",
      "Epoch: 729/750 Iteration: 6570 Train loss: 0.056631 Train acc: 0.978333\n",
      "Epoch: 729/750 Iteration: 6570 Validation loss: 0.078602 Validation acc: 0.963333\n",
      "Epoch: 730/750 Iteration: 6575 Train loss: 0.070868 Train acc: 0.965000\n",
      "Epoch: 731/750 Iteration: 6580 Train loss: 0.064880 Train acc: 0.970000\n",
      "Epoch: 731/750 Iteration: 6580 Validation loss: 0.078816 Validation acc: 0.963333\n",
      "Epoch: 731/750 Iteration: 6585 Train loss: 0.064154 Train acc: 0.970000\n",
      "Epoch: 732/750 Iteration: 6590 Train loss: 0.054314 Train acc: 0.971667\n",
      "Epoch: 732/750 Iteration: 6590 Validation loss: 0.078697 Validation acc: 0.963333\n",
      "Epoch: 732/750 Iteration: 6595 Train loss: 0.066823 Train acc: 0.971667\n",
      "Epoch: 733/750 Iteration: 6600 Train loss: 0.082373 Train acc: 0.960000\n",
      "Epoch: 733/750 Iteration: 6600 Validation loss: 0.079118 Validation acc: 0.962778\n",
      "Epoch: 733/750 Iteration: 6605 Train loss: 0.050856 Train acc: 0.975000\n",
      "Epoch: 734/750 Iteration: 6610 Train loss: 0.100639 Train acc: 0.943333\n",
      "Epoch: 734/750 Iteration: 6610 Validation loss: 0.079084 Validation acc: 0.962778\n",
      "Epoch: 734/750 Iteration: 6615 Train loss: 0.056385 Train acc: 0.976667\n",
      "Epoch: 735/750 Iteration: 6620 Train loss: 0.074082 Train acc: 0.968333\n",
      "Epoch: 735/750 Iteration: 6620 Validation loss: 0.078492 Validation acc: 0.962222\n",
      "Epoch: 736/750 Iteration: 6625 Train loss: 0.064790 Train acc: 0.973333\n",
      "Epoch: 736/750 Iteration: 6630 Train loss: 0.067400 Train acc: 0.965000\n",
      "Epoch: 736/750 Iteration: 6630 Validation loss: 0.078457 Validation acc: 0.962778\n",
      "Epoch: 737/750 Iteration: 6635 Train loss: 0.052816 Train acc: 0.976667\n",
      "Epoch: 737/750 Iteration: 6640 Train loss: 0.061873 Train acc: 0.971667\n",
      "Epoch: 737/750 Iteration: 6640 Validation loss: 0.078386 Validation acc: 0.962222\n",
      "Epoch: 738/750 Iteration: 6645 Train loss: 0.083073 Train acc: 0.955000\n",
      "Epoch: 738/750 Iteration: 6650 Train loss: 0.048144 Train acc: 0.980000\n",
      "Epoch: 738/750 Iteration: 6650 Validation loss: 0.078841 Validation acc: 0.962778\n",
      "Epoch: 739/750 Iteration: 6655 Train loss: 0.102722 Train acc: 0.946667\n",
      "Epoch: 739/750 Iteration: 6660 Train loss: 0.057478 Train acc: 0.975000\n",
      "Epoch: 739/750 Iteration: 6660 Validation loss: 0.078721 Validation acc: 0.962778\n",
      "Epoch: 740/750 Iteration: 6665 Train loss: 0.068122 Train acc: 0.968333\n",
      "Epoch: 741/750 Iteration: 6670 Train loss: 0.063596 Train acc: 0.973333\n",
      "Epoch: 741/750 Iteration: 6670 Validation loss: 0.078292 Validation acc: 0.962778\n",
      "Epoch: 741/750 Iteration: 6675 Train loss: 0.061461 Train acc: 0.973333\n",
      "Epoch: 742/750 Iteration: 6680 Train loss: 0.055875 Train acc: 0.971667\n",
      "Epoch: 742/750 Iteration: 6680 Validation loss: 0.078062 Validation acc: 0.963333\n",
      "Epoch: 742/750 Iteration: 6685 Train loss: 0.068238 Train acc: 0.971667\n",
      "Epoch: 743/750 Iteration: 6690 Train loss: 0.080986 Train acc: 0.958333\n",
      "Epoch: 743/750 Iteration: 6690 Validation loss: 0.078492 Validation acc: 0.962778\n",
      "Epoch: 743/750 Iteration: 6695 Train loss: 0.046582 Train acc: 0.976667\n",
      "Epoch: 744/750 Iteration: 6700 Train loss: 0.100757 Train acc: 0.948333\n",
      "Epoch: 744/750 Iteration: 6700 Validation loss: 0.078480 Validation acc: 0.962778\n",
      "Epoch: 744/750 Iteration: 6705 Train loss: 0.056818 Train acc: 0.978333\n",
      "Epoch: 745/750 Iteration: 6710 Train loss: 0.067197 Train acc: 0.971667\n",
      "Epoch: 745/750 Iteration: 6710 Validation loss: 0.078090 Validation acc: 0.962778\n",
      "Epoch: 746/750 Iteration: 6715 Train loss: 0.062176 Train acc: 0.971667\n",
      "Epoch: 746/750 Iteration: 6720 Train loss: 0.063629 Train acc: 0.973333\n",
      "Epoch: 746/750 Iteration: 6720 Validation loss: 0.078073 Validation acc: 0.962778\n",
      "Epoch: 747/750 Iteration: 6725 Train loss: 0.057198 Train acc: 0.968333\n",
      "Epoch: 747/750 Iteration: 6730 Train loss: 0.063580 Train acc: 0.966667\n",
      "Epoch: 747/750 Iteration: 6730 Validation loss: 0.078130 Validation acc: 0.963333\n",
      "Epoch: 748/750 Iteration: 6735 Train loss: 0.081954 Train acc: 0.958333\n",
      "Epoch: 748/750 Iteration: 6740 Train loss: 0.048776 Train acc: 0.978333\n",
      "Epoch: 748/750 Iteration: 6740 Validation loss: 0.077883 Validation acc: 0.962778\n",
      "Epoch: 749/750 Iteration: 6745 Train loss: 0.092579 Train acc: 0.953333\n",
      "Epoch: 749/750 Iteration: 6750 Train loss: 0.060905 Train acc: 0.971667\n",
      "Epoch: 749/750 Iteration: 6750 Validation loss: 0.078119 Validation acc: 0.962222\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAF3CAYAAABkPHbIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0oiIiKSMSURERHJmJKIiIhk7P8DGFgviUsuMxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f406d0557f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAF3CAYAAAC7cgzXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK5QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f406d055128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.893750\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
